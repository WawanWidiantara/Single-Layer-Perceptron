{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data Training Hasil Encode** (Belum dinormalisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0            1         0       3    1  22.0      1      0   7.2500         2\n",
       "1            2         1       1    0  38.0      1      0  71.2833         0\n",
       "2            3         1       3    0  26.0      0      0   7.9250         2\n",
       "3            4         1       1    0  35.0      1      0  53.1000         2\n",
       "4            5         0       3    1  35.0      0      0   8.0500         2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('D:/Code/py_code/Artificial-Neural-Network/Single-Layer-Perceptron/Data Training.xlsx', sheet_name='Hasil Encode', index_col=0)\n",
    "x_train = train.iloc[:, 2:].values\n",
    "y_train = train.iloc[:, 1].values\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data Training Hasil Normalisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked   \n",
       "0            1     1.0    1  0.271174    0.2    0.0  0.014151       1.0  \\\n",
       "1            2     0.0    0  0.472229    0.2    0.0  0.139136       0.0   \n",
       "2            3     1.0    0  0.321438    0.0    0.0  0.015469       1.0   \n",
       "3            4     0.0    0  0.434531    0.2    0.0  0.103644       1.0   \n",
       "4            5     1.0    1  0.434531    0.0    0.0  0.015713       1.0   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normalize = pd.read_excel('D:/Code/py_code/Artificial-Neural-Network/Single-Layer-Perceptron/Data Training.xlsx', sheet_name='Normalisasi', index_col=0)\n",
    "x_train_normalize = train_normalize.iloc[:, 1:-1].values\n",
    "y_train_normalize = train_normalize.iloc[:, -1].values\n",
    "train_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data Testing Hasil Encode** (Belum dinormalisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0          892       3    1  34.5      0      0   7.8292         1\n",
       "1          893       3    0  47.0      1      0   7.0000         2\n",
       "2          894       2    1  62.0      0      0   9.6875         1\n",
       "3          895       3    1  27.0      0      0   8.6625         2\n",
       "4          896       3    0  22.0      1      1  12.2875         2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('D:/Code/py_code/Artificial-Neural-Network/Single-Layer-Perceptron/Data Testing.xlsx', sheet_name='Hasil Encode', index_col=0)\n",
    "\n",
    "label = pd.read_csv(\"D:/Code/py_code/Artificial-Neural-Network/Single-Layer-Perceptron/data/test_data_GroundTruth_cl.csv\")\n",
    "\n",
    "x_test = test.iloc[:, 1:].values\n",
    "y_test = label['Survived'].values\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data Training Hasil Normalisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp     Parch      Fare  Embarked   \n",
       "0          892     1.0    1  0.452723  0.000  0.000000  0.015282       0.5  \\\n",
       "1          893     1.0    0  0.617566  0.125  0.000000  0.013663       1.0   \n",
       "2          894     0.5    1  0.815377  0.000  0.000000  0.018909       0.5   \n",
       "3          895     1.0    1  0.353818  0.000  0.000000  0.016908       1.0   \n",
       "4          896     1.0    0  0.287881  0.125  0.166667  0.023984       1.0   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_normalize = pd.read_excel('D:/Code/py_code/Artificial-Neural-Network/Single-Layer-Perceptron/Data Testing.xlsx', sheet_name='Normalisasi', index_col=0)\n",
    "x_test_normalize = test_normalize.iloc[:, 1:-1].values\n",
    "y_test_normalize = test_normalize.iloc[:, -1].values\n",
    "test_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Plot Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(matrix, title): \n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(matrix, annot=True, fmt='g', ax=ax, cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "\n",
    "    ax.set_title(f'Confusion Matrix {title}', pad=10);\n",
    "    ax.xaxis.set_ticklabels(['Not Survived', 'Survived']);ax.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembuatan Model Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8 (32.00 Byte)\n",
      "Trainable params: 8 (32.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[len(x_train[0])], activation='sigmoid', kernel_initializer='random_uniform')])\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03581891],\n",
       "        [ 0.01626286],\n",
       "        [-0.01412892],\n",
       "        [ 0.04499895],\n",
       "        [-0.04219389],\n",
       "        [ 0.01523323],\n",
       "        [ 0.04704999]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.3778\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.2496 - accuracy: 0.5225\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.2457 - accuracy: 0.5941\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2423 - accuracy: 0.5955\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2390 - accuracy: 0.5955\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2363 - accuracy: 0.5955\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.2339 - accuracy: 0.5955\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.2319 - accuracy: 0.5955\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.2299 - accuracy: 0.5955\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.2283 - accuracy: 0.5955\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 0s 776us/step - loss: 0.2268 - accuracy: 0.5955\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.2255 - accuracy: 0.5955\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.2243 - accuracy: 0.5955\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.2232 - accuracy: 0.5955\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.2221 - accuracy: 0.5955\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.2212 - accuracy: 0.5955\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2203 - accuracy: 0.5955\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.2194 - accuracy: 0.5955\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2187 - accuracy: 0.5955\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.2179 - accuracy: 0.5955\n",
      "Epoch 21/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.2173 - accuracy: 0.5955\n",
      "Epoch 22/1000\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.2166 - accuracy: 0.5955\n",
      "Epoch 23/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.2160 - accuracy: 0.5955\n",
      "Epoch 24/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.2154 - accuracy: 0.5955\n",
      "Epoch 25/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.2148 - accuracy: 0.5955\n",
      "Epoch 26/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.2142 - accuracy: 0.5955\n",
      "Epoch 27/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2137 - accuracy: 0.5955\n",
      "Epoch 28/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.2131 - accuracy: 0.5955\n",
      "Epoch 29/1000\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.2126 - accuracy: 0.5955\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.2121 - accuracy: 0.5955\n",
      "Epoch 31/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.2116 - accuracy: 0.5955\n",
      "Epoch 32/1000\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.2111 - accuracy: 0.5969\n",
      "Epoch 33/1000\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.2106 - accuracy: 0.5969\n",
      "Epoch 34/1000\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.2102 - accuracy: 0.5997\n",
      "Epoch 35/1000\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.2097 - accuracy: 0.6011\n",
      "Epoch 36/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.2093 - accuracy: 0.6011\n",
      "Epoch 37/1000\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.2088 - accuracy: 0.6025\n",
      "Epoch 38/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2084 - accuracy: 0.6067\n",
      "Epoch 39/1000\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.2079 - accuracy: 0.6110\n",
      "Epoch 40/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.6208\n",
      "Epoch 41/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.6320\n",
      "Epoch 42/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2066 - accuracy: 0.6419\n",
      "Epoch 43/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.2062 - accuracy: 0.6447\n",
      "Epoch 44/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.2058 - accuracy: 0.6461\n",
      "Epoch 45/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2054 - accuracy: 0.6461\n",
      "Epoch 46/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.2050 - accuracy: 0.6503\n",
      "Epoch 47/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.2045 - accuracy: 0.6503\n",
      "Epoch 48/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2041 - accuracy: 0.6503\n",
      "Epoch 49/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.2037 - accuracy: 0.6517\n",
      "Epoch 50/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.2033 - accuracy: 0.6489\n",
      "Epoch 51/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.2029 - accuracy: 0.6531\n",
      "Epoch 52/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.2025 - accuracy: 0.6573\n",
      "Epoch 53/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2021 - accuracy: 0.6784\n",
      "Epoch 54/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.2018 - accuracy: 0.6952\n",
      "Epoch 55/1000\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.2014 - accuracy: 0.6994\n",
      "Epoch 56/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.2010 - accuracy: 0.7022\n",
      "Epoch 57/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.2006 - accuracy: 0.7037\n",
      "Epoch 58/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.2002 - accuracy: 0.7037\n",
      "Epoch 59/1000\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1999 - accuracy: 0.7037\n",
      "Epoch 60/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1995 - accuracy: 0.7037\n",
      "Epoch 61/1000\n",
      "23/23 [==============================] - 0s 728us/step - loss: 0.1992 - accuracy: 0.7037\n",
      "Epoch 62/1000\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1988 - accuracy: 0.7037\n",
      "Epoch 63/1000\n",
      "23/23 [==============================] - 0s 742us/step - loss: 0.1984 - accuracy: 0.7037\n",
      "Epoch 64/1000\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.1981 - accuracy: 0.7037\n",
      "Epoch 65/1000\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.1978 - accuracy: 0.7037\n",
      "Epoch 66/1000\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1974 - accuracy: 0.7037\n",
      "Epoch 67/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1971 - accuracy: 0.7037\n",
      "Epoch 68/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1967 - accuracy: 0.7037\n",
      "Epoch 69/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1964 - accuracy: 0.7037\n",
      "Epoch 70/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1961 - accuracy: 0.7037\n",
      "Epoch 71/1000\n",
      "23/23 [==============================] - 0s 747us/step - loss: 0.1957 - accuracy: 0.7051\n",
      "Epoch 72/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.1954 - accuracy: 0.7051\n",
      "Epoch 73/1000\n",
      "23/23 [==============================] - 0s 776us/step - loss: 0.1951 - accuracy: 0.7065\n",
      "Epoch 74/1000\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.1947 - accuracy: 0.7107\n",
      "Epoch 75/1000\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1944 - accuracy: 0.7107\n",
      "Epoch 76/1000\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1941 - accuracy: 0.7107\n",
      "Epoch 77/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1938 - accuracy: 0.7135\n",
      "Epoch 78/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1935 - accuracy: 0.7135\n",
      "Epoch 79/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1932 - accuracy: 0.7135\n",
      "Epoch 80/1000\n",
      "23/23 [==============================] - 0s 781us/step - loss: 0.1929 - accuracy: 0.7135\n",
      "Epoch 81/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1926 - accuracy: 0.7177\n",
      "Epoch 82/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1923 - accuracy: 0.7219\n",
      "Epoch 83/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1920 - accuracy: 0.7388\n",
      "Epoch 84/1000\n",
      "23/23 [==============================] - 0s 782us/step - loss: 0.1917 - accuracy: 0.7416\n",
      "Epoch 85/1000\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.1914 - accuracy: 0.7570\n",
      "Epoch 86/1000\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1911 - accuracy: 0.7584\n",
      "Epoch 87/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1909 - accuracy: 0.7697\n",
      "Epoch 88/1000\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.1906 - accuracy: 0.7907\n",
      "Epoch 89/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1903 - accuracy: 0.7907\n",
      "Epoch 90/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.1900 - accuracy: 0.7907\n",
      "Epoch 91/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1897 - accuracy: 0.7907\n",
      "Epoch 92/1000\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.1895 - accuracy: 0.7907\n",
      "Epoch 93/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1892 - accuracy: 0.7907\n",
      "Epoch 94/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1889 - accuracy: 0.7907\n",
      "Epoch 95/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1887 - accuracy: 0.7907\n",
      "Epoch 96/1000\n",
      "23/23 [==============================] - 0s 780us/step - loss: 0.1884 - accuracy: 0.7907\n",
      "Epoch 97/1000\n",
      "23/23 [==============================] - 0s 780us/step - loss: 0.1882 - accuracy: 0.7907\n",
      "Epoch 98/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1879 - accuracy: 0.7907\n",
      "Epoch 99/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1876 - accuracy: 0.7907\n",
      "Epoch 100/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1874 - accuracy: 0.7907\n",
      "Epoch 101/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1871 - accuracy: 0.7907\n",
      "Epoch 102/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1869 - accuracy: 0.7907\n",
      "Epoch 103/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1866 - accuracy: 0.7907\n",
      "Epoch 104/1000\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.1864 - accuracy: 0.7907\n",
      "Epoch 105/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1862 - accuracy: 0.7907\n",
      "Epoch 106/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1859 - accuracy: 0.7907\n",
      "Epoch 107/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1857 - accuracy: 0.7907\n",
      "Epoch 108/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1855 - accuracy: 0.7907\n",
      "Epoch 109/1000\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1852 - accuracy: 0.7907\n",
      "Epoch 110/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1850 - accuracy: 0.7907\n",
      "Epoch 111/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1848 - accuracy: 0.7907\n",
      "Epoch 112/1000\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1846 - accuracy: 0.7907\n",
      "Epoch 113/1000\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1843 - accuracy: 0.7907\n",
      "Epoch 114/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1841 - accuracy: 0.7907\n",
      "Epoch 115/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1839 - accuracy: 0.7907\n",
      "Epoch 116/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1837 - accuracy: 0.7907\n",
      "Epoch 117/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1835 - accuracy: 0.7907\n",
      "Epoch 118/1000\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1833 - accuracy: 0.7907\n",
      "Epoch 119/1000\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1830 - accuracy: 0.7907\n",
      "Epoch 120/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1828 - accuracy: 0.7907\n",
      "Epoch 121/1000\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.1826 - accuracy: 0.7907\n",
      "Epoch 122/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1824 - accuracy: 0.7907\n",
      "Epoch 123/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1822 - accuracy: 0.7907\n",
      "Epoch 124/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1820 - accuracy: 0.7907\n",
      "Epoch 125/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1818 - accuracy: 0.7907\n",
      "Epoch 126/1000\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.1816 - accuracy: 0.7907\n",
      "Epoch 127/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1814 - accuracy: 0.7907\n",
      "Epoch 128/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1812 - accuracy: 0.7907\n",
      "Epoch 129/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1810 - accuracy: 0.7907\n",
      "Epoch 130/1000\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1808 - accuracy: 0.7907\n",
      "Epoch 131/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1806 - accuracy: 0.7907\n",
      "Epoch 132/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1804 - accuracy: 0.7907\n",
      "Epoch 133/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1802 - accuracy: 0.7907\n",
      "Epoch 134/1000\n",
      "23/23 [==============================] - 0s 788us/step - loss: 0.1801 - accuracy: 0.7907\n",
      "Epoch 135/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1799 - accuracy: 0.7907\n",
      "Epoch 136/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1797 - accuracy: 0.7893\n",
      "Epoch 137/1000\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1795 - accuracy: 0.7893\n",
      "Epoch 138/1000\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1794 - accuracy: 0.7879\n",
      "Epoch 139/1000\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1792 - accuracy: 0.7865\n",
      "Epoch 140/1000\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.1790 - accuracy: 0.7879\n",
      "Epoch 141/1000\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1788 - accuracy: 0.7865\n",
      "Epoch 142/1000\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1786 - accuracy: 0.7851\n",
      "Epoch 143/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1784 - accuracy: 0.7837\n",
      "Epoch 144/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1783 - accuracy: 0.7809\n",
      "Epoch 145/1000\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.1781 - accuracy: 0.7795\n",
      "Epoch 146/1000\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.1780 - accuracy: 0.7781\n",
      "Epoch 147/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1778 - accuracy: 0.7781\n",
      "Epoch 148/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1776 - accuracy: 0.7781\n",
      "Epoch 149/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1775 - accuracy: 0.7781\n",
      "Epoch 150/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1773 - accuracy: 0.7795\n",
      "Epoch 151/1000\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.1771 - accuracy: 0.7767\n",
      "Epoch 152/1000\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.1770 - accuracy: 0.7739\n",
      "Epoch 153/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1768 - accuracy: 0.7767\n",
      "Epoch 154/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1767 - accuracy: 0.7725\n",
      "Epoch 155/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1765 - accuracy: 0.7725\n",
      "Epoch 156/1000\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.1764 - accuracy: 0.7711\n",
      "Epoch 157/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1762 - accuracy: 0.7725\n",
      "Epoch 158/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1761 - accuracy: 0.7711\n",
      "Epoch 159/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1759 - accuracy: 0.7697\n",
      "Epoch 160/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1757 - accuracy: 0.7725\n",
      "Epoch 161/1000\n",
      "23/23 [==============================] - 0s 775us/step - loss: 0.1756 - accuracy: 0.7697\n",
      "Epoch 162/1000\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.1754 - accuracy: 0.7725\n",
      "Epoch 163/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1753 - accuracy: 0.7683\n",
      "Epoch 164/1000\n",
      "23/23 [==============================] - 0s 772us/step - loss: 0.1752 - accuracy: 0.7697\n",
      "Epoch 165/1000\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.1750 - accuracy: 0.7697\n",
      "Epoch 166/1000\n",
      "23/23 [==============================] - 0s 761us/step - loss: 0.1749 - accuracy: 0.7697\n",
      "Epoch 167/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1748 - accuracy: 0.7683\n",
      "Epoch 168/1000\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.1746 - accuracy: 0.7683\n",
      "Epoch 169/1000\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1745 - accuracy: 0.7711\n",
      "Epoch 170/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1743 - accuracy: 0.7739\n",
      "Epoch 171/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1742 - accuracy: 0.7725\n",
      "Epoch 172/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1741 - accuracy: 0.7739\n",
      "Epoch 173/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1740 - accuracy: 0.7725\n",
      "Epoch 174/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1738 - accuracy: 0.7711\n",
      "Epoch 175/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1737 - accuracy: 0.7711\n",
      "Epoch 176/1000\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.1735 - accuracy: 0.7697\n",
      "Epoch 177/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1734 - accuracy: 0.7739\n",
      "Epoch 178/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1733 - accuracy: 0.7725\n",
      "Epoch 179/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1732 - accuracy: 0.7669\n",
      "Epoch 180/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1730 - accuracy: 0.7711\n",
      "Epoch 181/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1729 - accuracy: 0.7683\n",
      "Epoch 182/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1728 - accuracy: 0.7725\n",
      "Epoch 183/1000\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1727 - accuracy: 0.7739\n",
      "Epoch 184/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1725 - accuracy: 0.7725\n",
      "Epoch 185/1000\n",
      "23/23 [==============================] - 0s 788us/step - loss: 0.1724 - accuracy: 0.7711\n",
      "Epoch 186/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1723 - accuracy: 0.7753\n",
      "Epoch 187/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1722 - accuracy: 0.7753\n",
      "Epoch 188/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1720 - accuracy: 0.7767\n",
      "Epoch 189/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1719 - accuracy: 0.7767\n",
      "Epoch 190/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1718 - accuracy: 0.7767\n",
      "Epoch 191/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1717 - accuracy: 0.7781\n",
      "Epoch 192/1000\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.1716 - accuracy: 0.7795\n",
      "Epoch 193/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1715 - accuracy: 0.7795\n",
      "Epoch 194/1000\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1714 - accuracy: 0.7795\n",
      "Epoch 195/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1713 - accuracy: 0.7795\n",
      "Epoch 196/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1711 - accuracy: 0.7795\n",
      "Epoch 197/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1710 - accuracy: 0.7795\n",
      "Epoch 198/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1709 - accuracy: 0.7795\n",
      "Epoch 199/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1708 - accuracy: 0.7795\n",
      "Epoch 200/1000\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1707 - accuracy: 0.7795\n",
      "Epoch 201/1000\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1706 - accuracy: 0.7795\n",
      "Epoch 202/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1705 - accuracy: 0.7795\n",
      "Epoch 203/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1704 - accuracy: 0.7795\n",
      "Epoch 204/1000\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.1703 - accuracy: 0.7795\n",
      "Epoch 205/1000\n",
      "23/23 [==============================] - 0s 765us/step - loss: 0.1702 - accuracy: 0.7795\n",
      "Epoch 206/1000\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1701 - accuracy: 0.7795\n",
      "Epoch 207/1000\n",
      "23/23 [==============================] - 0s 781us/step - loss: 0.1700 - accuracy: 0.7795\n",
      "Epoch 208/1000\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1699 - accuracy: 0.7795\n",
      "Epoch 209/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1698 - accuracy: 0.7795\n",
      "Epoch 210/1000\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1697 - accuracy: 0.7795\n",
      "Epoch 211/1000\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1696 - accuracy: 0.7795\n",
      "Epoch 212/1000\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.1695 - accuracy: 0.7795\n",
      "Epoch 213/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1694 - accuracy: 0.7795\n",
      "Epoch 214/1000\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1693 - accuracy: 0.7795\n",
      "Epoch 215/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1692 - accuracy: 0.7795\n",
      "Epoch 216/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1691 - accuracy: 0.7795\n",
      "Epoch 217/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1690 - accuracy: 0.7795\n",
      "Epoch 218/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1689 - accuracy: 0.7795\n",
      "Epoch 219/1000\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.1688 - accuracy: 0.7795\n",
      "Epoch 220/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1687 - accuracy: 0.7795\n",
      "Epoch 221/1000\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1686 - accuracy: 0.7795\n",
      "Epoch 222/1000\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1685 - accuracy: 0.7795\n",
      "Epoch 223/1000\n",
      "23/23 [==============================] - 0s 781us/step - loss: 0.1684 - accuracy: 0.7795\n",
      "Epoch 224/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1684 - accuracy: 0.7795\n",
      "Epoch 225/1000\n",
      "23/23 [==============================] - 0s 980us/step - loss: 0.1683 - accuracy: 0.7795\n",
      "Epoch 226/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.7795\n",
      "Epoch 227/1000\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.1681 - accuracy: 0.7795\n",
      "Epoch 228/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1680 - accuracy: 0.7795\n",
      "Epoch 229/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1679 - accuracy: 0.7795\n",
      "Epoch 230/1000\n",
      "23/23 [==============================] - 0s 780us/step - loss: 0.1678 - accuracy: 0.7795\n",
      "Epoch 231/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1677 - accuracy: 0.7795\n",
      "Epoch 232/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.7795\n",
      "Epoch 233/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.7795\n",
      "Epoch 234/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1675 - accuracy: 0.7795\n",
      "Epoch 235/1000\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.1674 - accuracy: 0.7795\n",
      "Epoch 236/1000\n",
      "23/23 [==============================] - 0s 787us/step - loss: 0.1673 - accuracy: 0.7795\n",
      "Epoch 237/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1673 - accuracy: 0.7795\n",
      "Epoch 238/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.7795\n",
      "Epoch 239/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1671 - accuracy: 0.7795\n",
      "Epoch 240/1000\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.1670 - accuracy: 0.7795\n",
      "Epoch 241/1000\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.1669 - accuracy: 0.7795\n",
      "Epoch 242/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1669 - accuracy: 0.7795\n",
      "Epoch 243/1000\n",
      "23/23 [==============================] - 0s 781us/step - loss: 0.1668 - accuracy: 0.7795\n",
      "Epoch 244/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1667 - accuracy: 0.7795\n",
      "Epoch 245/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1666 - accuracy: 0.7795\n",
      "Epoch 246/1000\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1666 - accuracy: 0.7795\n",
      "Epoch 247/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.7795\n",
      "Epoch 248/1000\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1664 - accuracy: 0.7795\n",
      "Epoch 249/1000\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1663 - accuracy: 0.7795\n",
      "Epoch 250/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1662 - accuracy: 0.7795\n",
      "Epoch 251/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1662 - accuracy: 0.7795\n",
      "Epoch 252/1000\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.1661 - accuracy: 0.7795\n",
      "Epoch 253/1000\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1660 - accuracy: 0.7795\n",
      "Epoch 254/1000\n",
      "23/23 [==============================] - 0s 776us/step - loss: 0.1660 - accuracy: 0.7795\n",
      "Epoch 255/1000\n",
      "23/23 [==============================] - 0s 777us/step - loss: 0.1659 - accuracy: 0.7795\n",
      "Epoch 256/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1658 - accuracy: 0.7795\n",
      "Epoch 257/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1657 - accuracy: 0.7795\n",
      "Epoch 258/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1657 - accuracy: 0.7795\n",
      "Epoch 259/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1656 - accuracy: 0.7795\n",
      "Epoch 260/1000\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.1655 - accuracy: 0.7795\n",
      "Epoch 261/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1655 - accuracy: 0.7795\n",
      "Epoch 262/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1654 - accuracy: 0.7795\n",
      "Epoch 263/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1653 - accuracy: 0.7795\n",
      "Epoch 264/1000\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.1653 - accuracy: 0.7795\n",
      "Epoch 265/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1652 - accuracy: 0.7795\n",
      "Epoch 266/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1651 - accuracy: 0.7795\n",
      "Epoch 267/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1651 - accuracy: 0.7795\n",
      "Epoch 268/1000\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1650 - accuracy: 0.7795\n",
      "Epoch 269/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1649 - accuracy: 0.7795\n",
      "Epoch 270/1000\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1649 - accuracy: 0.7795\n",
      "Epoch 271/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1648 - accuracy: 0.7795\n",
      "Epoch 272/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.7795\n",
      "Epoch 273/1000\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.1647 - accuracy: 0.7795\n",
      "Epoch 274/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1646 - accuracy: 0.7795\n",
      "Epoch 275/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1645 - accuracy: 0.7795\n",
      "Epoch 276/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1645 - accuracy: 0.7795\n",
      "Epoch 277/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1644 - accuracy: 0.7795\n",
      "Epoch 278/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1643 - accuracy: 0.7795\n",
      "Epoch 279/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1643 - accuracy: 0.7795\n",
      "Epoch 280/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.7795\n",
      "Epoch 281/1000\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.1642 - accuracy: 0.7795\n",
      "Epoch 282/1000\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1641 - accuracy: 0.7795\n",
      "Epoch 283/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1641 - accuracy: 0.7795\n",
      "Epoch 284/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1640 - accuracy: 0.7795\n",
      "Epoch 285/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1639 - accuracy: 0.7795\n",
      "Epoch 286/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1639 - accuracy: 0.7795\n",
      "Epoch 287/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1638 - accuracy: 0.7795\n",
      "Epoch 288/1000\n",
      "23/23 [==============================] - 0s 760us/step - loss: 0.1638 - accuracy: 0.7795\n",
      "Epoch 289/1000\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.1637 - accuracy: 0.7795\n",
      "Epoch 290/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1636 - accuracy: 0.7795\n",
      "Epoch 291/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1636 - accuracy: 0.7795\n",
      "Epoch 292/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1635 - accuracy: 0.7795\n",
      "Epoch 293/1000\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1635 - accuracy: 0.7795\n",
      "Epoch 294/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1634 - accuracy: 0.7795\n",
      "Epoch 295/1000\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.1634 - accuracy: 0.7795\n",
      "Epoch 296/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1633 - accuracy: 0.7795\n",
      "Epoch 297/1000\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1632 - accuracy: 0.7795\n",
      "Epoch 298/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1632 - accuracy: 0.7795\n",
      "Epoch 299/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1631 - accuracy: 0.7795\n",
      "Epoch 300/1000\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.1631 - accuracy: 0.7795\n",
      "Epoch 301/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1630 - accuracy: 0.7795\n",
      "Epoch 302/1000\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1630 - accuracy: 0.7795\n",
      "Epoch 303/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1629 - accuracy: 0.7795\n",
      "Epoch 304/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1629 - accuracy: 0.7795\n",
      "Epoch 305/1000\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.1628 - accuracy: 0.7795\n",
      "Epoch 306/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1628 - accuracy: 0.7795\n",
      "Epoch 307/1000\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.1627 - accuracy: 0.7795\n",
      "Epoch 308/1000\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.1627 - accuracy: 0.7795\n",
      "Epoch 309/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.7795\n",
      "Epoch 310/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.7795\n",
      "Epoch 311/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1625 - accuracy: 0.7795\n",
      "Epoch 312/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1625 - accuracy: 0.7795\n",
      "Epoch 313/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1624 - accuracy: 0.7795\n",
      "Epoch 314/1000\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1624 - accuracy: 0.7795\n",
      "Epoch 315/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1623 - accuracy: 0.7795\n",
      "Epoch 316/1000\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.1623 - accuracy: 0.7795\n",
      "Epoch 317/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1622 - accuracy: 0.7795\n",
      "Epoch 318/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1622 - accuracy: 0.7795\n",
      "Epoch 319/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1621 - accuracy: 0.7795\n",
      "Epoch 320/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1621 - accuracy: 0.7795\n",
      "Epoch 321/1000\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1620 - accuracy: 0.7795\n",
      "Epoch 322/1000\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1620 - accuracy: 0.7795\n",
      "Epoch 323/1000\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1619 - accuracy: 0.7795\n",
      "Epoch 324/1000\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.1619 - accuracy: 0.7795\n",
      "Epoch 325/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1618 - accuracy: 0.7795\n",
      "Epoch 326/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1618 - accuracy: 0.7795\n",
      "Epoch 327/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1617 - accuracy: 0.7795\n",
      "Epoch 328/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1617 - accuracy: 0.7795\n",
      "Epoch 329/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1617 - accuracy: 0.7795\n",
      "Epoch 330/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1616 - accuracy: 0.7795\n",
      "Epoch 331/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1616 - accuracy: 0.7795\n",
      "Epoch 332/1000\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1615 - accuracy: 0.7795\n",
      "Epoch 333/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1615 - accuracy: 0.7795\n",
      "Epoch 334/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1614 - accuracy: 0.7795\n",
      "Epoch 335/1000\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.1614 - accuracy: 0.7795\n",
      "Epoch 336/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1614 - accuracy: 0.7795\n",
      "Epoch 337/1000\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.1613 - accuracy: 0.7795\n",
      "Epoch 338/1000\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1613 - accuracy: 0.7795\n",
      "Epoch 339/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1612 - accuracy: 0.7795\n",
      "Epoch 340/1000\n",
      "23/23 [==============================] - 0s 793us/step - loss: 0.1612 - accuracy: 0.7795\n",
      "Epoch 341/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1611 - accuracy: 0.7795\n",
      "Epoch 342/1000\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.1611 - accuracy: 0.7795\n",
      "Epoch 343/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1611 - accuracy: 0.7795\n",
      "Epoch 344/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1610 - accuracy: 0.7795\n",
      "Epoch 345/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1610 - accuracy: 0.7795\n",
      "Epoch 346/1000\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1609 - accuracy: 0.7795\n",
      "Epoch 347/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1609 - accuracy: 0.7795\n",
      "Epoch 348/1000\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1608 - accuracy: 0.7795\n",
      "Epoch 349/1000\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.1608 - accuracy: 0.7795\n",
      "Epoch 350/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.7795\n",
      "Epoch 351/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.7795\n",
      "Epoch 352/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1607 - accuracy: 0.7795\n",
      "Epoch 353/1000\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.1606 - accuracy: 0.7795\n",
      "Epoch 354/1000\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.1606 - accuracy: 0.7795\n",
      "Epoch 355/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1606 - accuracy: 0.7795\n",
      "Epoch 356/1000\n",
      "23/23 [==============================] - 0s 779us/step - loss: 0.1605 - accuracy: 0.7795\n",
      "Epoch 357/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1605 - accuracy: 0.7795\n",
      "Epoch 358/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1605 - accuracy: 0.7795\n",
      "Epoch 359/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1604 - accuracy: 0.7795\n",
      "Epoch 360/1000\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1604 - accuracy: 0.7795\n",
      "Epoch 361/1000\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.1603 - accuracy: 0.7795\n",
      "Epoch 362/1000\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1603 - accuracy: 0.7795\n",
      "Epoch 363/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1603 - accuracy: 0.7795\n",
      "Epoch 364/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1602 - accuracy: 0.7795\n",
      "Epoch 365/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1602 - accuracy: 0.7795\n",
      "Epoch 366/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1602 - accuracy: 0.7795\n",
      "Epoch 367/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1601 - accuracy: 0.7795\n",
      "Epoch 368/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1601 - accuracy: 0.7795\n",
      "Epoch 369/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1600 - accuracy: 0.7795\n",
      "Epoch 370/1000\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1600 - accuracy: 0.7795\n",
      "Epoch 371/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1600 - accuracy: 0.7795\n",
      "Epoch 372/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1599 - accuracy: 0.7795\n",
      "Epoch 373/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1599 - accuracy: 0.7795\n",
      "Epoch 374/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1599 - accuracy: 0.7795\n",
      "Epoch 375/1000\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.1598 - accuracy: 0.7795\n",
      "Epoch 376/1000\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1598 - accuracy: 0.7795\n",
      "Epoch 377/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1598 - accuracy: 0.7795\n",
      "Epoch 378/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1597 - accuracy: 0.7795\n",
      "Epoch 379/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1597 - accuracy: 0.7795\n",
      "Epoch 380/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1596 - accuracy: 0.7795\n",
      "Epoch 381/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1596 - accuracy: 0.7795\n",
      "Epoch 382/1000\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.1596 - accuracy: 0.7795\n",
      "Epoch 383/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1595 - accuracy: 0.7795\n",
      "Epoch 384/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1595 - accuracy: 0.7795\n",
      "Epoch 385/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1595 - accuracy: 0.7795\n",
      "Epoch 386/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.7795\n",
      "Epoch 387/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.7795\n",
      "Epoch 388/1000\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.1594 - accuracy: 0.7795\n",
      "Epoch 389/1000\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.1593 - accuracy: 0.7795\n",
      "Epoch 390/1000\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1593 - accuracy: 0.7795\n",
      "Epoch 391/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1593 - accuracy: 0.7795\n",
      "Epoch 392/1000\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.1592 - accuracy: 0.7795\n",
      "Epoch 393/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1592 - accuracy: 0.7795\n",
      "Epoch 394/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1592 - accuracy: 0.7795\n",
      "Epoch 395/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1591 - accuracy: 0.7795\n",
      "Epoch 396/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1591 - accuracy: 0.7795\n",
      "Epoch 397/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1591 - accuracy: 0.7795\n",
      "Epoch 398/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1590 - accuracy: 0.7795\n",
      "Epoch 399/1000\n",
      "23/23 [==============================] - 0s 779us/step - loss: 0.1590 - accuracy: 0.7795\n",
      "Epoch 400/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1590 - accuracy: 0.7795\n",
      "Epoch 401/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1589 - accuracy: 0.7795\n",
      "Epoch 402/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1589 - accuracy: 0.7795\n",
      "Epoch 403/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1589 - accuracy: 0.7795\n",
      "Epoch 404/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1589 - accuracy: 0.7795\n",
      "Epoch 405/1000\n",
      "23/23 [==============================] - 0s 788us/step - loss: 0.1588 - accuracy: 0.7795\n",
      "Epoch 406/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1588 - accuracy: 0.7795\n",
      "Epoch 407/1000\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1588 - accuracy: 0.7795\n",
      "Epoch 408/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1587 - accuracy: 0.7795\n",
      "Epoch 409/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1587 - accuracy: 0.7795\n",
      "Epoch 410/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1587 - accuracy: 0.7795\n",
      "Epoch 411/1000\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.1586 - accuracy: 0.7795\n",
      "Epoch 412/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1586 - accuracy: 0.7795\n",
      "Epoch 413/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1586 - accuracy: 0.7795\n",
      "Epoch 414/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1586 - accuracy: 0.7795\n",
      "Epoch 415/1000\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1585 - accuracy: 0.7795\n",
      "Epoch 416/1000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.7795\n",
      "Epoch 417/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.7795\n",
      "Epoch 418/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1584 - accuracy: 0.7795\n",
      "Epoch 419/1000\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1584 - accuracy: 0.7795\n",
      "Epoch 420/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1584 - accuracy: 0.7795\n",
      "Epoch 421/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1583 - accuracy: 0.7795\n",
      "Epoch 422/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1583 - accuracy: 0.7795\n",
      "Epoch 423/1000\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1583 - accuracy: 0.7795\n",
      "Epoch 424/1000\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1583 - accuracy: 0.7795\n",
      "Epoch 425/1000\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.1582 - accuracy: 0.7795\n",
      "Epoch 426/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.7795\n",
      "Epoch 427/1000\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1582 - accuracy: 0.7795\n",
      "Epoch 428/1000\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.1582 - accuracy: 0.7795\n",
      "Epoch 429/1000\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1581 - accuracy: 0.7795\n",
      "Epoch 430/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1581 - accuracy: 0.7795\n",
      "Epoch 431/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1581 - accuracy: 0.7795\n",
      "Epoch 432/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1581 - accuracy: 0.7795\n",
      "Epoch 433/1000\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1580 - accuracy: 0.7795\n",
      "Epoch 434/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1580 - accuracy: 0.7795\n",
      "Epoch 435/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1580 - accuracy: 0.7795\n",
      "Epoch 436/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1579 - accuracy: 0.7795\n",
      "Epoch 437/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1579 - accuracy: 0.7795\n",
      "Epoch 438/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.7795\n",
      "Epoch 439/1000\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.1579 - accuracy: 0.7795\n",
      "Epoch 440/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.7795\n",
      "Epoch 441/1000\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1578 - accuracy: 0.7795\n",
      "Epoch 442/1000\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.1578 - accuracy: 0.7795\n",
      "Epoch 443/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.7795\n",
      "Epoch 444/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.7795\n",
      "Epoch 445/1000\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.1577 - accuracy: 0.7795\n",
      "Epoch 446/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1577 - accuracy: 0.7795\n",
      "Epoch 447/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1577 - accuracy: 0.7795\n",
      "Epoch 448/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1576 - accuracy: 0.7795\n",
      "Epoch 449/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1576 - accuracy: 0.7795\n",
      "Epoch 450/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1576 - accuracy: 0.7795\n",
      "Epoch 451/1000\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1576 - accuracy: 0.7795\n",
      "Epoch 452/1000\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.1575 - accuracy: 0.7795\n",
      "Epoch 453/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.7795\n",
      "Epoch 454/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1575 - accuracy: 0.7795\n",
      "Epoch 455/1000\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1575 - accuracy: 0.7795\n",
      "Epoch 456/1000\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.1574 - accuracy: 0.7795\n",
      "Epoch 457/1000\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.1574 - accuracy: 0.7795\n",
      "Epoch 458/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1574 - accuracy: 0.7795\n",
      "Epoch 459/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1574 - accuracy: 0.7795\n",
      "Epoch 460/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1573 - accuracy: 0.7795\n",
      "Epoch 461/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1573 - accuracy: 0.7795\n",
      "Epoch 462/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1573 - accuracy: 0.7795\n",
      "Epoch 463/1000\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1573 - accuracy: 0.7795\n",
      "Epoch 464/1000\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1572 - accuracy: 0.7795\n",
      "Epoch 465/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1572 - accuracy: 0.7795\n",
      "Epoch 466/1000\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1572 - accuracy: 0.7795\n",
      "Epoch 467/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1572 - accuracy: 0.7795\n",
      "Epoch 468/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1572 - accuracy: 0.7795\n",
      "Epoch 469/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1571 - accuracy: 0.7795\n",
      "Epoch 470/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1571 - accuracy: 0.7795\n",
      "Epoch 471/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1571 - accuracy: 0.7795\n",
      "Epoch 472/1000\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1571 - accuracy: 0.7795\n",
      "Epoch 473/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1570 - accuracy: 0.7795\n",
      "Epoch 474/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1570 - accuracy: 0.7795\n",
      "Epoch 475/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1570 - accuracy: 0.7795\n",
      "Epoch 476/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1570 - accuracy: 0.7795\n",
      "Epoch 477/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1569 - accuracy: 0.7795\n",
      "Epoch 478/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.7795\n",
      "Epoch 479/1000\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.1569 - accuracy: 0.7795\n",
      "Epoch 480/1000\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1569 - accuracy: 0.7795\n",
      "Epoch 481/1000\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.1568 - accuracy: 0.7795\n",
      "Epoch 482/1000\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1568 - accuracy: 0.7795\n",
      "Epoch 483/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1568 - accuracy: 0.7795\n",
      "Epoch 484/1000\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.1568 - accuracy: 0.7795\n",
      "Epoch 485/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1568 - accuracy: 0.7795\n",
      "Epoch 486/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1567 - accuracy: 0.7795\n",
      "Epoch 487/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1567 - accuracy: 0.7795\n",
      "Epoch 488/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1567 - accuracy: 0.7795\n",
      "Epoch 489/1000\n",
      "23/23 [==============================] - 0s 776us/step - loss: 0.1567 - accuracy: 0.7795\n",
      "Epoch 490/1000\n",
      "23/23 [==============================] - 0s 795us/step - loss: 0.1567 - accuracy: 0.7795\n",
      "Epoch 491/1000\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1566 - accuracy: 0.7795\n",
      "Epoch 492/1000\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.1566 - accuracy: 0.7795\n",
      "Epoch 493/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1566 - accuracy: 0.7795\n",
      "Epoch 494/1000\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1566 - accuracy: 0.7795\n",
      "Epoch 495/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1565 - accuracy: 0.7795\n",
      "Epoch 496/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1565 - accuracy: 0.7795\n",
      "Epoch 497/1000\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.1565 - accuracy: 0.7795\n",
      "Epoch 498/1000\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1565 - accuracy: 0.7795\n",
      "Epoch 499/1000\n",
      "23/23 [==============================] - 0s 751us/step - loss: 0.1565 - accuracy: 0.7795\n",
      "Epoch 500/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1564 - accuracy: 0.7795\n",
      "Epoch 501/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1564 - accuracy: 0.7795\n",
      "Epoch 502/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1564 - accuracy: 0.7795\n",
      "Epoch 503/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1564 - accuracy: 0.7795\n",
      "Epoch 504/1000\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1564 - accuracy: 0.7795\n",
      "Epoch 505/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1563 - accuracy: 0.7795\n",
      "Epoch 506/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.7795\n",
      "Epoch 507/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.7795\n",
      "Epoch 508/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.7795\n",
      "Epoch 509/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1563 - accuracy: 0.7795\n",
      "Epoch 510/1000\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1562 - accuracy: 0.7795\n",
      "Epoch 511/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1562 - accuracy: 0.7795\n",
      "Epoch 512/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1562 - accuracy: 0.7795\n",
      "Epoch 513/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1562 - accuracy: 0.7795\n",
      "Epoch 514/1000\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1562 - accuracy: 0.7795\n",
      "Epoch 515/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1561 - accuracy: 0.7795\n",
      "Epoch 516/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1561 - accuracy: 0.7795\n",
      "Epoch 517/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1561 - accuracy: 0.7795\n",
      "Epoch 518/1000\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1561 - accuracy: 0.7795\n",
      "Epoch 519/1000\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1561 - accuracy: 0.7795\n",
      "Epoch 520/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1560 - accuracy: 0.7795\n",
      "Epoch 521/1000\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1560 - accuracy: 0.7795\n",
      "Epoch 522/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1560 - accuracy: 0.7795\n",
      "Epoch 523/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1560 - accuracy: 0.7795\n",
      "Epoch 524/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.7795\n",
      "Epoch 525/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.7795\n",
      "Epoch 526/1000\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.1559 - accuracy: 0.7795\n",
      "Epoch 527/1000\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.1559 - accuracy: 0.7795\n",
      "Epoch 528/1000\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.1559 - accuracy: 0.7795\n",
      "Epoch 529/1000\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.1559 - accuracy: 0.7795\n",
      "Epoch 530/1000\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1559 - accuracy: 0.7795\n",
      "Epoch 531/1000\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.1558 - accuracy: 0.7795\n",
      "Epoch 532/1000\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.1558 - accuracy: 0.7795\n",
      "Epoch 533/1000\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1558 - accuracy: 0.7795\n",
      "Epoch 534/1000\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1558 - accuracy: 0.7795\n",
      "Epoch 535/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1558 - accuracy: 0.7795\n",
      "Epoch 536/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.7795\n",
      "Epoch 537/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.7795\n",
      "Epoch 538/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1557 - accuracy: 0.7795\n",
      "Epoch 539/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.7795\n",
      "Epoch 540/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1557 - accuracy: 0.7795\n",
      "Epoch 541/1000\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1556 - accuracy: 0.7795\n",
      "Epoch 542/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1556 - accuracy: 0.7795\n",
      "Epoch 543/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.1556 - accuracy: 0.7795\n",
      "Epoch 544/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1556 - accuracy: 0.7795\n",
      "Epoch 545/1000\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1556 - accuracy: 0.7795\n",
      "Epoch 546/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1556 - accuracy: 0.7795\n",
      "Epoch 547/1000\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1555 - accuracy: 0.7795\n",
      "Epoch 548/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.7795\n",
      "Epoch 549/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1555 - accuracy: 0.7795\n",
      "Epoch 550/1000\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1555 - accuracy: 0.7795\n",
      "Epoch 551/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1555 - accuracy: 0.7795\n",
      "Epoch 552/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1555 - accuracy: 0.7795\n",
      "Epoch 553/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1554 - accuracy: 0.7795\n",
      "Epoch 554/1000\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1554 - accuracy: 0.7795\n",
      "Epoch 555/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1554 - accuracy: 0.7795\n",
      "Epoch 556/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1554 - accuracy: 0.7795\n",
      "Epoch 557/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1554 - accuracy: 0.7795\n",
      "Epoch 558/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1554 - accuracy: 0.7795\n",
      "Epoch 559/1000\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.1553 - accuracy: 0.7795\n",
      "Epoch 560/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1553 - accuracy: 0.7795\n",
      "Epoch 561/1000\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.1553 - accuracy: 0.7795\n",
      "Epoch 562/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1553 - accuracy: 0.7795\n",
      "Epoch 563/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1553 - accuracy: 0.7795\n",
      "Epoch 564/1000\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.1553 - accuracy: 0.7795\n",
      "Epoch 565/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1552 - accuracy: 0.7795\n",
      "Epoch 566/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1552 - accuracy: 0.7795\n",
      "Epoch 567/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1552 - accuracy: 0.7795\n",
      "Epoch 568/1000\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.1552 - accuracy: 0.7795\n",
      "Epoch 569/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1552 - accuracy: 0.7795\n",
      "Epoch 570/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1552 - accuracy: 0.7795\n",
      "Epoch 571/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1551 - accuracy: 0.7795\n",
      "Epoch 572/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.7795\n",
      "Epoch 573/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.7795\n",
      "Epoch 574/1000\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.1551 - accuracy: 0.7795\n",
      "Epoch 575/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1551 - accuracy: 0.7795\n",
      "Epoch 576/1000\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1551 - accuracy: 0.7795\n",
      "Epoch 577/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1550 - accuracy: 0.7795\n",
      "Epoch 578/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1550 - accuracy: 0.7795\n",
      "Epoch 579/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1550 - accuracy: 0.7795\n",
      "Epoch 580/1000\n",
      "23/23 [==============================] - 0s 779us/step - loss: 0.1550 - accuracy: 0.7795\n",
      "Epoch 581/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1550 - accuracy: 0.7795\n",
      "Epoch 582/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1550 - accuracy: 0.7795\n",
      "Epoch 583/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1549 - accuracy: 0.7795\n",
      "Epoch 584/1000\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1549 - accuracy: 0.7795\n",
      "Epoch 585/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1549 - accuracy: 0.7795\n",
      "Epoch 586/1000\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.1549 - accuracy: 0.7795\n",
      "Epoch 587/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1549 - accuracy: 0.7795\n",
      "Epoch 588/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.1549 - accuracy: 0.7795\n",
      "Epoch 589/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 590/1000\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 591/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 592/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 593/1000\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 594/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 595/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1548 - accuracy: 0.7795\n",
      "Epoch 596/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 597/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 598/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 599/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 600/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 601/1000\n",
      "23/23 [==============================] - 0s 775us/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 602/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1547 - accuracy: 0.7795\n",
      "Epoch 603/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.1546 - accuracy: 0.7795\n",
      "Epoch 604/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1546 - accuracy: 0.7795\n",
      "Epoch 605/1000\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1546 - accuracy: 0.7795\n",
      "Epoch 606/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1546 - accuracy: 0.7795\n",
      "Epoch 607/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1546 - accuracy: 0.7795\n",
      "Epoch 608/1000\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.1546 - accuracy: 0.7795\n",
      "Epoch 609/1000\n",
      "23/23 [==============================] - 0s 779us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 610/1000\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 611/1000\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 612/1000\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 613/1000\n",
      "23/23 [==============================] - 0s 787us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 614/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 615/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1545 - accuracy: 0.7795\n",
      "Epoch 616/1000\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 617/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 618/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 619/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 620/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 621/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 622/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1544 - accuracy: 0.7795\n",
      "Epoch 623/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 624/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 625/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 626/1000\n",
      "23/23 [==============================] - 0s 751us/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 627/1000\n",
      "23/23 [==============================] - 0s 756us/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 628/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 629/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.7795\n",
      "Epoch 630/1000\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 631/1000\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 632/1000\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 633/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 634/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 635/1000\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 636/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1542 - accuracy: 0.7795\n",
      "Epoch 637/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 638/1000\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 639/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 640/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 641/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 642/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 643/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1541 - accuracy: 0.7795\n",
      "Epoch 644/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 645/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 646/1000\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 647/1000\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 648/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 649/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 650/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 651/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1540 - accuracy: 0.7795\n",
      "Epoch 652/1000\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 653/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 654/1000\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 655/1000\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 656/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 657/1000\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 658/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 659/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1539 - accuracy: 0.7795\n",
      "Epoch 660/1000\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 661/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 662/1000\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 663/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 664/1000\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 665/1000\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 666/1000\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.1538 - accuracy: 0.7795\n",
      "Epoch 667/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 668/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 669/1000\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 670/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 671/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 672/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 673/1000\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 674/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1537 - accuracy: 0.7795\n",
      "Epoch 675/1000\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 676/1000\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 677/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 678/1000\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 679/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 680/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 681/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 682/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 683/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1536 - accuracy: 0.7795\n",
      "Epoch 684/1000\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 685/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 686/1000\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 687/1000\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 688/1000\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 689/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 690/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 691/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1535 - accuracy: 0.7795\n",
      "Epoch 692/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 693/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 694/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 695/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 696/1000\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 697/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 698/1000\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 699/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1534 - accuracy: 0.7795\n",
      "Epoch 700/1000\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 701/1000\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 702/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 703/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 704/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 705/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 706/1000\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 707/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 708/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1533 - accuracy: 0.7795\n",
      "Epoch 709/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1532 - accuracy: 0.7795\n",
      "Epoch 710/1000\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 711/1000\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 712/1000\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 713/1000\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 714/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 715/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 716/1000\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 717/1000\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 718/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1532 - accuracy: 0.7809\n",
      "Epoch 719/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 720/1000\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 721/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 722/1000\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 723/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 724/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 725/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 726/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1531 - accuracy: 0.7809\n",
      "Epoch 727/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1530 - accuracy: 0.7809\n",
      "Epoch 728/1000\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 729/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 730/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 731/1000\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 732/1000\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 733/1000\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 734/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 735/1000\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 736/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1530 - accuracy: 0.7823\n",
      "Epoch 737/1000\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 738/1000\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 739/1000\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 740/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 741/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 742/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 743/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 744/1000\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 745/1000\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1529 - accuracy: 0.7823\n",
      "Epoch 746/1000\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 747/1000\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 748/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 749/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 750/1000\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 751/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 752/1000\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 753/1000\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 754/1000\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 755/1000\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.1528 - accuracy: 0.7823\n",
      "Epoch 756/1000\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 757/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 758/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 759/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 760/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 761/1000\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 762/1000\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 763/1000\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 764/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 765/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1527 - accuracy: 0.7823\n",
      "Epoch 766/1000\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 767/1000\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 768/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 769/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 770/1000\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 771/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 772/1000\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 773/1000\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 774/1000\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 775/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1526 - accuracy: 0.7823\n",
      "Epoch 776/1000\n",
      "23/23 [==============================] - 0s 791us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 777/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 778/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 779/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 780/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 781/1000\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 782/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 783/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 784/1000\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 785/1000\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1525 - accuracy: 0.7823\n",
      "Epoch 786/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 787/1000\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 788/1000\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 789/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 790/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 791/1000\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 792/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 793/1000\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 794/1000\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 795/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1524 - accuracy: 0.7823\n",
      "Epoch 796/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 797/1000\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 798/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 799/1000\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 800/1000\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 801/1000\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 802/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 803/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 804/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 805/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 806/1000\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1523 - accuracy: 0.7823\n",
      "Epoch 807/1000\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 808/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 809/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 810/1000\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 811/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 812/1000\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 813/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 814/1000\n",
      "23/23 [==============================] - 0s 782us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 815/1000\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 816/1000\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 817/1000\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.1522 - accuracy: 0.7823\n",
      "Epoch 818/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 819/1000\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 820/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 821/1000\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 822/1000\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 823/1000\n",
      "23/23 [==============================] - 0s 784us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 824/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 825/1000\n",
      "23/23 [==============================] - 0s 741us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 826/1000\n",
      "23/23 [==============================] - 0s 756us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 827/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 828/1000\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 829/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1521 - accuracy: 0.7823\n",
      "Epoch 830/1000\n",
      "23/23 [==============================] - 0s 770us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 831/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 832/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 833/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 834/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 835/1000\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 836/1000\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 837/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 838/1000\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 839/1000\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 840/1000\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1520 - accuracy: 0.7823\n",
      "Epoch 841/1000\n",
      "23/23 [==============================] - 0s 788us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 842/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 843/1000\n",
      "23/23 [==============================] - 0s 771us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 844/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 845/1000\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 846/1000\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 847/1000\n",
      "23/23 [==============================] - 0s 793us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 848/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 849/1000\n",
      "23/23 [==============================] - 0s 791us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 850/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 851/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1519 - accuracy: 0.7823\n",
      "Epoch 852/1000\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 853/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 854/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 855/1000\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 856/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 857/1000\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 858/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 859/1000\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 860/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 861/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 862/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 863/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1518 - accuracy: 0.7823\n",
      "Epoch 864/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 865/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 866/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 867/1000\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 868/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 869/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 870/1000\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 871/1000\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 872/1000\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 873/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 874/1000\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 875/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.7823\n",
      "Epoch 876/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 877/1000\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 878/1000\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 879/1000\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 880/1000\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 881/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 882/1000\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 883/1000\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 884/1000\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 885/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 886/1000\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 887/1000\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1516 - accuracy: 0.7823\n",
      "Epoch 888/1000\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 889/1000\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 890/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 891/1000\n",
      "23/23 [==============================] - 0s 769us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 892/1000\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 893/1000\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 894/1000\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 895/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 896/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 897/1000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 898/1000\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 899/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 900/1000\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1515 - accuracy: 0.7823\n",
      "Epoch 901/1000\n",
      "23/23 [==============================] - 0s 769us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 902/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 903/1000\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 904/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 905/1000\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 906/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 907/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 908/1000\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 909/1000\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 910/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 911/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 912/1000\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1514 - accuracy: 0.7823\n",
      "Epoch 913/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 914/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 915/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 916/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 917/1000\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 918/1000\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 919/1000\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 920/1000\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 921/1000\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 922/1000\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 923/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 924/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 925/1000\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 926/1000\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1513 - accuracy: 0.7823\n",
      "Epoch 927/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 928/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 929/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 930/1000\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 931/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 932/1000\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 933/1000\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 934/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 935/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 936/1000\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 937/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 938/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 939/1000\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1512 - accuracy: 0.7823\n",
      "Epoch 940/1000\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 941/1000\n",
      "23/23 [==============================] - 0s 787us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 942/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 943/1000\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 944/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 945/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 946/1000\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 947/1000\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 948/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 949/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 950/1000\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 951/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 952/1000\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1511 - accuracy: 0.7823\n",
      "Epoch 953/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 954/1000\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 955/1000\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 956/1000\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 957/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 958/1000\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 959/1000\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 960/1000\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 961/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 962/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 963/1000\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 964/1000\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 965/1000\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 966/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 967/1000\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1510 - accuracy: 0.7823\n",
      "Epoch 968/1000\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 969/1000\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 970/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 971/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 972/1000\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 973/1000\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 974/1000\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 975/1000\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 976/1000\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 977/1000\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 978/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 979/1000\n",
      "23/23 [==============================] - 0s 787us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 980/1000\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 981/1000\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.1509 - accuracy: 0.7823\n",
      "Epoch 982/1000\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 983/1000\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 984/1000\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 985/1000\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 986/1000\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 987/1000\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 988/1000\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 989/1000\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 990/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 991/1000\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 992/1000\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 993/1000\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 994/1000\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 995/1000\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1508 - accuracy: 0.7823\n",
      "Epoch 996/1000\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1507 - accuracy: 0.7823\n",
      "Epoch 997/1000\n",
      "23/23 [==============================] - 0s 795us/step - loss: 0.1507 - accuracy: 0.7823\n",
      "Epoch 998/1000\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1507 - accuracy: 0.7823\n",
      "Epoch 999/1000\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1507 - accuracy: 0.7823\n",
      "Epoch 1000/1000\n",
      "23/23 [==============================] - 0s 751us/step - loss: 0.1507 - accuracy: 0.7823\n",
      "11/11 [==============================] - 0s 719us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_normalize, y_train_normalize, epochs=epochs)\n",
    "\n",
    "predict = model.predict(x_test_normalize)\n",
    "predict = np.round(predict)\n",
    "predict = predict.astype(int)\n",
    "predict = predict.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1_cf1 = confusion_matrix(y_test_normalize, predict)\n",
    "plot_cm(model1_cf1, 'Model 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Survived</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "Not Survived        1.0     1.0       1.0    204.0\n",
       "Survived            1.0     1.0       1.0    127.0\n",
       "accuracy            1.0     1.0       1.0      1.0\n",
       "macro avg           1.0     1.0       1.0    331.0\n",
       "weighted avg        1.0     1.0       1.0    331.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_report = classification_report(y_test_normalize, predict, output_dict=True, target_names=['Not Survived',\"Survived\"])\n",
    "pd.DataFrame(model1_report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Binary Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, input_size, learning_rate, epochs):\n",
    "        np.random.seed(42)\n",
    "        self.weights = np.random.uniform(-0.3,0.3, size=input_size+1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return self._activation_function(summation)\n",
    "\n",
    "    def _calculate_accuracy(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy * 100\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, label in zip(X_train, y_train):\n",
    "                prediction = self._predict(inputs)\n",
    "\n",
    "                # Update weights\n",
    "                error = label - prediction\n",
    "                self.weights[1:] += self.learning_rate * error * inputs\n",
    "                self.weights[0] += self.learning_rate * error\n",
    "\n",
    "            # Calculate training accuracy at each epoch\n",
    "            training_accuracy = self._calculate_accuracy(X_train, y_train)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}: Training Accuracy = {training_accuracy:.2f}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self._predict(inputs) for inputs in X_test]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data dinormalisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: Training Accuracy = 72.19%\n",
      "Epoch 2/1000: Training Accuracy = 78.23%\n",
      "Epoch 3/1000: Training Accuracy = 73.74%\n",
      "Epoch 4/1000: Training Accuracy = 78.09%\n",
      "Epoch 5/1000: Training Accuracy = 76.12%\n",
      "Epoch 6/1000: Training Accuracy = 78.23%\n",
      "Epoch 7/1000: Training Accuracy = 76.97%\n",
      "Epoch 8/1000: Training Accuracy = 79.35%\n",
      "Epoch 9/1000: Training Accuracy = 79.21%\n",
      "Epoch 10/1000: Training Accuracy = 74.72%\n",
      "Epoch 11/1000: Training Accuracy = 75.84%\n",
      "Epoch 12/1000: Training Accuracy = 76.54%\n",
      "Epoch 13/1000: Training Accuracy = 75.98%\n",
      "Epoch 14/1000: Training Accuracy = 80.48%\n",
      "Epoch 15/1000: Training Accuracy = 79.63%\n",
      "Epoch 16/1000: Training Accuracy = 79.07%\n",
      "Epoch 17/1000: Training Accuracy = 76.83%\n",
      "Epoch 18/1000: Training Accuracy = 79.07%\n",
      "Epoch 19/1000: Training Accuracy = 77.11%\n",
      "Epoch 20/1000: Training Accuracy = 80.34%\n",
      "Epoch 21/1000: Training Accuracy = 78.93%\n",
      "Epoch 22/1000: Training Accuracy = 74.72%\n",
      "Epoch 23/1000: Training Accuracy = 76.69%\n",
      "Epoch 24/1000: Training Accuracy = 78.37%\n",
      "Epoch 25/1000: Training Accuracy = 78.37%\n",
      "Epoch 26/1000: Training Accuracy = 80.06%\n",
      "Epoch 27/1000: Training Accuracy = 78.51%\n",
      "Epoch 28/1000: Training Accuracy = 78.23%\n",
      "Epoch 29/1000: Training Accuracy = 77.53%\n",
      "Epoch 30/1000: Training Accuracy = 78.79%\n",
      "Epoch 31/1000: Training Accuracy = 79.78%\n",
      "Epoch 32/1000: Training Accuracy = 79.07%\n",
      "Epoch 33/1000: Training Accuracy = 79.92%\n",
      "Epoch 34/1000: Training Accuracy = 75.14%\n",
      "Epoch 35/1000: Training Accuracy = 80.06%\n",
      "Epoch 36/1000: Training Accuracy = 76.26%\n",
      "Epoch 37/1000: Training Accuracy = 75.98%\n",
      "Epoch 38/1000: Training Accuracy = 78.37%\n",
      "Epoch 39/1000: Training Accuracy = 79.49%\n",
      "Epoch 40/1000: Training Accuracy = 77.95%\n",
      "Epoch 41/1000: Training Accuracy = 79.21%\n",
      "Epoch 42/1000: Training Accuracy = 76.83%\n",
      "Epoch 43/1000: Training Accuracy = 74.30%\n",
      "Epoch 44/1000: Training Accuracy = 76.97%\n",
      "Epoch 45/1000: Training Accuracy = 78.79%\n",
      "Epoch 46/1000: Training Accuracy = 76.26%\n",
      "Epoch 47/1000: Training Accuracy = 79.63%\n",
      "Epoch 48/1000: Training Accuracy = 79.49%\n",
      "Epoch 49/1000: Training Accuracy = 77.81%\n",
      "Epoch 50/1000: Training Accuracy = 79.21%\n",
      "Epoch 51/1000: Training Accuracy = 75.42%\n",
      "Epoch 52/1000: Training Accuracy = 80.06%\n",
      "Epoch 53/1000: Training Accuracy = 77.81%\n",
      "Epoch 54/1000: Training Accuracy = 79.07%\n",
      "Epoch 55/1000: Training Accuracy = 77.95%\n",
      "Epoch 56/1000: Training Accuracy = 77.95%\n",
      "Epoch 57/1000: Training Accuracy = 76.26%\n",
      "Epoch 58/1000: Training Accuracy = 71.77%\n",
      "Epoch 59/1000: Training Accuracy = 76.69%\n",
      "Epoch 60/1000: Training Accuracy = 75.00%\n",
      "Epoch 61/1000: Training Accuracy = 75.56%\n",
      "Epoch 62/1000: Training Accuracy = 79.21%\n",
      "Epoch 63/1000: Training Accuracy = 76.83%\n",
      "Epoch 64/1000: Training Accuracy = 78.51%\n",
      "Epoch 65/1000: Training Accuracy = 80.20%\n",
      "Epoch 66/1000: Training Accuracy = 78.37%\n",
      "Epoch 67/1000: Training Accuracy = 75.00%\n",
      "Epoch 68/1000: Training Accuracy = 77.95%\n",
      "Epoch 69/1000: Training Accuracy = 74.30%\n",
      "Epoch 70/1000: Training Accuracy = 74.16%\n",
      "Epoch 71/1000: Training Accuracy = 72.89%\n",
      "Epoch 72/1000: Training Accuracy = 79.21%\n",
      "Epoch 73/1000: Training Accuracy = 79.35%\n",
      "Epoch 74/1000: Training Accuracy = 79.92%\n",
      "Epoch 75/1000: Training Accuracy = 78.23%\n",
      "Epoch 76/1000: Training Accuracy = 74.44%\n",
      "Epoch 77/1000: Training Accuracy = 75.00%\n",
      "Epoch 78/1000: Training Accuracy = 76.97%\n",
      "Epoch 79/1000: Training Accuracy = 80.76%\n",
      "Epoch 80/1000: Training Accuracy = 78.79%\n",
      "Epoch 81/1000: Training Accuracy = 79.07%\n",
      "Epoch 82/1000: Training Accuracy = 80.76%\n",
      "Epoch 83/1000: Training Accuracy = 78.93%\n",
      "Epoch 84/1000: Training Accuracy = 78.51%\n",
      "Epoch 85/1000: Training Accuracy = 74.30%\n",
      "Epoch 86/1000: Training Accuracy = 73.74%\n",
      "Epoch 87/1000: Training Accuracy = 76.12%\n",
      "Epoch 88/1000: Training Accuracy = 80.34%\n",
      "Epoch 89/1000: Training Accuracy = 78.37%\n",
      "Epoch 90/1000: Training Accuracy = 77.81%\n",
      "Epoch 91/1000: Training Accuracy = 73.60%\n",
      "Epoch 92/1000: Training Accuracy = 75.98%\n",
      "Epoch 93/1000: Training Accuracy = 80.06%\n",
      "Epoch 94/1000: Training Accuracy = 72.89%\n",
      "Epoch 95/1000: Training Accuracy = 75.56%\n",
      "Epoch 96/1000: Training Accuracy = 78.51%\n",
      "Epoch 97/1000: Training Accuracy = 76.26%\n",
      "Epoch 98/1000: Training Accuracy = 76.40%\n",
      "Epoch 99/1000: Training Accuracy = 79.21%\n",
      "Epoch 100/1000: Training Accuracy = 79.35%\n",
      "Epoch 101/1000: Training Accuracy = 80.62%\n",
      "Epoch 102/1000: Training Accuracy = 78.79%\n",
      "Epoch 103/1000: Training Accuracy = 75.84%\n",
      "Epoch 104/1000: Training Accuracy = 75.28%\n",
      "Epoch 105/1000: Training Accuracy = 78.79%\n",
      "Epoch 106/1000: Training Accuracy = 79.07%\n",
      "Epoch 107/1000: Training Accuracy = 77.81%\n",
      "Epoch 108/1000: Training Accuracy = 79.21%\n",
      "Epoch 109/1000: Training Accuracy = 79.63%\n",
      "Epoch 110/1000: Training Accuracy = 78.65%\n",
      "Epoch 111/1000: Training Accuracy = 79.21%\n",
      "Epoch 112/1000: Training Accuracy = 78.65%\n",
      "Epoch 113/1000: Training Accuracy = 74.86%\n",
      "Epoch 114/1000: Training Accuracy = 79.49%\n",
      "Epoch 115/1000: Training Accuracy = 71.91%\n",
      "Epoch 116/1000: Training Accuracy = 77.95%\n",
      "Epoch 117/1000: Training Accuracy = 76.26%\n",
      "Epoch 118/1000: Training Accuracy = 76.40%\n",
      "Epoch 119/1000: Training Accuracy = 76.69%\n",
      "Epoch 120/1000: Training Accuracy = 78.93%\n",
      "Epoch 121/1000: Training Accuracy = 79.92%\n",
      "Epoch 122/1000: Training Accuracy = 76.54%\n",
      "Epoch 123/1000: Training Accuracy = 73.74%\n",
      "Epoch 124/1000: Training Accuracy = 78.23%\n",
      "Epoch 125/1000: Training Accuracy = 81.18%\n",
      "Epoch 126/1000: Training Accuracy = 80.06%\n",
      "Epoch 127/1000: Training Accuracy = 78.37%\n",
      "Epoch 128/1000: Training Accuracy = 79.07%\n",
      "Epoch 129/1000: Training Accuracy = 74.58%\n",
      "Epoch 130/1000: Training Accuracy = 79.21%\n",
      "Epoch 131/1000: Training Accuracy = 78.79%\n",
      "Epoch 132/1000: Training Accuracy = 79.49%\n",
      "Epoch 133/1000: Training Accuracy = 76.12%\n",
      "Epoch 134/1000: Training Accuracy = 80.48%\n",
      "Epoch 135/1000: Training Accuracy = 79.07%\n",
      "Epoch 136/1000: Training Accuracy = 79.63%\n",
      "Epoch 137/1000: Training Accuracy = 78.65%\n",
      "Epoch 138/1000: Training Accuracy = 73.88%\n",
      "Epoch 139/1000: Training Accuracy = 75.14%\n",
      "Epoch 140/1000: Training Accuracy = 74.72%\n",
      "Epoch 141/1000: Training Accuracy = 79.35%\n",
      "Epoch 142/1000: Training Accuracy = 79.21%\n",
      "Epoch 143/1000: Training Accuracy = 80.62%\n",
      "Epoch 144/1000: Training Accuracy = 78.65%\n",
      "Epoch 145/1000: Training Accuracy = 79.63%\n",
      "Epoch 146/1000: Training Accuracy = 76.40%\n",
      "Epoch 147/1000: Training Accuracy = 79.21%\n",
      "Epoch 148/1000: Training Accuracy = 77.67%\n",
      "Epoch 149/1000: Training Accuracy = 80.90%\n",
      "Epoch 150/1000: Training Accuracy = 77.81%\n",
      "Epoch 151/1000: Training Accuracy = 76.40%\n",
      "Epoch 152/1000: Training Accuracy = 79.21%\n",
      "Epoch 153/1000: Training Accuracy = 75.84%\n",
      "Epoch 154/1000: Training Accuracy = 78.93%\n",
      "Epoch 155/1000: Training Accuracy = 78.23%\n",
      "Epoch 156/1000: Training Accuracy = 74.86%\n",
      "Epoch 157/1000: Training Accuracy = 79.92%\n",
      "Epoch 158/1000: Training Accuracy = 79.21%\n",
      "Epoch 159/1000: Training Accuracy = 79.07%\n",
      "Epoch 160/1000: Training Accuracy = 78.93%\n",
      "Epoch 161/1000: Training Accuracy = 79.35%\n",
      "Epoch 162/1000: Training Accuracy = 76.69%\n",
      "Epoch 163/1000: Training Accuracy = 79.35%\n",
      "Epoch 164/1000: Training Accuracy = 78.51%\n",
      "Epoch 165/1000: Training Accuracy = 78.93%\n",
      "Epoch 166/1000: Training Accuracy = 80.76%\n",
      "Epoch 167/1000: Training Accuracy = 78.65%\n",
      "Epoch 168/1000: Training Accuracy = 78.93%\n",
      "Epoch 169/1000: Training Accuracy = 77.39%\n",
      "Epoch 170/1000: Training Accuracy = 77.25%\n",
      "Epoch 171/1000: Training Accuracy = 80.20%\n",
      "Epoch 172/1000: Training Accuracy = 75.14%\n",
      "Epoch 173/1000: Training Accuracy = 78.51%\n",
      "Epoch 174/1000: Training Accuracy = 79.21%\n",
      "Epoch 175/1000: Training Accuracy = 80.48%\n",
      "Epoch 176/1000: Training Accuracy = 81.04%\n",
      "Epoch 177/1000: Training Accuracy = 79.92%\n",
      "Epoch 178/1000: Training Accuracy = 80.06%\n",
      "Epoch 179/1000: Training Accuracy = 76.83%\n",
      "Epoch 180/1000: Training Accuracy = 73.74%\n",
      "Epoch 181/1000: Training Accuracy = 78.79%\n",
      "Epoch 182/1000: Training Accuracy = 79.07%\n",
      "Epoch 183/1000: Training Accuracy = 80.20%\n",
      "Epoch 184/1000: Training Accuracy = 74.44%\n",
      "Epoch 185/1000: Training Accuracy = 79.21%\n",
      "Epoch 186/1000: Training Accuracy = 80.90%\n",
      "Epoch 187/1000: Training Accuracy = 79.21%\n",
      "Epoch 188/1000: Training Accuracy = 75.28%\n",
      "Epoch 189/1000: Training Accuracy = 80.06%\n",
      "Epoch 190/1000: Training Accuracy = 73.60%\n",
      "Epoch 191/1000: Training Accuracy = 73.46%\n",
      "Epoch 192/1000: Training Accuracy = 79.63%\n",
      "Epoch 193/1000: Training Accuracy = 76.83%\n",
      "Epoch 194/1000: Training Accuracy = 71.63%\n",
      "Epoch 195/1000: Training Accuracy = 73.60%\n",
      "Epoch 196/1000: Training Accuracy = 74.86%\n",
      "Epoch 197/1000: Training Accuracy = 72.61%\n",
      "Epoch 198/1000: Training Accuracy = 79.35%\n",
      "Epoch 199/1000: Training Accuracy = 77.53%\n",
      "Epoch 200/1000: Training Accuracy = 75.42%\n",
      "Epoch 201/1000: Training Accuracy = 77.95%\n",
      "Epoch 202/1000: Training Accuracy = 76.54%\n",
      "Epoch 203/1000: Training Accuracy = 79.07%\n",
      "Epoch 204/1000: Training Accuracy = 79.07%\n",
      "Epoch 205/1000: Training Accuracy = 79.78%\n",
      "Epoch 206/1000: Training Accuracy = 75.14%\n",
      "Epoch 207/1000: Training Accuracy = 79.07%\n",
      "Epoch 208/1000: Training Accuracy = 75.28%\n",
      "Epoch 209/1000: Training Accuracy = 77.53%\n",
      "Epoch 210/1000: Training Accuracy = 78.09%\n",
      "Epoch 211/1000: Training Accuracy = 79.78%\n",
      "Epoch 212/1000: Training Accuracy = 74.44%\n",
      "Epoch 213/1000: Training Accuracy = 79.92%\n",
      "Epoch 214/1000: Training Accuracy = 72.47%\n",
      "Epoch 215/1000: Training Accuracy = 75.00%\n",
      "Epoch 216/1000: Training Accuracy = 78.51%\n",
      "Epoch 217/1000: Training Accuracy = 79.35%\n",
      "Epoch 218/1000: Training Accuracy = 75.84%\n",
      "Epoch 219/1000: Training Accuracy = 79.35%\n",
      "Epoch 220/1000: Training Accuracy = 79.21%\n",
      "Epoch 221/1000: Training Accuracy = 78.51%\n",
      "Epoch 222/1000: Training Accuracy = 75.98%\n",
      "Epoch 223/1000: Training Accuracy = 75.56%\n",
      "Epoch 224/1000: Training Accuracy = 75.14%\n",
      "Epoch 225/1000: Training Accuracy = 79.78%\n",
      "Epoch 226/1000: Training Accuracy = 72.19%\n",
      "Epoch 227/1000: Training Accuracy = 76.12%\n",
      "Epoch 228/1000: Training Accuracy = 79.21%\n",
      "Epoch 229/1000: Training Accuracy = 73.88%\n",
      "Epoch 230/1000: Training Accuracy = 78.93%\n",
      "Epoch 231/1000: Training Accuracy = 79.35%\n",
      "Epoch 232/1000: Training Accuracy = 73.74%\n",
      "Epoch 233/1000: Training Accuracy = 76.40%\n",
      "Epoch 234/1000: Training Accuracy = 79.07%\n",
      "Epoch 235/1000: Training Accuracy = 79.63%\n",
      "Epoch 236/1000: Training Accuracy = 78.93%\n",
      "Epoch 237/1000: Training Accuracy = 73.46%\n",
      "Epoch 238/1000: Training Accuracy = 78.09%\n",
      "Epoch 239/1000: Training Accuracy = 76.54%\n",
      "Epoch 240/1000: Training Accuracy = 76.54%\n",
      "Epoch 241/1000: Training Accuracy = 79.63%\n",
      "Epoch 242/1000: Training Accuracy = 80.06%\n",
      "Epoch 243/1000: Training Accuracy = 74.16%\n",
      "Epoch 244/1000: Training Accuracy = 79.07%\n",
      "Epoch 245/1000: Training Accuracy = 74.44%\n",
      "Epoch 246/1000: Training Accuracy = 79.78%\n",
      "Epoch 247/1000: Training Accuracy = 78.79%\n",
      "Epoch 248/1000: Training Accuracy = 75.98%\n",
      "Epoch 249/1000: Training Accuracy = 73.88%\n",
      "Epoch 250/1000: Training Accuracy = 72.33%\n",
      "Epoch 251/1000: Training Accuracy = 80.06%\n",
      "Epoch 252/1000: Training Accuracy = 75.98%\n",
      "Epoch 253/1000: Training Accuracy = 77.25%\n",
      "Epoch 254/1000: Training Accuracy = 80.90%\n",
      "Epoch 255/1000: Training Accuracy = 73.74%\n",
      "Epoch 256/1000: Training Accuracy = 80.34%\n",
      "Epoch 257/1000: Training Accuracy = 74.72%\n",
      "Epoch 258/1000: Training Accuracy = 73.60%\n",
      "Epoch 259/1000: Training Accuracy = 78.65%\n",
      "Epoch 260/1000: Training Accuracy = 78.79%\n",
      "Epoch 261/1000: Training Accuracy = 80.20%\n",
      "Epoch 262/1000: Training Accuracy = 80.20%\n",
      "Epoch 263/1000: Training Accuracy = 74.02%\n",
      "Epoch 264/1000: Training Accuracy = 79.63%\n",
      "Epoch 265/1000: Training Accuracy = 77.53%\n",
      "Epoch 266/1000: Training Accuracy = 76.69%\n",
      "Epoch 267/1000: Training Accuracy = 77.39%\n",
      "Epoch 268/1000: Training Accuracy = 80.34%\n",
      "Epoch 269/1000: Training Accuracy = 74.44%\n",
      "Epoch 270/1000: Training Accuracy = 79.49%\n",
      "Epoch 271/1000: Training Accuracy = 75.42%\n",
      "Epoch 272/1000: Training Accuracy = 76.54%\n",
      "Epoch 273/1000: Training Accuracy = 79.78%\n",
      "Epoch 274/1000: Training Accuracy = 80.06%\n",
      "Epoch 275/1000: Training Accuracy = 72.19%\n",
      "Epoch 276/1000: Training Accuracy = 77.67%\n",
      "Epoch 277/1000: Training Accuracy = 78.09%\n",
      "Epoch 278/1000: Training Accuracy = 75.98%\n",
      "Epoch 279/1000: Training Accuracy = 78.37%\n",
      "Epoch 280/1000: Training Accuracy = 79.63%\n",
      "Epoch 281/1000: Training Accuracy = 79.63%\n",
      "Epoch 282/1000: Training Accuracy = 76.54%\n",
      "Epoch 283/1000: Training Accuracy = 80.06%\n",
      "Epoch 284/1000: Training Accuracy = 75.14%\n",
      "Epoch 285/1000: Training Accuracy = 77.11%\n",
      "Epoch 286/1000: Training Accuracy = 76.26%\n",
      "Epoch 287/1000: Training Accuracy = 75.98%\n",
      "Epoch 288/1000: Training Accuracy = 79.35%\n",
      "Epoch 289/1000: Training Accuracy = 79.49%\n",
      "Epoch 290/1000: Training Accuracy = 73.46%\n",
      "Epoch 291/1000: Training Accuracy = 78.79%\n",
      "Epoch 292/1000: Training Accuracy = 79.21%\n",
      "Epoch 293/1000: Training Accuracy = 78.93%\n",
      "Epoch 294/1000: Training Accuracy = 78.65%\n",
      "Epoch 295/1000: Training Accuracy = 73.88%\n",
      "Epoch 296/1000: Training Accuracy = 77.39%\n",
      "Epoch 297/1000: Training Accuracy = 76.54%\n",
      "Epoch 298/1000: Training Accuracy = 76.12%\n",
      "Epoch 299/1000: Training Accuracy = 79.63%\n",
      "Epoch 300/1000: Training Accuracy = 75.14%\n",
      "Epoch 301/1000: Training Accuracy = 79.21%\n",
      "Epoch 302/1000: Training Accuracy = 80.20%\n",
      "Epoch 303/1000: Training Accuracy = 77.81%\n",
      "Epoch 304/1000: Training Accuracy = 76.69%\n",
      "Epoch 305/1000: Training Accuracy = 79.78%\n",
      "Epoch 306/1000: Training Accuracy = 78.23%\n",
      "Epoch 307/1000: Training Accuracy = 74.58%\n",
      "Epoch 308/1000: Training Accuracy = 78.37%\n",
      "Epoch 309/1000: Training Accuracy = 78.79%\n",
      "Epoch 310/1000: Training Accuracy = 72.33%\n",
      "Epoch 311/1000: Training Accuracy = 74.02%\n",
      "Epoch 312/1000: Training Accuracy = 79.21%\n",
      "Epoch 313/1000: Training Accuracy = 79.92%\n",
      "Epoch 314/1000: Training Accuracy = 75.00%\n",
      "Epoch 315/1000: Training Accuracy = 78.51%\n",
      "Epoch 316/1000: Training Accuracy = 79.21%\n",
      "Epoch 317/1000: Training Accuracy = 75.56%\n",
      "Epoch 318/1000: Training Accuracy = 79.78%\n",
      "Epoch 319/1000: Training Accuracy = 78.93%\n",
      "Epoch 320/1000: Training Accuracy = 75.14%\n",
      "Epoch 321/1000: Training Accuracy = 76.83%\n",
      "Epoch 322/1000: Training Accuracy = 72.61%\n",
      "Epoch 323/1000: Training Accuracy = 78.37%\n",
      "Epoch 324/1000: Training Accuracy = 77.81%\n",
      "Epoch 325/1000: Training Accuracy = 78.51%\n",
      "Epoch 326/1000: Training Accuracy = 79.35%\n",
      "Epoch 327/1000: Training Accuracy = 75.14%\n",
      "Epoch 328/1000: Training Accuracy = 78.37%\n",
      "Epoch 329/1000: Training Accuracy = 79.07%\n",
      "Epoch 330/1000: Training Accuracy = 80.06%\n",
      "Epoch 331/1000: Training Accuracy = 79.35%\n",
      "Epoch 332/1000: Training Accuracy = 78.93%\n",
      "Epoch 333/1000: Training Accuracy = 75.28%\n",
      "Epoch 334/1000: Training Accuracy = 76.26%\n",
      "Epoch 335/1000: Training Accuracy = 73.74%\n",
      "Epoch 336/1000: Training Accuracy = 77.11%\n",
      "Epoch 337/1000: Training Accuracy = 74.30%\n",
      "Epoch 338/1000: Training Accuracy = 75.00%\n",
      "Epoch 339/1000: Training Accuracy = 78.65%\n",
      "Epoch 340/1000: Training Accuracy = 76.12%\n",
      "Epoch 341/1000: Training Accuracy = 74.44%\n",
      "Epoch 342/1000: Training Accuracy = 78.23%\n",
      "Epoch 343/1000: Training Accuracy = 76.26%\n",
      "Epoch 344/1000: Training Accuracy = 78.37%\n",
      "Epoch 345/1000: Training Accuracy = 79.63%\n",
      "Epoch 346/1000: Training Accuracy = 75.70%\n",
      "Epoch 347/1000: Training Accuracy = 79.49%\n",
      "Epoch 348/1000: Training Accuracy = 79.49%\n",
      "Epoch 349/1000: Training Accuracy = 78.65%\n",
      "Epoch 350/1000: Training Accuracy = 77.81%\n",
      "Epoch 351/1000: Training Accuracy = 79.21%\n",
      "Epoch 352/1000: Training Accuracy = 80.76%\n",
      "Epoch 353/1000: Training Accuracy = 80.20%\n",
      "Epoch 354/1000: Training Accuracy = 78.23%\n",
      "Epoch 355/1000: Training Accuracy = 79.21%\n",
      "Epoch 356/1000: Training Accuracy = 80.06%\n",
      "Epoch 357/1000: Training Accuracy = 78.79%\n",
      "Epoch 358/1000: Training Accuracy = 79.35%\n",
      "Epoch 359/1000: Training Accuracy = 74.58%\n",
      "Epoch 360/1000: Training Accuracy = 72.19%\n",
      "Epoch 361/1000: Training Accuracy = 71.21%\n",
      "Epoch 362/1000: Training Accuracy = 75.84%\n",
      "Epoch 363/1000: Training Accuracy = 72.47%\n",
      "Epoch 364/1000: Training Accuracy = 76.40%\n",
      "Epoch 365/1000: Training Accuracy = 78.65%\n",
      "Epoch 366/1000: Training Accuracy = 79.63%\n",
      "Epoch 367/1000: Training Accuracy = 79.21%\n",
      "Epoch 368/1000: Training Accuracy = 77.53%\n",
      "Epoch 369/1000: Training Accuracy = 78.65%\n",
      "Epoch 370/1000: Training Accuracy = 78.93%\n",
      "Epoch 371/1000: Training Accuracy = 76.12%\n",
      "Epoch 372/1000: Training Accuracy = 79.92%\n",
      "Epoch 373/1000: Training Accuracy = 73.17%\n",
      "Epoch 374/1000: Training Accuracy = 78.65%\n",
      "Epoch 375/1000: Training Accuracy = 79.35%\n",
      "Epoch 376/1000: Training Accuracy = 77.39%\n",
      "Epoch 377/1000: Training Accuracy = 74.58%\n",
      "Epoch 378/1000: Training Accuracy = 78.65%\n",
      "Epoch 379/1000: Training Accuracy = 76.26%\n",
      "Epoch 380/1000: Training Accuracy = 80.62%\n",
      "Epoch 381/1000: Training Accuracy = 79.21%\n",
      "Epoch 382/1000: Training Accuracy = 75.70%\n",
      "Epoch 383/1000: Training Accuracy = 78.37%\n",
      "Epoch 384/1000: Training Accuracy = 73.17%\n",
      "Epoch 385/1000: Training Accuracy = 79.63%\n",
      "Epoch 386/1000: Training Accuracy = 80.34%\n",
      "Epoch 387/1000: Training Accuracy = 79.78%\n",
      "Epoch 388/1000: Training Accuracy = 79.21%\n",
      "Epoch 389/1000: Training Accuracy = 78.65%\n",
      "Epoch 390/1000: Training Accuracy = 78.65%\n",
      "Epoch 391/1000: Training Accuracy = 74.86%\n",
      "Epoch 392/1000: Training Accuracy = 78.51%\n",
      "Epoch 393/1000: Training Accuracy = 76.54%\n",
      "Epoch 394/1000: Training Accuracy = 80.20%\n",
      "Epoch 395/1000: Training Accuracy = 78.65%\n",
      "Epoch 396/1000: Training Accuracy = 80.06%\n",
      "Epoch 397/1000: Training Accuracy = 79.07%\n",
      "Epoch 398/1000: Training Accuracy = 79.78%\n",
      "Epoch 399/1000: Training Accuracy = 73.17%\n",
      "Epoch 400/1000: Training Accuracy = 79.35%\n",
      "Epoch 401/1000: Training Accuracy = 79.92%\n",
      "Epoch 402/1000: Training Accuracy = 75.00%\n",
      "Epoch 403/1000: Training Accuracy = 77.95%\n",
      "Epoch 404/1000: Training Accuracy = 79.35%\n",
      "Epoch 405/1000: Training Accuracy = 79.35%\n",
      "Epoch 406/1000: Training Accuracy = 80.34%\n",
      "Epoch 407/1000: Training Accuracy = 78.93%\n",
      "Epoch 408/1000: Training Accuracy = 73.88%\n",
      "Epoch 409/1000: Training Accuracy = 78.37%\n",
      "Epoch 410/1000: Training Accuracy = 78.79%\n",
      "Epoch 411/1000: Training Accuracy = 71.91%\n",
      "Epoch 412/1000: Training Accuracy = 73.88%\n",
      "Epoch 413/1000: Training Accuracy = 72.19%\n",
      "Epoch 414/1000: Training Accuracy = 79.92%\n",
      "Epoch 415/1000: Training Accuracy = 79.21%\n",
      "Epoch 416/1000: Training Accuracy = 75.28%\n",
      "Epoch 417/1000: Training Accuracy = 75.42%\n",
      "Epoch 418/1000: Training Accuracy = 75.14%\n",
      "Epoch 419/1000: Training Accuracy = 79.63%\n",
      "Epoch 420/1000: Training Accuracy = 79.21%\n",
      "Epoch 421/1000: Training Accuracy = 78.93%\n",
      "Epoch 422/1000: Training Accuracy = 77.67%\n",
      "Epoch 423/1000: Training Accuracy = 77.25%\n",
      "Epoch 424/1000: Training Accuracy = 80.20%\n",
      "Epoch 425/1000: Training Accuracy = 76.40%\n",
      "Epoch 426/1000: Training Accuracy = 79.07%\n",
      "Epoch 427/1000: Training Accuracy = 75.56%\n",
      "Epoch 428/1000: Training Accuracy = 79.35%\n",
      "Epoch 429/1000: Training Accuracy = 79.35%\n",
      "Epoch 430/1000: Training Accuracy = 80.20%\n",
      "Epoch 431/1000: Training Accuracy = 78.93%\n",
      "Epoch 432/1000: Training Accuracy = 79.63%\n",
      "Epoch 433/1000: Training Accuracy = 74.02%\n",
      "Epoch 434/1000: Training Accuracy = 79.07%\n",
      "Epoch 435/1000: Training Accuracy = 78.23%\n",
      "Epoch 436/1000: Training Accuracy = 75.42%\n",
      "Epoch 437/1000: Training Accuracy = 77.95%\n",
      "Epoch 438/1000: Training Accuracy = 74.44%\n",
      "Epoch 439/1000: Training Accuracy = 74.86%\n",
      "Epoch 440/1000: Training Accuracy = 78.93%\n",
      "Epoch 441/1000: Training Accuracy = 76.26%\n",
      "Epoch 442/1000: Training Accuracy = 79.63%\n",
      "Epoch 443/1000: Training Accuracy = 75.14%\n",
      "Epoch 444/1000: Training Accuracy = 79.78%\n",
      "Epoch 445/1000: Training Accuracy = 79.63%\n",
      "Epoch 446/1000: Training Accuracy = 74.02%\n",
      "Epoch 447/1000: Training Accuracy = 79.63%\n",
      "Epoch 448/1000: Training Accuracy = 79.07%\n",
      "Epoch 449/1000: Training Accuracy = 74.86%\n",
      "Epoch 450/1000: Training Accuracy = 79.49%\n",
      "Epoch 451/1000: Training Accuracy = 79.63%\n",
      "Epoch 452/1000: Training Accuracy = 79.63%\n",
      "Epoch 453/1000: Training Accuracy = 76.26%\n",
      "Epoch 454/1000: Training Accuracy = 79.78%\n",
      "Epoch 455/1000: Training Accuracy = 79.49%\n",
      "Epoch 456/1000: Training Accuracy = 77.81%\n",
      "Epoch 457/1000: Training Accuracy = 79.07%\n",
      "Epoch 458/1000: Training Accuracy = 78.23%\n",
      "Epoch 459/1000: Training Accuracy = 79.07%\n",
      "Epoch 460/1000: Training Accuracy = 73.74%\n",
      "Epoch 461/1000: Training Accuracy = 79.78%\n",
      "Epoch 462/1000: Training Accuracy = 78.93%\n",
      "Epoch 463/1000: Training Accuracy = 74.44%\n",
      "Epoch 464/1000: Training Accuracy = 75.00%\n",
      "Epoch 465/1000: Training Accuracy = 79.92%\n",
      "Epoch 466/1000: Training Accuracy = 79.07%\n",
      "Epoch 467/1000: Training Accuracy = 75.98%\n",
      "Epoch 468/1000: Training Accuracy = 73.03%\n",
      "Epoch 469/1000: Training Accuracy = 79.07%\n",
      "Epoch 470/1000: Training Accuracy = 77.81%\n",
      "Epoch 471/1000: Training Accuracy = 80.48%\n",
      "Epoch 472/1000: Training Accuracy = 78.23%\n",
      "Epoch 473/1000: Training Accuracy = 74.30%\n",
      "Epoch 474/1000: Training Accuracy = 74.44%\n",
      "Epoch 475/1000: Training Accuracy = 78.65%\n",
      "Epoch 476/1000: Training Accuracy = 77.53%\n",
      "Epoch 477/1000: Training Accuracy = 78.23%\n",
      "Epoch 478/1000: Training Accuracy = 77.95%\n",
      "Epoch 479/1000: Training Accuracy = 78.65%\n",
      "Epoch 480/1000: Training Accuracy = 78.93%\n",
      "Epoch 481/1000: Training Accuracy = 79.07%\n",
      "Epoch 482/1000: Training Accuracy = 73.74%\n",
      "Epoch 483/1000: Training Accuracy = 80.62%\n",
      "Epoch 484/1000: Training Accuracy = 78.37%\n",
      "Epoch 485/1000: Training Accuracy = 78.79%\n",
      "Epoch 486/1000: Training Accuracy = 73.46%\n",
      "Epoch 487/1000: Training Accuracy = 79.35%\n",
      "Epoch 488/1000: Training Accuracy = 76.12%\n",
      "Epoch 489/1000: Training Accuracy = 75.14%\n",
      "Epoch 490/1000: Training Accuracy = 75.28%\n",
      "Epoch 491/1000: Training Accuracy = 79.49%\n",
      "Epoch 492/1000: Training Accuracy = 78.93%\n",
      "Epoch 493/1000: Training Accuracy = 79.07%\n",
      "Epoch 494/1000: Training Accuracy = 79.63%\n",
      "Epoch 495/1000: Training Accuracy = 77.95%\n",
      "Epoch 496/1000: Training Accuracy = 76.69%\n",
      "Epoch 497/1000: Training Accuracy = 74.72%\n",
      "Epoch 498/1000: Training Accuracy = 79.49%\n",
      "Epoch 499/1000: Training Accuracy = 77.11%\n",
      "Epoch 500/1000: Training Accuracy = 80.20%\n",
      "Epoch 501/1000: Training Accuracy = 74.02%\n",
      "Epoch 502/1000: Training Accuracy = 76.26%\n",
      "Epoch 503/1000: Training Accuracy = 73.46%\n",
      "Epoch 504/1000: Training Accuracy = 79.35%\n",
      "Epoch 505/1000: Training Accuracy = 79.35%\n",
      "Epoch 506/1000: Training Accuracy = 80.20%\n",
      "Epoch 507/1000: Training Accuracy = 78.93%\n",
      "Epoch 508/1000: Training Accuracy = 79.63%\n",
      "Epoch 509/1000: Training Accuracy = 74.02%\n",
      "Epoch 510/1000: Training Accuracy = 76.54%\n",
      "Epoch 511/1000: Training Accuracy = 74.44%\n",
      "Epoch 512/1000: Training Accuracy = 78.37%\n",
      "Epoch 513/1000: Training Accuracy = 74.30%\n",
      "Epoch 514/1000: Training Accuracy = 77.25%\n",
      "Epoch 515/1000: Training Accuracy = 76.12%\n",
      "Epoch 516/1000: Training Accuracy = 75.98%\n",
      "Epoch 517/1000: Training Accuracy = 79.07%\n",
      "Epoch 518/1000: Training Accuracy = 78.93%\n",
      "Epoch 519/1000: Training Accuracy = 79.92%\n",
      "Epoch 520/1000: Training Accuracy = 78.65%\n",
      "Epoch 521/1000: Training Accuracy = 72.33%\n",
      "Epoch 522/1000: Training Accuracy = 73.03%\n",
      "Epoch 523/1000: Training Accuracy = 80.20%\n",
      "Epoch 524/1000: Training Accuracy = 72.89%\n",
      "Epoch 525/1000: Training Accuracy = 79.49%\n",
      "Epoch 526/1000: Training Accuracy = 79.78%\n",
      "Epoch 527/1000: Training Accuracy = 79.78%\n",
      "Epoch 528/1000: Training Accuracy = 78.65%\n",
      "Epoch 529/1000: Training Accuracy = 73.74%\n",
      "Epoch 530/1000: Training Accuracy = 78.09%\n",
      "Epoch 531/1000: Training Accuracy = 80.62%\n",
      "Epoch 532/1000: Training Accuracy = 76.83%\n",
      "Epoch 533/1000: Training Accuracy = 79.07%\n",
      "Epoch 534/1000: Training Accuracy = 79.78%\n",
      "Epoch 535/1000: Training Accuracy = 80.06%\n",
      "Epoch 536/1000: Training Accuracy = 77.81%\n",
      "Epoch 537/1000: Training Accuracy = 76.54%\n",
      "Epoch 538/1000: Training Accuracy = 79.78%\n",
      "Epoch 539/1000: Training Accuracy = 78.23%\n",
      "Epoch 540/1000: Training Accuracy = 74.44%\n",
      "Epoch 541/1000: Training Accuracy = 79.21%\n",
      "Epoch 542/1000: Training Accuracy = 78.37%\n",
      "Epoch 543/1000: Training Accuracy = 76.97%\n",
      "Epoch 544/1000: Training Accuracy = 78.93%\n",
      "Epoch 545/1000: Training Accuracy = 78.93%\n",
      "Epoch 546/1000: Training Accuracy = 75.00%\n",
      "Epoch 547/1000: Training Accuracy = 78.79%\n",
      "Epoch 548/1000: Training Accuracy = 79.07%\n",
      "Epoch 549/1000: Training Accuracy = 78.51%\n",
      "Epoch 550/1000: Training Accuracy = 80.62%\n",
      "Epoch 551/1000: Training Accuracy = 73.46%\n",
      "Epoch 552/1000: Training Accuracy = 77.81%\n",
      "Epoch 553/1000: Training Accuracy = 75.84%\n",
      "Epoch 554/1000: Training Accuracy = 74.58%\n",
      "Epoch 555/1000: Training Accuracy = 73.88%\n",
      "Epoch 556/1000: Training Accuracy = 74.02%\n",
      "Epoch 557/1000: Training Accuracy = 74.44%\n",
      "Epoch 558/1000: Training Accuracy = 77.53%\n",
      "Epoch 559/1000: Training Accuracy = 78.37%\n",
      "Epoch 560/1000: Training Accuracy = 79.21%\n",
      "Epoch 561/1000: Training Accuracy = 75.56%\n",
      "Epoch 562/1000: Training Accuracy = 73.46%\n",
      "Epoch 563/1000: Training Accuracy = 79.63%\n",
      "Epoch 564/1000: Training Accuracy = 75.98%\n",
      "Epoch 565/1000: Training Accuracy = 79.07%\n",
      "Epoch 566/1000: Training Accuracy = 79.49%\n",
      "Epoch 567/1000: Training Accuracy = 78.37%\n",
      "Epoch 568/1000: Training Accuracy = 78.51%\n",
      "Epoch 569/1000: Training Accuracy = 75.70%\n",
      "Epoch 570/1000: Training Accuracy = 77.53%\n",
      "Epoch 571/1000: Training Accuracy = 79.63%\n",
      "Epoch 572/1000: Training Accuracy = 79.35%\n",
      "Epoch 573/1000: Training Accuracy = 74.16%\n",
      "Epoch 574/1000: Training Accuracy = 78.93%\n",
      "Epoch 575/1000: Training Accuracy = 79.35%\n",
      "Epoch 576/1000: Training Accuracy = 78.23%\n",
      "Epoch 577/1000: Training Accuracy = 79.78%\n",
      "Epoch 578/1000: Training Accuracy = 80.20%\n",
      "Epoch 579/1000: Training Accuracy = 77.95%\n",
      "Epoch 580/1000: Training Accuracy = 79.21%\n",
      "Epoch 581/1000: Training Accuracy = 80.20%\n",
      "Epoch 582/1000: Training Accuracy = 71.77%\n",
      "Epoch 583/1000: Training Accuracy = 78.37%\n",
      "Epoch 584/1000: Training Accuracy = 79.49%\n",
      "Epoch 585/1000: Training Accuracy = 79.35%\n",
      "Epoch 586/1000: Training Accuracy = 79.63%\n",
      "Epoch 587/1000: Training Accuracy = 79.07%\n",
      "Epoch 588/1000: Training Accuracy = 79.49%\n",
      "Epoch 589/1000: Training Accuracy = 77.95%\n",
      "Epoch 590/1000: Training Accuracy = 74.44%\n",
      "Epoch 591/1000: Training Accuracy = 79.07%\n",
      "Epoch 592/1000: Training Accuracy = 79.63%\n",
      "Epoch 593/1000: Training Accuracy = 79.63%\n",
      "Epoch 594/1000: Training Accuracy = 73.46%\n",
      "Epoch 595/1000: Training Accuracy = 79.35%\n",
      "Epoch 596/1000: Training Accuracy = 79.35%\n",
      "Epoch 597/1000: Training Accuracy = 74.16%\n",
      "Epoch 598/1000: Training Accuracy = 73.46%\n",
      "Epoch 599/1000: Training Accuracy = 76.97%\n",
      "Epoch 600/1000: Training Accuracy = 76.97%\n",
      "Epoch 601/1000: Training Accuracy = 77.95%\n",
      "Epoch 602/1000: Training Accuracy = 78.37%\n",
      "Epoch 603/1000: Training Accuracy = 79.21%\n",
      "Epoch 604/1000: Training Accuracy = 79.78%\n",
      "Epoch 605/1000: Training Accuracy = 79.49%\n",
      "Epoch 606/1000: Training Accuracy = 77.67%\n",
      "Epoch 607/1000: Training Accuracy = 79.35%\n",
      "Epoch 608/1000: Training Accuracy = 72.61%\n",
      "Epoch 609/1000: Training Accuracy = 79.92%\n",
      "Epoch 610/1000: Training Accuracy = 78.51%\n",
      "Epoch 611/1000: Training Accuracy = 78.09%\n",
      "Epoch 612/1000: Training Accuracy = 75.28%\n",
      "Epoch 613/1000: Training Accuracy = 72.75%\n",
      "Epoch 614/1000: Training Accuracy = 79.35%\n",
      "Epoch 615/1000: Training Accuracy = 80.34%\n",
      "Epoch 616/1000: Training Accuracy = 72.75%\n",
      "Epoch 617/1000: Training Accuracy = 80.48%\n",
      "Epoch 618/1000: Training Accuracy = 73.60%\n",
      "Epoch 619/1000: Training Accuracy = 79.92%\n",
      "Epoch 620/1000: Training Accuracy = 79.35%\n",
      "Epoch 621/1000: Training Accuracy = 78.23%\n",
      "Epoch 622/1000: Training Accuracy = 78.93%\n",
      "Epoch 623/1000: Training Accuracy = 73.17%\n",
      "Epoch 624/1000: Training Accuracy = 75.98%\n",
      "Epoch 625/1000: Training Accuracy = 80.20%\n",
      "Epoch 626/1000: Training Accuracy = 80.48%\n",
      "Epoch 627/1000: Training Accuracy = 77.67%\n",
      "Epoch 628/1000: Training Accuracy = 73.46%\n",
      "Epoch 629/1000: Training Accuracy = 76.54%\n",
      "Epoch 630/1000: Training Accuracy = 78.93%\n",
      "Epoch 631/1000: Training Accuracy = 79.21%\n",
      "Epoch 632/1000: Training Accuracy = 72.33%\n",
      "Epoch 633/1000: Training Accuracy = 79.78%\n",
      "Epoch 634/1000: Training Accuracy = 79.07%\n",
      "Epoch 635/1000: Training Accuracy = 78.09%\n",
      "Epoch 636/1000: Training Accuracy = 71.49%\n",
      "Epoch 637/1000: Training Accuracy = 75.00%\n",
      "Epoch 638/1000: Training Accuracy = 79.07%\n",
      "Epoch 639/1000: Training Accuracy = 76.83%\n",
      "Epoch 640/1000: Training Accuracy = 78.93%\n",
      "Epoch 641/1000: Training Accuracy = 74.72%\n",
      "Epoch 642/1000: Training Accuracy = 76.54%\n",
      "Epoch 643/1000: Training Accuracy = 74.44%\n",
      "Epoch 644/1000: Training Accuracy = 71.63%\n",
      "Epoch 645/1000: Training Accuracy = 77.81%\n",
      "Epoch 646/1000: Training Accuracy = 79.49%\n",
      "Epoch 647/1000: Training Accuracy = 74.72%\n",
      "Epoch 648/1000: Training Accuracy = 79.21%\n",
      "Epoch 649/1000: Training Accuracy = 79.35%\n",
      "Epoch 650/1000: Training Accuracy = 80.62%\n",
      "Epoch 651/1000: Training Accuracy = 76.69%\n",
      "Epoch 652/1000: Training Accuracy = 78.51%\n",
      "Epoch 653/1000: Training Accuracy = 77.81%\n",
      "Epoch 654/1000: Training Accuracy = 78.23%\n",
      "Epoch 655/1000: Training Accuracy = 75.00%\n",
      "Epoch 656/1000: Training Accuracy = 76.26%\n",
      "Epoch 657/1000: Training Accuracy = 79.07%\n",
      "Epoch 658/1000: Training Accuracy = 76.12%\n",
      "Epoch 659/1000: Training Accuracy = 76.26%\n",
      "Epoch 660/1000: Training Accuracy = 76.26%\n",
      "Epoch 661/1000: Training Accuracy = 80.34%\n",
      "Epoch 662/1000: Training Accuracy = 78.51%\n",
      "Epoch 663/1000: Training Accuracy = 76.40%\n",
      "Epoch 664/1000: Training Accuracy = 72.47%\n",
      "Epoch 665/1000: Training Accuracy = 79.21%\n",
      "Epoch 666/1000: Training Accuracy = 77.39%\n",
      "Epoch 667/1000: Training Accuracy = 75.14%\n",
      "Epoch 668/1000: Training Accuracy = 78.51%\n",
      "Epoch 669/1000: Training Accuracy = 79.63%\n",
      "Epoch 670/1000: Training Accuracy = 75.00%\n",
      "Epoch 671/1000: Training Accuracy = 76.26%\n",
      "Epoch 672/1000: Training Accuracy = 78.79%\n",
      "Epoch 673/1000: Training Accuracy = 79.49%\n",
      "Epoch 674/1000: Training Accuracy = 73.31%\n",
      "Epoch 675/1000: Training Accuracy = 79.21%\n",
      "Epoch 676/1000: Training Accuracy = 76.12%\n",
      "Epoch 677/1000: Training Accuracy = 74.30%\n",
      "Epoch 678/1000: Training Accuracy = 74.44%\n",
      "Epoch 679/1000: Training Accuracy = 79.78%\n",
      "Epoch 680/1000: Training Accuracy = 76.26%\n",
      "Epoch 681/1000: Training Accuracy = 74.72%\n",
      "Epoch 682/1000: Training Accuracy = 73.60%\n",
      "Epoch 683/1000: Training Accuracy = 76.69%\n",
      "Epoch 684/1000: Training Accuracy = 73.60%\n",
      "Epoch 685/1000: Training Accuracy = 74.58%\n",
      "Epoch 686/1000: Training Accuracy = 79.78%\n",
      "Epoch 687/1000: Training Accuracy = 78.37%\n",
      "Epoch 688/1000: Training Accuracy = 79.07%\n",
      "Epoch 689/1000: Training Accuracy = 75.42%\n",
      "Epoch 690/1000: Training Accuracy = 79.21%\n",
      "Epoch 691/1000: Training Accuracy = 75.84%\n",
      "Epoch 692/1000: Training Accuracy = 79.78%\n",
      "Epoch 693/1000: Training Accuracy = 80.48%\n",
      "Epoch 694/1000: Training Accuracy = 77.67%\n",
      "Epoch 695/1000: Training Accuracy = 79.49%\n",
      "Epoch 696/1000: Training Accuracy = 79.07%\n",
      "Epoch 697/1000: Training Accuracy = 73.46%\n",
      "Epoch 698/1000: Training Accuracy = 78.93%\n",
      "Epoch 699/1000: Training Accuracy = 80.48%\n",
      "Epoch 700/1000: Training Accuracy = 79.35%\n",
      "Epoch 701/1000: Training Accuracy = 78.79%\n",
      "Epoch 702/1000: Training Accuracy = 75.56%\n",
      "Epoch 703/1000: Training Accuracy = 80.34%\n",
      "Epoch 704/1000: Training Accuracy = 79.21%\n",
      "Epoch 705/1000: Training Accuracy = 75.28%\n",
      "Epoch 706/1000: Training Accuracy = 75.98%\n",
      "Epoch 707/1000: Training Accuracy = 72.61%\n",
      "Epoch 708/1000: Training Accuracy = 79.07%\n",
      "Epoch 709/1000: Training Accuracy = 73.60%\n",
      "Epoch 710/1000: Training Accuracy = 79.92%\n",
      "Epoch 711/1000: Training Accuracy = 79.78%\n",
      "Epoch 712/1000: Training Accuracy = 78.23%\n",
      "Epoch 713/1000: Training Accuracy = 80.06%\n",
      "Epoch 714/1000: Training Accuracy = 72.47%\n",
      "Epoch 715/1000: Training Accuracy = 77.39%\n",
      "Epoch 716/1000: Training Accuracy = 74.72%\n",
      "Epoch 717/1000: Training Accuracy = 74.86%\n",
      "Epoch 718/1000: Training Accuracy = 74.16%\n",
      "Epoch 719/1000: Training Accuracy = 74.72%\n",
      "Epoch 720/1000: Training Accuracy = 79.21%\n",
      "Epoch 721/1000: Training Accuracy = 78.51%\n",
      "Epoch 722/1000: Training Accuracy = 76.26%\n",
      "Epoch 723/1000: Training Accuracy = 80.06%\n",
      "Epoch 724/1000: Training Accuracy = 76.12%\n",
      "Epoch 725/1000: Training Accuracy = 79.49%\n",
      "Epoch 726/1000: Training Accuracy = 74.02%\n",
      "Epoch 727/1000: Training Accuracy = 78.93%\n",
      "Epoch 728/1000: Training Accuracy = 75.00%\n",
      "Epoch 729/1000: Training Accuracy = 78.79%\n",
      "Epoch 730/1000: Training Accuracy = 80.20%\n",
      "Epoch 731/1000: Training Accuracy = 75.14%\n",
      "Epoch 732/1000: Training Accuracy = 80.06%\n",
      "Epoch 733/1000: Training Accuracy = 73.60%\n",
      "Epoch 734/1000: Training Accuracy = 74.02%\n",
      "Epoch 735/1000: Training Accuracy = 79.49%\n",
      "Epoch 736/1000: Training Accuracy = 79.35%\n",
      "Epoch 737/1000: Training Accuracy = 75.70%\n",
      "Epoch 738/1000: Training Accuracy = 79.21%\n",
      "Epoch 739/1000: Training Accuracy = 76.40%\n",
      "Epoch 740/1000: Training Accuracy = 79.78%\n",
      "Epoch 741/1000: Training Accuracy = 72.75%\n",
      "Epoch 742/1000: Training Accuracy = 75.42%\n",
      "Epoch 743/1000: Training Accuracy = 72.61%\n",
      "Epoch 744/1000: Training Accuracy = 79.07%\n",
      "Epoch 745/1000: Training Accuracy = 76.97%\n",
      "Epoch 746/1000: Training Accuracy = 79.92%\n",
      "Epoch 747/1000: Training Accuracy = 78.09%\n",
      "Epoch 748/1000: Training Accuracy = 79.63%\n",
      "Epoch 749/1000: Training Accuracy = 80.34%\n",
      "Epoch 750/1000: Training Accuracy = 78.23%\n",
      "Epoch 751/1000: Training Accuracy = 78.23%\n",
      "Epoch 752/1000: Training Accuracy = 76.40%\n",
      "Epoch 753/1000: Training Accuracy = 78.51%\n",
      "Epoch 754/1000: Training Accuracy = 76.40%\n",
      "Epoch 755/1000: Training Accuracy = 79.07%\n",
      "Epoch 756/1000: Training Accuracy = 79.21%\n",
      "Epoch 757/1000: Training Accuracy = 79.78%\n",
      "Epoch 758/1000: Training Accuracy = 78.51%\n",
      "Epoch 759/1000: Training Accuracy = 79.21%\n",
      "Epoch 760/1000: Training Accuracy = 74.02%\n",
      "Epoch 761/1000: Training Accuracy = 80.62%\n",
      "Epoch 762/1000: Training Accuracy = 78.93%\n",
      "Epoch 763/1000: Training Accuracy = 76.26%\n",
      "Epoch 764/1000: Training Accuracy = 79.49%\n",
      "Epoch 765/1000: Training Accuracy = 79.78%\n",
      "Epoch 766/1000: Training Accuracy = 71.63%\n",
      "Epoch 767/1000: Training Accuracy = 81.04%\n",
      "Epoch 768/1000: Training Accuracy = 77.67%\n",
      "Epoch 769/1000: Training Accuracy = 78.23%\n",
      "Epoch 770/1000: Training Accuracy = 79.49%\n",
      "Epoch 771/1000: Training Accuracy = 76.54%\n",
      "Epoch 772/1000: Training Accuracy = 79.49%\n",
      "Epoch 773/1000: Training Accuracy = 80.76%\n",
      "Epoch 774/1000: Training Accuracy = 76.97%\n",
      "Epoch 775/1000: Training Accuracy = 74.16%\n",
      "Epoch 776/1000: Training Accuracy = 76.54%\n",
      "Epoch 777/1000: Training Accuracy = 79.49%\n",
      "Epoch 778/1000: Training Accuracy = 79.07%\n",
      "Epoch 779/1000: Training Accuracy = 78.65%\n",
      "Epoch 780/1000: Training Accuracy = 73.60%\n",
      "Epoch 781/1000: Training Accuracy = 78.51%\n",
      "Epoch 782/1000: Training Accuracy = 76.12%\n",
      "Epoch 783/1000: Training Accuracy = 79.07%\n",
      "Epoch 784/1000: Training Accuracy = 73.46%\n",
      "Epoch 785/1000: Training Accuracy = 78.37%\n",
      "Epoch 786/1000: Training Accuracy = 79.78%\n",
      "Epoch 787/1000: Training Accuracy = 76.97%\n",
      "Epoch 788/1000: Training Accuracy = 80.34%\n",
      "Epoch 789/1000: Training Accuracy = 79.21%\n",
      "Epoch 790/1000: Training Accuracy = 79.92%\n",
      "Epoch 791/1000: Training Accuracy = 79.49%\n",
      "Epoch 792/1000: Training Accuracy = 78.93%\n",
      "Epoch 793/1000: Training Accuracy = 75.14%\n",
      "Epoch 794/1000: Training Accuracy = 76.69%\n",
      "Epoch 795/1000: Training Accuracy = 78.65%\n",
      "Epoch 796/1000: Training Accuracy = 74.86%\n",
      "Epoch 797/1000: Training Accuracy = 79.07%\n",
      "Epoch 798/1000: Training Accuracy = 74.58%\n",
      "Epoch 799/1000: Training Accuracy = 79.92%\n",
      "Epoch 800/1000: Training Accuracy = 79.63%\n",
      "Epoch 801/1000: Training Accuracy = 75.14%\n",
      "Epoch 802/1000: Training Accuracy = 79.35%\n",
      "Epoch 803/1000: Training Accuracy = 75.00%\n",
      "Epoch 804/1000: Training Accuracy = 79.07%\n",
      "Epoch 805/1000: Training Accuracy = 81.18%\n",
      "Epoch 806/1000: Training Accuracy = 74.58%\n",
      "Epoch 807/1000: Training Accuracy = 78.79%\n",
      "Epoch 808/1000: Training Accuracy = 78.65%\n",
      "Epoch 809/1000: Training Accuracy = 79.78%\n",
      "Epoch 810/1000: Training Accuracy = 79.78%\n",
      "Epoch 811/1000: Training Accuracy = 78.23%\n",
      "Epoch 812/1000: Training Accuracy = 78.23%\n",
      "Epoch 813/1000: Training Accuracy = 77.95%\n",
      "Epoch 814/1000: Training Accuracy = 71.91%\n",
      "Epoch 815/1000: Training Accuracy = 78.93%\n",
      "Epoch 816/1000: Training Accuracy = 73.74%\n",
      "Epoch 817/1000: Training Accuracy = 79.78%\n",
      "Epoch 818/1000: Training Accuracy = 80.20%\n",
      "Epoch 819/1000: Training Accuracy = 78.93%\n",
      "Epoch 820/1000: Training Accuracy = 78.93%\n",
      "Epoch 821/1000: Training Accuracy = 78.93%\n",
      "Epoch 822/1000: Training Accuracy = 79.21%\n",
      "Epoch 823/1000: Training Accuracy = 79.63%\n",
      "Epoch 824/1000: Training Accuracy = 76.69%\n",
      "Epoch 825/1000: Training Accuracy = 78.65%\n",
      "Epoch 826/1000: Training Accuracy = 77.81%\n",
      "Epoch 827/1000: Training Accuracy = 77.67%\n",
      "Epoch 828/1000: Training Accuracy = 74.30%\n",
      "Epoch 829/1000: Training Accuracy = 73.88%\n",
      "Epoch 830/1000: Training Accuracy = 73.60%\n",
      "Epoch 831/1000: Training Accuracy = 78.93%\n",
      "Epoch 832/1000: Training Accuracy = 78.93%\n",
      "Epoch 833/1000: Training Accuracy = 79.92%\n",
      "Epoch 834/1000: Training Accuracy = 78.37%\n",
      "Epoch 835/1000: Training Accuracy = 75.00%\n",
      "Epoch 836/1000: Training Accuracy = 79.35%\n",
      "Epoch 837/1000: Training Accuracy = 79.92%\n",
      "Epoch 838/1000: Training Accuracy = 80.34%\n",
      "Epoch 839/1000: Training Accuracy = 78.51%\n",
      "Epoch 840/1000: Training Accuracy = 80.76%\n",
      "Epoch 841/1000: Training Accuracy = 76.40%\n",
      "Epoch 842/1000: Training Accuracy = 79.35%\n",
      "Epoch 843/1000: Training Accuracy = 80.06%\n",
      "Epoch 844/1000: Training Accuracy = 72.19%\n",
      "Epoch 845/1000: Training Accuracy = 78.79%\n",
      "Epoch 846/1000: Training Accuracy = 79.07%\n",
      "Epoch 847/1000: Training Accuracy = 81.32%\n",
      "Epoch 848/1000: Training Accuracy = 79.07%\n",
      "Epoch 849/1000: Training Accuracy = 78.79%\n",
      "Epoch 850/1000: Training Accuracy = 76.40%\n",
      "Epoch 851/1000: Training Accuracy = 79.49%\n",
      "Epoch 852/1000: Training Accuracy = 80.06%\n",
      "Epoch 853/1000: Training Accuracy = 74.58%\n",
      "Epoch 854/1000: Training Accuracy = 80.06%\n",
      "Epoch 855/1000: Training Accuracy = 76.83%\n",
      "Epoch 856/1000: Training Accuracy = 72.75%\n",
      "Epoch 857/1000: Training Accuracy = 78.65%\n",
      "Epoch 858/1000: Training Accuracy = 76.12%\n",
      "Epoch 859/1000: Training Accuracy = 79.92%\n",
      "Epoch 860/1000: Training Accuracy = 79.21%\n",
      "Epoch 861/1000: Training Accuracy = 77.81%\n",
      "Epoch 862/1000: Training Accuracy = 78.37%\n",
      "Epoch 863/1000: Training Accuracy = 76.54%\n",
      "Epoch 864/1000: Training Accuracy = 78.37%\n",
      "Epoch 865/1000: Training Accuracy = 80.34%\n",
      "Epoch 866/1000: Training Accuracy = 79.21%\n",
      "Epoch 867/1000: Training Accuracy = 78.23%\n",
      "Epoch 868/1000: Training Accuracy = 79.21%\n",
      "Epoch 869/1000: Training Accuracy = 80.90%\n",
      "Epoch 870/1000: Training Accuracy = 76.12%\n",
      "Epoch 871/1000: Training Accuracy = 79.21%\n",
      "Epoch 872/1000: Training Accuracy = 79.49%\n",
      "Epoch 873/1000: Training Accuracy = 76.12%\n",
      "Epoch 874/1000: Training Accuracy = 78.09%\n",
      "Epoch 875/1000: Training Accuracy = 73.60%\n",
      "Epoch 876/1000: Training Accuracy = 77.81%\n",
      "Epoch 877/1000: Training Accuracy = 73.74%\n",
      "Epoch 878/1000: Training Accuracy = 79.63%\n",
      "Epoch 879/1000: Training Accuracy = 78.37%\n",
      "Epoch 880/1000: Training Accuracy = 73.46%\n",
      "Epoch 881/1000: Training Accuracy = 75.98%\n",
      "Epoch 882/1000: Training Accuracy = 79.21%\n",
      "Epoch 883/1000: Training Accuracy = 79.92%\n",
      "Epoch 884/1000: Training Accuracy = 78.79%\n",
      "Epoch 885/1000: Training Accuracy = 79.78%\n",
      "Epoch 886/1000: Training Accuracy = 71.91%\n",
      "Epoch 887/1000: Training Accuracy = 72.47%\n",
      "Epoch 888/1000: Training Accuracy = 72.47%\n",
      "Epoch 889/1000: Training Accuracy = 78.51%\n",
      "Epoch 890/1000: Training Accuracy = 77.95%\n",
      "Epoch 891/1000: Training Accuracy = 80.20%\n",
      "Epoch 892/1000: Training Accuracy = 73.17%\n",
      "Epoch 893/1000: Training Accuracy = 79.78%\n",
      "Epoch 894/1000: Training Accuracy = 75.84%\n",
      "Epoch 895/1000: Training Accuracy = 72.75%\n",
      "Epoch 896/1000: Training Accuracy = 72.61%\n",
      "Epoch 897/1000: Training Accuracy = 80.06%\n",
      "Epoch 898/1000: Training Accuracy = 76.40%\n",
      "Epoch 899/1000: Training Accuracy = 79.21%\n",
      "Epoch 900/1000: Training Accuracy = 79.35%\n",
      "Epoch 901/1000: Training Accuracy = 79.07%\n",
      "Epoch 902/1000: Training Accuracy = 79.21%\n",
      "Epoch 903/1000: Training Accuracy = 79.21%\n",
      "Epoch 904/1000: Training Accuracy = 78.65%\n",
      "Epoch 905/1000: Training Accuracy = 80.34%\n",
      "Epoch 906/1000: Training Accuracy = 76.26%\n",
      "Epoch 907/1000: Training Accuracy = 74.30%\n",
      "Epoch 908/1000: Training Accuracy = 72.47%\n",
      "Epoch 909/1000: Training Accuracy = 72.61%\n",
      "Epoch 910/1000: Training Accuracy = 79.63%\n",
      "Epoch 911/1000: Training Accuracy = 75.00%\n",
      "Epoch 912/1000: Training Accuracy = 78.51%\n",
      "Epoch 913/1000: Training Accuracy = 78.37%\n",
      "Epoch 914/1000: Training Accuracy = 78.79%\n",
      "Epoch 915/1000: Training Accuracy = 80.90%\n",
      "Epoch 916/1000: Training Accuracy = 75.42%\n",
      "Epoch 917/1000: Training Accuracy = 78.65%\n",
      "Epoch 918/1000: Training Accuracy = 77.39%\n",
      "Epoch 919/1000: Training Accuracy = 79.21%\n",
      "Epoch 920/1000: Training Accuracy = 78.93%\n",
      "Epoch 921/1000: Training Accuracy = 72.61%\n",
      "Epoch 922/1000: Training Accuracy = 79.07%\n",
      "Epoch 923/1000: Training Accuracy = 79.07%\n",
      "Epoch 924/1000: Training Accuracy = 75.70%\n",
      "Epoch 925/1000: Training Accuracy = 79.07%\n",
      "Epoch 926/1000: Training Accuracy = 76.12%\n",
      "Epoch 927/1000: Training Accuracy = 79.07%\n",
      "Epoch 928/1000: Training Accuracy = 79.49%\n",
      "Epoch 929/1000: Training Accuracy = 78.23%\n",
      "Epoch 930/1000: Training Accuracy = 79.78%\n",
      "Epoch 931/1000: Training Accuracy = 79.21%\n",
      "Epoch 932/1000: Training Accuracy = 78.93%\n",
      "Epoch 933/1000: Training Accuracy = 80.34%\n",
      "Epoch 934/1000: Training Accuracy = 75.56%\n",
      "Epoch 935/1000: Training Accuracy = 80.06%\n",
      "Epoch 936/1000: Training Accuracy = 79.92%\n",
      "Epoch 937/1000: Training Accuracy = 77.39%\n",
      "Epoch 938/1000: Training Accuracy = 72.89%\n",
      "Epoch 939/1000: Training Accuracy = 75.00%\n",
      "Epoch 940/1000: Training Accuracy = 78.65%\n",
      "Epoch 941/1000: Training Accuracy = 77.81%\n",
      "Epoch 942/1000: Training Accuracy = 79.07%\n",
      "Epoch 943/1000: Training Accuracy = 76.12%\n",
      "Epoch 944/1000: Training Accuracy = 76.40%\n",
      "Epoch 945/1000: Training Accuracy = 80.34%\n",
      "Epoch 946/1000: Training Accuracy = 79.07%\n",
      "Epoch 947/1000: Training Accuracy = 72.61%\n",
      "Epoch 948/1000: Training Accuracy = 75.14%\n",
      "Epoch 949/1000: Training Accuracy = 73.03%\n",
      "Epoch 950/1000: Training Accuracy = 73.17%\n",
      "Epoch 951/1000: Training Accuracy = 78.93%\n",
      "Epoch 952/1000: Training Accuracy = 77.39%\n",
      "Epoch 953/1000: Training Accuracy = 80.34%\n",
      "Epoch 954/1000: Training Accuracy = 79.49%\n",
      "Epoch 955/1000: Training Accuracy = 77.25%\n",
      "Epoch 956/1000: Training Accuracy = 75.84%\n",
      "Epoch 957/1000: Training Accuracy = 79.07%\n",
      "Epoch 958/1000: Training Accuracy = 75.42%\n",
      "Epoch 959/1000: Training Accuracy = 71.63%\n",
      "Epoch 960/1000: Training Accuracy = 78.65%\n",
      "Epoch 961/1000: Training Accuracy = 79.07%\n",
      "Epoch 962/1000: Training Accuracy = 77.95%\n",
      "Epoch 963/1000: Training Accuracy = 75.98%\n",
      "Epoch 964/1000: Training Accuracy = 77.53%\n",
      "Epoch 965/1000: Training Accuracy = 79.49%\n",
      "Epoch 966/1000: Training Accuracy = 79.63%\n",
      "Epoch 967/1000: Training Accuracy = 76.26%\n",
      "Epoch 968/1000: Training Accuracy = 79.07%\n",
      "Epoch 969/1000: Training Accuracy = 79.49%\n",
      "Epoch 970/1000: Training Accuracy = 78.79%\n",
      "Epoch 971/1000: Training Accuracy = 77.95%\n",
      "Epoch 972/1000: Training Accuracy = 75.00%\n",
      "Epoch 973/1000: Training Accuracy = 75.14%\n",
      "Epoch 974/1000: Training Accuracy = 75.56%\n",
      "Epoch 975/1000: Training Accuracy = 72.61%\n",
      "Epoch 976/1000: Training Accuracy = 79.21%\n",
      "Epoch 977/1000: Training Accuracy = 73.46%\n",
      "Epoch 978/1000: Training Accuracy = 79.35%\n",
      "Epoch 979/1000: Training Accuracy = 79.21%\n",
      "Epoch 980/1000: Training Accuracy = 76.97%\n",
      "Epoch 981/1000: Training Accuracy = 79.63%\n",
      "Epoch 982/1000: Training Accuracy = 73.74%\n",
      "Epoch 983/1000: Training Accuracy = 73.03%\n",
      "Epoch 984/1000: Training Accuracy = 78.93%\n",
      "Epoch 985/1000: Training Accuracy = 80.48%\n",
      "Epoch 986/1000: Training Accuracy = 75.00%\n",
      "Epoch 987/1000: Training Accuracy = 72.61%\n",
      "Epoch 988/1000: Training Accuracy = 79.63%\n",
      "Epoch 989/1000: Training Accuracy = 76.54%\n",
      "Epoch 990/1000: Training Accuracy = 74.86%\n",
      "Epoch 991/1000: Training Accuracy = 75.28%\n",
      "Epoch 992/1000: Training Accuracy = 74.72%\n",
      "Epoch 993/1000: Training Accuracy = 75.98%\n",
      "Epoch 994/1000: Training Accuracy = 79.21%\n",
      "Epoch 995/1000: Training Accuracy = 79.21%\n",
      "Epoch 996/1000: Training Accuracy = 79.07%\n",
      "Epoch 997/1000: Training Accuracy = 79.07%\n",
      "Epoch 998/1000: Training Accuracy = 78.79%\n",
      "Epoch 999/1000: Training Accuracy = 76.69%\n",
      "Epoch 1000/1000: Training Accuracy = 79.21%\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train.shape[1]\n",
    "perceptron = SingleLayerPerceptron(input_size, learning_rate=lr, epochs=epochs)\n",
    "perceptron.train(x_train_normalize, y_train_normalize)\n",
    "pred = perceptron.predict(x_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAG5CAYAAAAaiZejAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLHElEQVR4nO3de1yO9/8H8NcduovOOg+VnA8hxxhKTjmfz9+VOW3DNs1hbUyyyXFO29iJQmE2ZWzMKXLIKQsjVMJMYagItw6f3x9+rrnuwn3nrrvcr+ce12Ndn+tzfa73lZvefQ7XpRBCCBARERH9PyN9B0BERESlC5MDIiIikmFyQERERDJMDoiIiEiGyQERERHJMDkgIiIiGSYHREREJMPkgIiIiGSYHBAREZEMkwPSu6SkJHTu3BmWlpZQKBSIjo7WafuXL1+GQqFAWFiYTtsty7y9veHt7a3vMF5ZQEAAXF1di3Tu6/I9ICoOTA4IAJCSkoJx48ahevXqMDExgYWFBdq0aYOlS5fi4cOHxXptf39/nDlzBl988QXWrl2LZs2aFev1SlJAQAAUCgUsLCwK/T4mJSVBoVBAoVBg4cKFWrd//fp1BAcHIyEhQQfRFt3Texg9enShxz/99FOpzr///lvC0RXdgwcP8PXXX6Nz585wcnKCubk5mjRpghUrViAvL0/f4REVm/L6DoD077fffsPAgQOhVCrx1ltvoUGDBnj8+DEOHjyIKVOm4OzZs/juu++K5doPHz5EXFwcPv30U0yYMKFYruHi4oKHDx+iQoUKxdL+y5QvXx4PHjzA1q1bMWjQINmxiIgImJiY4NGjR0Vq+/r165g1axZcXV3RuHFjjc/buXNnka73IiYmJvjll1/wzTffwNjYWHZs/fr1r3Sf+nLp0iVMnDgRvr6+CAwMhIWFBf744w+89957OHLkCMLDw/UdIlGxYM+BgUtNTcWQIUPg4uKCc+fOYenSpRgzZgzGjx+P9evX49y5c6hfv36xXf/WrVsAACsrq2K7hkKhgImJCcqVK1ds13gRpVIJX19frF+/vsCxyMhIdO/evcRiefDgAQDA2Ni4wA/wV9W1a1dkZWVh+/btsvLDhw8jNTW1RO9TVxwdHXHmzBns2rULU6ZMwbhx47B582aMHDkSa9asQXJysr5DJCoWTA4M3Pz583H//n38+OOPcHJyKnC8Ro0a+OCDD6T93NxczJ49G+7u7lAqlXB1dcUnn3wClUolO8/V1RU9evTAwYMH0aJFC5iYmKB69epYs2aNVCc4OBguLi4AgClTpkChUEjjx88bSw4ODoZCoZCV7dq1C2+++SasrKxgZmaG2rVr45NPPpGOP2/Owd69e9G2bVtUqlQJVlZW6N27NxITEwu9XnJyMgICAmBlZQVLS0uMHDlS+kGriWHDhmH79u3IyMiQyo4fP46kpCQMGzasQP07d+5g8uTJaNiwIczMzGBhYQE/Pz+cOnVKqrNv3z40b94cADBy5Eip2/7pfXp7e6NBgwaIj49Hu3btULFiRen7oj7e7u/vDxMTkwL336VLF1hbW+P69esvvcc33ngD7dq1Q2RkpKw8IiICDRs2RIMGDQo9b9OmTWjatClMTU1ha2uLESNG4J9//ilQLzo6Gg0aNICJiQkaNGiAqKioQtvLz8/HkiVLUL9+fZiYmMDBwQHjxo3D3bt3X3oP6mxtbQtNjvv27QsABb5fRK8LJgcGbuvWrahevTpat26tUf3Ro0fjs88+g6enJxYvXoz27dsjNDQUQ4YMKVA3OTkZAwYMQKdOnbBo0SJYW1sjICAAZ8+eBQD069cPixcvBgAMHToUa9euxZIlS7SK/+zZs+jRowdUKhVCQkKwaNEi9OrVC4cOHXrhebt370aXLl1w8+ZNBAcHIzAwEIcPH0abNm1w+fLlAvUHDRqEe/fuITQ0FIMGDUJYWBhmzZqlcZz9+vWDQqHA5s2bpbLIyEjUqVMHnp6eBepfunQJ0dHR6NGjB7788ktMmTIFZ86cQfv27aUf1HXr1kVISAgAYOzYsVi7di3Wrl2Ldu3aSe3cvn0bfn5+aNy4MZYsWQIfH59C41u6dCns7Ozg7+8vjaV/++232LlzJ5YvXw5nZ2eN7nPYsGHYunUr7t+/D+BJMrlp06ZCEyAACAsLw6BBg1CuXDmEhoZizJgx2Lx5M958801ZIrVz5070798fCoUCoaGh6NOnD0aOHIkTJ04UaHPcuHGYMmWKNGdm5MiRiIiIQJcuXZCTk6PRfbxMeno6gCfJA9FrSZDByszMFABE7969NaqfkJAgAIjRo0fLyidPniwAiL1790plLi4uAoCIjY2Vym7evCmUSqX46KOPpLLU1FQBQCxYsEDWpr+/v3BxcSkQw8yZM8WzH9vFixcLAOLWrVvPjfvpNVavXi2VNW7cWNjb24vbt29LZadOnRJGRkbirbfeKnC9t99+W9Zm3759ReXKlZ97zWfvo1KlSkIIIQYMGCB8fX2FEELk5eUJR0dHMWvWrEK/B48ePRJ5eXkF7kOpVIqQkBCp7Pjx4wXu7an27dsLAGLlypWFHmvfvr2s7I8//hAAxOeffy4uXbokzMzMRJ8+fV56j0IIAUCMHz9e3LlzRxgbG4u1a9cKIYT47bffhEKhEJcvX5a+l0//rB4/fizs7e1FgwYNxMOHD6W2tm3bJgCIzz77TCpr3LixcHJyEhkZGVLZzp07BQDZ5+TAgQMCgIiIiJDFt2PHjgLlhX0PNKFSqUS9evWEm5ubyMnJ0fp8orKAPQcGLCsrCwBgbm6uUf3ff/8dABAYGCgr/+ijjwA8mdj4rHr16qFt27bSvp2dHWrXro1Lly4VOWZ1T+cqbNmyBfn5+Rqdk5aWhoSEBAQEBMDGxkYq9/DwQKdOnaT7fNY777wj22/bti1u374tfQ81MWzYMOzbtw/p6enYu3cv0tPTn/sbtVKphJHRk7+eeXl5uH37tjRkcvLkSY2vqVQqMXLkSI3qdu7cGePGjUNISAj69esHExMTfPvttxpfCwCsra3RtWtXaX5FZGQkWrduLQ0fPevEiRO4efMm3nvvPZiYmEjl3bt3R506daTP09M/L39/f1haWkr1OnXqhHr16sna3LRpEywtLdGpUyf8+++/0ta0aVOYmZkhJiZGq/spzIQJE3Du3Dl89dVXKF+ec7rp9cTkwIBZWFgAAO7du6dR/StXrsDIyAg1atSQlTs6OsLKygpXrlyRlVerVq1AG9bW1kUa+32ewYMHo02bNhg9ejQcHBwwZMgQ/PTTTy9MFJ7GWbt27QLH6tati3///RfZ2dmycvV7sba2BgCt7qVbt24wNzfHxo0bERERgebNmxf4Xj6Vn5+PxYsXo2bNmlAqlbC1tYWdnR1Onz6NzMxMja/5xhtvaDXxcOHChbCxsUFCQgKWLVsGe3t7jc99atiwYdi1axeuXr2K6Ojo5yZAL/pzqFOnjnT86f9r1qxZoJ76uUlJScjMzIS9vT3s7Oxk2/3793Hz5k2t7+dZCxYswPfff4/Zs2ejW7dur9QWUWnGtNeAWVhYwNnZGX/99ZdW56lPCHye560OEEIU+Rrqa8tNTU0RGxuLmJgY/Pbbb9ixYwc2btyIDh06YOfOnTpbofAq9/KUUqlEv379EB4ejkuXLiE4OPi5defMmYMZM2bg7bffxuzZs2FjYwMjIyN8+OGHGveQAE++P9r4888/pR+gZ86cwdChQ7U6HwB69eoFpVIJf39/qFSqAss3i1N+fj7s7e0RERFR6HE7O7sitx0WFoZp06bhnXfewfTp04vcDlFZwOTAwPXo0QPfffcd4uLi4OXl9cK6Li4uyM/PR1JSEurWrSuV37hxAxkZGYV2HReVtbW1bELaU+q9EwBgZGQEX19f+Pr64ssvv8ScOXPw6aefIiYmBh07diz0PgDgwoULBY6dP38etra2qFSp0qvfRCGGDRuGVatWwcjIqNBJnE/9/PPP8PHxwY8//igrz8jIkE2C0zRR00R2djZGjhyJevXqoXXr1pg/fz769u0rrYjQlKmpKfr06YN169bBz8/vuZP2nv1z6NChg+zYhQsXpONP/5+UlFSgDfU/Q3d3d+zevRtt2rTROjF6kS1btmD06NHo168fvv76a521S1RacVjBwE2dOhWVKlXC6NGjcePGjQLHU1JSsHTpUgCQulHVVxR8+eWXAKDTdezu7u7IzMzE6dOnpbK0tLQCy9fu3LlT4NynDwNSX175lJOTExo3bozw8HBZAvLXX39h586dxdpd7OPjg9mzZ+Orr76Co6Pjc+uVK1euQK/Epk2bCizxe5rEFJZIaWvatGm4evUqwsPD8eWXX8LV1VX67V9bkydPxsyZMzFjxozn1mnWrBns7e2xcuVK2TW2b9+OxMRE6fP07J/Xs0Mqu3btwrlz52RtDho0CHl5eZg9e3aB6+Xm5hbp+xQbG4shQ4agXbt2iIiIkOaCEL3O2HNg4Nzd3REZGYnBgwejbt26sickHj58GJs2bUJAQAAAoFGjRvD398d3332HjIwMtG/fHseOHUN4eDj69Onz3GVyRTFkyBBMmzYNffv2xfvvv48HDx5gxYoVqFWrlmxCXkhICGJjY9G9e3e4uLjg5s2b+Oabb1ClShW8+eabz21/wYIF8PPzg5eXF0aNGoWHDx9i+fLlsLS0fGF3/6syMjLSqEu6R48eCAkJwciRI9G6dWucOXMGERERqF69uqyeu7s7rKyssHLlSpibm6NSpUpo2bIl3NzctIpr7969+OabbzBz5kxpaeXq1avh7e2NGTNmYP78+Vq116hRIzRq1OiFdSpUqIB58+Zh5MiRaN++PYYOHYobN25g6dKlcHV1xaRJk6S6oaGh6N69O9588028/fbbuHPnDpYvX4769etLyyYBoH379hg3bhxCQ0ORkJCAzp07o0KFCkhKSsKmTZuwdOlSDBgwQOP7uHLlCnr16gWFQoEBAwZg06ZNsuMeHh7w8PDQuD2iMkPPqyWolLh48aIYM2aMcHV1FcbGxsLc3Fy0adNGLF++XDx69Eiql5OTI2bNmiXc3NxEhQoVRNWqVUVQUJCsjhBPljJ27969wHXUl489bymjEE+WqjVo0EAYGxuL2rVri3Xr1hVYyrhnzx7Ru3dv4ezsLIyNjYWzs7MYOnSouHjxYoFrqC/32717t2jTpo0wNTUVFhYWomfPnuLcuXOyOurL755avXq1ACBSU1Of+z0VQr6U8Xmet5Txo48+Ek5OTsLU1FS0adNGxMXFFbr8bsuWLaJevXqifPnysvts3769qF+/fqHXfLadrKws4eLiIjw9PQsszZs0aZIwMjIScXFxL7wH/P9Sxhd53vdy48aNokmTJkKpVAobGxsxfPhwce3atQLn//LLL6Ju3bpCqVSKevXqic2bNz93yet3330nmjZtKkxNTYW5ublo2LChmDp1qrh+/Xqh34PniYmJEQCeu82cOfOF5xOVVQohtJhRRURERK89Dp4RERGRDJMDIiIikmFyQERERDJMDoiIiEiGyQERERHJMDkgIiIiGSYHREREJMPkgIiIiGSYHBAREZEMkwMiIiKSYXJARERUSoSGhqJ58+YwNzeHvb09+vTpU+DV5I8ePcL48eNRuXJlmJmZoX///gXeqnv16lV0794dFStWhL29PaZMmYLc3FyN42ByQEREVErs378f48ePx5EjR7Br1y7k5OSgc+fOyM7OlupMmjQJW7duxaZNm7B//35cv34d/fr1k47n5eWhe/fu0tt1w8PDERYWhs8++0zjOPjiJSIiolLq1q1bsLe3x/79+9GuXTtkZmbCzs4OkZGR0uvHz58/j7p16yIuLg6tWrXC9u3b0aNHD1y/fh0ODg4AgJUrV2LatGm4desWjI2NX3rd8sV6V1rwcGmv7xCISp19WxfpOwSiUsnGo1mxtq/Ln0mnr+wv8rmZmZkAABsbGwBAfHw8cnJy0LFjR6lOnTp1UK1aNSk5iIuLQ8OGDaXEAAC6dOmCd999F2fPnkWTJk1eet1SkxwQERGVFgqFQmdtqVQqqFQqWZlSqYRSqXzhefn5+fjwww/Rpk0bNGjQAACQnp4OY2NjWFlZyeo6ODggPT1dqvNsYvD0+NNjmuCcAyIiomIUGhoKS0tL2RYaGvrS88aPH4+//voLGzZsKIEo5dhzQEREVIyCgoIQGBgoK3tZr8GECROwbds2xMbGokqVKlK5o6MjHj9+jIyMDFnvwY0bN+Do6CjVOXbsmKy9p6sZntZ5GfYcEBERqVEojHS2KZVKWFhYyLbnJQdCCEyYMAFRUVHYu3cv3NzcZMebNm2KChUqYM+ePVLZhQsXcPXqVXh5eQEAvLy8cObMGdy8eVOqs2vXLlhYWKBevXoa3T97DoiIiNQYQXdzDrQxfvx4REZGYsuWLTA3N5fmCFhaWsLU1BSWlpYYNWoUAgMDYWNjAwsLC0ycOBFeXl5o1aoVAKBz586oV68e/ve//2H+/PlIT0/H9OnTMX78+Jf2WDzF5ICIiKiUWLFiBQDA29tbVr569WoEBAQAABYvXgwjIyP0798fKpUKXbp0wTfffCPVLVeuHLZt24Z3330XXl5eqFSpEvz9/RESEqJxHKXmOQdcykhUEJcyEhWuuJcyerr56qytk6l7Xl6plGHPARERkRpdLmUsizghkYiIiGTYc0BERKTGSGHYvzszOSAiIlLDYQUiIiKiZzA5ICIiIhkOKxAREalR6OkhSKUFew6IiIhIhj0HREREagx9tYJh3z0REREVwJ4DIiIiNVzKSERERPQM9hwQERGpMWLPAREREdF/mBwQERGRDIcViIiI1CgM/HdnJgdERERquFqBiIiI6BnsOSAiIlLD1QpEREREz2ByQERERDIcViAiIlJj6K9sZnJARESkhm9lJCIiInoGkwMiIiKS4bACERGRGkN/CBKTAyIiIjV8zgERERHRM5gcEBERkQyHFYiIiNQY+nMO2HNAREREMuw5ICIiUmPoD0FickBERKTG0JcyGnZqRERERAUwOSAiIiIZDisQERGp4UOQiIiISEahw/+0ERsbi549e8LZ2RkKhQLR0dHyuBSKQrcFCxZIdVxdXQscnzt3rlZxMDkgIiIqJbKzs9GoUSN8/fXXhR5PS0uTbatWrYJCoUD//v1l9UJCQmT1Jk6cqFUcHFYgIiIqJfz8/ODn5/fc446OjrL9LVu2wMfHB9WrV5eVm5ubF6irDfYcEBERqXle931RNpVKhaysLNmmUqleOcYbN27gt99+w6hRowocmzt3LipXrowmTZpgwYIFyM3N1aptJgdERETFKDQ0FJaWlrItNDT0ldsNDw+Hubk5+vXrJyt///33sWHDBsTExGDcuHGYM2cOpk6dqlXbGg0rLFu2TOMG33//fa0CICIiKm10uVohKCgIgYGBsjKlUvnK7a5atQrDhw+HiYmJrPzZa3l4eMDY2Bjjxo1DaGioxtfVKDlYvHixbP/WrVt48OABrKysAAAZGRmoWLEi7O3tmRwQERE9Q6lU6iQZeNaBAwdw4cIFbNy48aV1W7ZsidzcXFy+fBm1a9fWqH2NhhVSU1Ol7YsvvkDjxo2RmJiIO3fu4M6dO0hMTISnpydmz56t0UWJiIio6H788Uc0bdoUjRo1emndhIQEGBkZwd7eXuP2tV6tMGPGDPz888+y7KN27dpYvHgxBgwYgOHDh2vbJBERUamir1c2379/H8nJydJ+amoqEhISYGNjg2rVqgEAsrKysGnTJixatKjA+XFxcTh69Ch8fHxgbm6OuLg4TJo0CSNGjIC1tbXGcWidHKSlpRU66zEvLw83btzQtjkiIqJSR19vZTxx4gR8fHyk/afzB/z9/REWFgYA2LBhA4QQGDp0aIHzlUolNmzYgODgYKhUKri5uWHSpEkF5jy8jEIIIbQ5oWfPnvjnn3/www8/wNPTEwAQHx+PsWPH4o033sCvv/6qVQBPebi0L9J5RK+zfVsL/mZARICNR7Nibb+/Z4DO2vrlZJjO2iopWqdGq1atgqOjI5o1ayZNsmjRogUcHBzwww8/FEeMREREJUqXzzkoi7QeVrCzs8Pvv/+Oixcv4vz58wCAOnXqoFatWjoPjoiIiEpekR+f7OrqCiEE3N3dUb48n8JMRESvD76VUUsPHjzAqFGjULFiRdSvXx9Xr14FAEycOFHrtz4RERFR6aN1chAUFIRTp05h3759sqcydezYUaOHMRAREZV2+nplc2mh9XhAdHQ0Nm7ciFatWskmWtSvXx8pKSk6DY6IiIhKntY9B7du3Sr0KUvZ2dlldlYmERER/Ufr5KBZs2b47bffpP2nCcEPP/wALy8v3UVGRESkJ0YKhc62skjrYYU5c+bAz88P586dQ25uLpYuXYpz587h8OHD2L9/f3HESEREVKIMvSdc656DN998EwkJCcjNzUXDhg2xc+dO2NvbIy4uDk2bNi2OGImIiKgEFekBBe7u7vj+++91HQsREVGpUFaHA3RF656Djh07IiwsDFlZWcURDxEREemZ1slB/fr1ERQUBEdHRwwcOBBbtmxBTk5OccRGREREeqB1crB06VL8888/iI6ORqVKlfDWW2/BwcEBY8eO5YREIiJ6LRj6Q5CK9MJqIyMjdO7cGWFhYbhx4wa+/fZbHDt2DB06dNB1fERERCWOSxlfQXp6OjZs2IB169bh9OnTaNGiha7iIiIiIj3RuucgKysLq1evRqdOnVC1alWsWLECvXr1QlJSEo4cOVIcMRIREVEJ0rrnwMHBAdbW1hg8eDBCQ0PRrFmz4oiLiIhIbwz9IUhaJwe//vorfH19YWRUpOkKREREpV5ZnSugK1onB506dSqOOIiIiKiU0Cg58PT0xJ49e2BtbY0mTZq8sLvl5MmTOguOiIiISp5GyUHv3r2hVCqlrw19LIaIiF5vZfX5BLqiUXIwc+ZM6evg4ODiioWIiIhKAa1nFY4ePRr79u0rhlCIiIhKB0N/CJLWycGtW7fQtWtXVK1aFVOmTMGpU6eKIy4iIiK9USgUOtvKIq2Tgy1btiAtLQ0zZszA8ePH4enpifr162POnDm4fPlyMYRIREREJalIDyuwtrbG2LFjsW/fPly5cgUBAQFYu3YtatSooev4iIiIqIS90rsVcnJycOLECRw9ehSXL1+Gg4ODruIiIiLSm7I6V0BXitRzEBMTgzFjxsDBwQEBAQGwsLDAtm3bcO3aNV3HR0REVOIMfc6B1j0Hb7zxBu7cuYOuXbviu+++Q8+ePaVnIBAREVHZp3VyEBwcjIEDB8LKyqoYwiEiIiJ90yo5yMnJwbvvvgsvLy8mB2XIqPeGw7drO7i5V4PqkQoJ8X9hydxvcfnS31IdY6UxJk9/D117doCxcQUcjj2Oz6cvxp1/70p1pgW/jybNGqBGLTdcSr6CQd1G6+N2iErM5j92Y/PO3Ui7dQsAUL1KFbw9sC+8mjTWb2BU7Az9CYlazTmoUKECqlWrhry8vOKKh4pBs5aNsGFNFEb0eRdjR3yE8hXKY+XahTA1NZHqTJ0xAe19W2PyezMxctAHsHOwxeJvZxdoK+qn3/HHtpiSDJ9Ib+wq2+C94UMQNu8LrJ77OZo2qI+p877Epb85v4peb1oPK3z66af45JNPsHbtWtjY2BRHTKRj7/pPle3P+CgU+//8FfUa1kL8sdMwM6+EvoO74eMPZuPY4T+f1Jk8F7/uXQuPJvVw+s9zAIB5wcsAADY2VqhZp3rJ3gSRHrRt5inbf2fYIGzeuRt/XUxG9apV9BQVlQQjw+440D45+Oqrr5CcnAxnZ2e4uLigUqVKsuN8K2PpZ2ZuBgDIzLgHAKjXsBYqGFfAkYPxUp3LKVdx/Vo6PDzrS8kBkSHLy8vH3iNH8UilQsNafKYLvd60Tg769OlTDGFQSVEoFJg6cwJOHj+N5IupAABbu8p4rHqMe1n3ZXVv/3sXtnbsHSLDlnzlKsZ+GozHOTkwNTHB3CmT4MZeA3rNaZ0cPPuGxqJSqVRQqVSysnyRDyNFkR67QFr4dPYk1KjlhoABE/UdClGZ4OLsjPAFc5D94CH2HjmK2V+txDezpjNBeM3p6/kEsbGxWLBgAeLj45GWloaoqCjZL+UBAQEIDw+XndOlSxfs2LFD2r9z5w4mTpyIrVu3wsjICP3798fSpUthZmamcRx6+WkcGhoKS0tL2XYr86o+QjEoQSEfoJ2vF0YP/RA30m9J5f/eug1jpTHMLeQfnMq21vj31p2SDpOoVKlQoTyqOjmijrsb3hs+BDVcq2Hj73/oOywqZvp6K2N2djYaNWqEr7/++rl1unbtirS0NGlbv3697Pjw4cNx9uxZ7Nq1C9u2bUNsbCzGjh2rVRxa9xwYGRm9MKPSZCVDUFAQAgMDZWWtG3TXNhTSQlDIB+jQpS1GDf4A//ydLjt27sxF5DzOQcs2nti9PRYA4Fq9KpyrOOL0ybP6CJeo1BL5Ajk5OfoOg15Tfn5+8PPze2EdpVIJR0fHQo8lJiZix44dOH78OJo1awYAWL58Obp164aFCxfC2dlZozi0Tg6ioqJk+zk5Ofjzzz8RHh6OWbNmadSGUqks8FRFDikUn08/nwS/Xr74YMynyM5+iMr/P4/gftZ9qFSPcf9eNqI2/o7J08cjM+Me7t/LRlDIB0iI/0s2GbGqyxuoWMkUle1sYGKiRO16TyZlpSRdRm5Orl7ujag4fROxAV5NGsHR1hbZDx9i58HDOHkuEUs+nabv0KiY6XJYobCh9MJ+Dmpq3759sLe3h7W1NTp06IDPP/8clStXBgDExcXByspKSgwAoGPHjjAyMsLRo0fRt29fja6hdXLQu3fvAmUDBgxA/fr1sXHjRowaNUrbJqmYDf5fHwDA6p+WycqnfxSKX39+Mk41f/ZXyBf5+HJlCIyNK+BQ7HF8MX2xrH7wvClo7tVE2t+0/UcAQNc2g3H9mrw3guh1cDczCyFfrcTtuxkwq1gR7i5VseTTaWjRqKG+Q6MyJDQ0tMAvzzNnzkRwcLDWbXXt2hX9+vWDm5sbUlJS8Mknn8DPzw9xcXEoV64c0tPTYW9vLzunfPnysLGxQXq65v9Ov9JbGZ/VqlUrrcc0qGR4uLR/aZ3HqseYM2MJ5sxY8tw6o4Z8qLugiMqAT9/jv2mGykiHT0gsbCi9qL0GQ4YMkb5u2LAhPDw84O7ujn379sHX1/eV4nyWTvryHz58iGXLluGNN97QRXNERESvDaVSCQsLC9mmqxcWVq9eHba2tkhOTgYAODo64ubNm7I6ubm5uHPnznPnKRRG654Da2tr2ViMEAL37t1DxYoVsW7dOm2bIyIiKnXKyquWr127htu3b8PJyQkA4OXlhYyMDMTHx6Np06YAgL179yI/Px8tW7bUuF2tk4MlS5bI9o2MjGBnZ4eWLVvC2tpa2+aIiIjo/92/f1/qBQCA1NRUJCQkwMbGBjY2Npg1axb69+8PR0dHpKSkYOrUqahRowa6dOkCAKhbty66du2KMWPGYOXKlcjJycGECRMwZMgQjVcqAEVIDvz9/bU9hYiIiDRw4sQJ+Pj4SPtP5yr4+/tjxYoVOH36NMLDw5GRkQFnZ2d07twZs2fPlg1TREREYMKECfD19ZUegrRs2bIC13oRjZODf//9F9nZ2XBxcZHKzp49i4ULFyI7Oxt9+vTBsGHDtLo4ERFRaaTtw4t0xdvbG0KI5x7/44+XP4DLxsYGkZGRrxSHxhMSJ06cKMs8bt68ibZt2+L48eNQqVQICAjA2rVrXykYIiKi0kCh0N1WFmmcHBw5cgS9evWS9tesWQMbGxskJCRgy5YtmDNnzgsf90hERERlg8bJQXp6OlxdXaX9vXv3ol+/fihf/snIRK9evZCUlKTzAImIiKhkaZwcWFhYICMjQ9o/duyYbFmEQqEo8HhIIiKiskhfL14qLTRODlq1aoVly5YhPz8fP//8M+7du4cOHTpIxy9evIiqVasWS5BERERUcjRerTB79mz4+vpi3bp1yM3NxSeffCJ7rsGGDRvQvv3LH9NLRERU2il0+Pjkskjj5MDDwwOJiYk4dOgQHB0dCzxpaciQIahXr57OAyQiIippZeUJicVFq4cg2draFvpWRgDo3r27TgIiIiIi/dLJi5eIiIjo9aGzVzYTERG9LsrqKgNdYXJARESkxsBzAw4rEBERkZzWyUG5cuVw8+bNAuW3b99GuXLldBIUERER6Y/WwwrPe1uUSqWCsbHxKwdERESkb5xzoKGnb2RUKBT44YcfYGZmJh3Ly8tDbGws6tSpo/sIiYiIqERpnBwsXrwYwJOeg5UrV8qGEIyNjeHq6oqVK1fqPkIiIqISxickaig1NRUA4OPjg82bN8senUxERPQ64bCClmJiYqSvn84/MPTHTBIREb1OirSUcc2aNWjYsCFMTU1hamoKDw8PrF27VtexERERkR5o3XPw5ZdfYsaMGZgwYQLatGkDADh48CDeeecd/Pvvv5g0aZLOgyQiIipJht4hrnVysHz5cqxYsQJvvfWWVNarVy/Ur18fwcHBTA6IiKjMM/Thcq2HFdLS0tC6desC5a1bt0ZaWppOgiIiIiL90To5qFGjBn766acC5Rs3bkTNmjV1EhQRERHpj9bDCrNmzcLgwYMRGxsrzTk4dOgQ9uzZU2jSQEREVNYY+lJGrXsO+vfvj6NHj8LW1hbR0dGIjo6Gra0tjh07hr59+xZHjERERFSCivTK5qZNm2LdunW6joWIiKhUMPCOA76ymYiIiOQ07jkwMjJ66dIOhUKB3NzcVw6KiIiI9Efj5CAqKuq5x+Li4rBs2TLk5+frJCgiIiJ9MvQJiRonB7179y5QduHCBXz88cfYunUrhg8fjpCQEJ0GR0REpA+G/lbGIs05uH79OsaMGYOGDRsiNzcXCQkJCA8Ph4uLi67jIyIiohKmVXKQmZmJadOmoUaNGjh79iz27NmDrVu3okGDBsUVHxERUYlTKBQ628oijYcV5s+fj3nz5sHR0RHr168vdJiBiIiIyj6Nk4OPP/4YpqamqFGjBsLDwxEeHl5ovc2bN+ssOCIiIn0wKpu/8OuMxsnBW2+9VWa7R4iIiEhzGicHYWFhxRgGERFR6aGvX4ZjY2OxYMECxMfHIy0tDVFRUejTpw8AICcnB9OnT8fvv/+OS5cuwdLSEh07dsTcuXPh7OwsteHq6oorV67I2g0NDcXHH3+scRx8QiIREVEpkZ2djUaNGuHrr78ucOzBgwc4efIkZsyYgZMnT2Lz5s24cOECevXqVaBuSEgI0tLSpG3ixIlaxVGkdysQERGR7vn5+cHPz6/QY5aWlti1a5es7KuvvkKLFi1w9epVVKtWTSo3NzeHo6NjkeNgzwEREZGasrKUMTMzEwqFAlZWVrLyuXPnonLlymjSpAkWLFig9asN2HNARESkRperFVQqFVQqlaxMqVRCqVS+UruPHj3CtGnTMHToUFhYWEjl77//Pjw9PWFjY4PDhw8jKCgIaWlp+PLLLzVumz0HRERExSg0NBSWlpayLTQ09JXazMnJwaBBgyCEwIoVK2THAgMD4e3tDQ8PD7zzzjtYtGgRli9fXiBBeRH2HBARERWjoKAgBAYGyspepdfgaWJw5coV7N27V9ZrUJiWLVsiNzcXly9fRu3atTW6BpMDIiIiNbqcK6CLIYSnniYGSUlJiImJQeXKlV96TkJCAoyMjGBvb6/xdZgcEBERqdHXM//u37+P5ORkaT81NRUJCQmwsbGBk5MTBgwYgJMnT2Lbtm3Iy8tDeno6AMDGxgbGxsaIi4vD0aNH4ePjA3Nzc8TFxWHSpEkYMWIErK2tNY6DyQEREVEpceLECfj4+Ej7T4cj/P39ERwcjF9//RUA0LhxY9l5MTEx8Pb2hlKpxIYNGxAcHAyVSgU3NzdMmjSpwLDGyzA5ICIiUmOkp64Db29vCCGee/xFxwDA09MTR44ceeU4uFqBiIiIZJgcEBERkQyHFYiIiNQoYNhvIWZyQEREpEZfqxVKCw4rEBERkQyTAyIiIpLhsAIREZEafS1lLC3Yc0BEREQy7DkgIiJSo8t3K5RF7DkgIiIiGfYcEBERqTHwjgP2HBAREZEcew6IiIjUGPqcAyYHREREaowMOzfgsAIRERHJMTkgIiIiGQ4rEBERqTH0OQfsOSAiIiIZ9hwQERGpMfCOA/YcEBERkRyTAyIiIpLhsAIREZEaQ39lM5MDIiIiNYa+WoHJARERkRoDzw0454CIiIjkmBwQERGRDIcViIiI1Bj6nAP2HBAREZEMew6IiIjUGHjHAXsOiIiISI7JAREREclwWIGIiEgNn5BIREREMgaeG3BYgYiIiOSYHBAREZEMhxWIiIjUGPpDkEpNcrD351B9h0BU6vw8b4++QyAqlcZGNCvW9vWVG8TGxmLBggWIj49HWloaoqKi0KdPH+m4EAIzZ87E999/j4yMDLRp0wYrVqxAzZo1pTp37tzBxIkTsXXrVhgZGaF///5YunQpzMzMNI6DwwpERESlRHZ2Nho1aoSvv/660OPz58/HsmXLsHLlShw9ehSVKlVCly5d8OjRI6nO8OHDcfbsWezatQvbtm1DbGwsxo4dq1UcpabngIiIqLTQ17CCn58f/Pz8Cj0mhMCSJUswffp09O7dGwCwZs0aODg4IDo6GkOGDEFiYiJ27NiB48ePo1mzJ70ry5cvR7du3bBw4UI4OztrFAd7DoiIiIqRSqVCVlaWbFOpVFq3k5qaivT0dHTs2FEqs7S0RMuWLREXFwcAiIuLg5WVlZQYAEDHjh1hZGSEo0ePanwtJgdERETFKDQ0FJaWlrItNFT7eXbp6ekAAAcHB1m5g4ODdCw9PR329vay4+XLl4eNjY1URxMcViAiIlKjy1GFoKAgBAYGysqUSqXuLlAMmBwQERGp0eXjk5VKpU6SAUdHRwDAjRs34OTkJJXfuHEDjRs3lurcvHlTdl5ubi7u3Lkjna8JDisQERGVAW5ubnB0dMSePf8tcc7KysLRo0fh5eUFAPDy8kJGRgbi4+OlOnv37kV+fj5atmyp8bXYc0BERFRK3L9/H8nJydJ+amoqEhISYGNjg2rVquHDDz/E559/jpo1a8LNzQ0zZsyAs7Oz9CyEunXromvXrhgzZgxWrlyJnJwcTJgwAUOGDNF4pQLA5ICIiKgAfT0E6cSJE/Dx8ZH2n85V8Pf3R1hYGKZOnYrs7GyMHTsWGRkZePPNN7Fjxw6YmJhI50RERGDChAnw9fWVHoK0bNkyreJgckBERFRKeHt7Qwjx3OMKhQIhISEICQl5bh0bGxtERka+UhxMDoiIiNQY+rsVOCGRiIiIZNhzQEREpMbAOw7Yc0BERERy7DkgIiJSY+hzDpgcEBERqTHw3IDDCkRERCTH5ICIiIhkOKxARESkxtDnHLDngIiIiGTYc0BERKTGwDsO2HNAREREckwOiIiISIbDCkRERGoMfUIikwMiIiI1Bp4bMDkgIiJSZ2Tg2QHnHBAREZEMkwMiIiKS4bACERGRGgMfVWDPAREREcmx54CIiEiNoS9lZM8BERERyTA5ICIiIhkOKxAREakx8FEFJgdERETqFEaGnR1wWIGIiIhkmBwQERGRDIcViIiI1HDOAREREcnwOQdEREREz2DPARERkRoD7zhgzwERERHJMTkgIiIiGQ4rEBERqTH0CYlMDoiIiNQYeG7AYQUiIiKSY3JARERUSri6ukKhUBTYxo8fDwDw9vYucOydd97ReRwcViAiIlKnp3GF48ePIy8vT9r/66+/0KlTJwwcOFAqGzNmDEJCQqT9ihUr6jwOJgdERESlhJ2dnWx/7ty5cHd3R/v27aWyihUrwtHRsVjj4LACERGRmsK69ou6qVQqZGVlyTaVSvXSGB4/fox169bh7bfflq2eiIiIgK2tLRo0aICgoCA8ePBA5/fP5ICIiKgYhYaGwtLSUraFhoa+9Lzo6GhkZGQgICBAKhs2bBjWrVuHmJgYBAUFYe3atRgxYoTOY+awAhERkRpdTjkICgpCYGCgrEypVL70vB9//BF+fn5wdnaWysaOHSt93bBhQzg5OcHX1xcpKSlwd3fXWcxMDoiIiIqRUqnUKBl41pUrV7B7925s3rz5hfVatmwJAEhOTmZyQEREVJwURvp9CtLq1athb2+P7t27v7BeQkICAMDJyUmn12dyQEREpEafT0jMz8/H6tWr4e/vj/Ll//sxnZKSgsjISHTr1g2VK1fG6dOnMWnSJLRr1w4eHh46jYHJARERUSmye/duXL16FW+//bas3NjYGLt378aSJUuQnZ2NqlWron///pg+fbrOY2ByQEREVIp07twZQogC5VWrVsX+/ftLJAYmB0RERGoM/a2MfM4BERERybDngIiISI2Bdxyw54CIiIjkmBwQERGRDIcViIiI1Bj6hEQmB0RERGoMPDfgsAIRERHJadxz0K9fP40bfdmLIoiIiKj00jg5sLS0lL4WQiAqKgqWlpZo1qwZACA+Ph4ZGRlaJRFERESlEeccaGj16tXS19OmTcOgQYOwcuVKlCtXDgCQl5eH9957DxYWFrqPkoiIqCQZ+KB7kW5/1apVmDx5spQYAEC5cuUQGBiIVatW6Sw4IiIiKnlFSg5yc3Nx/vz5AuXnz59Hfn7+KwdFRESkTwqFQmdbWVSkpYwjR47EqFGjkJKSghYtWgAAjh49irlz52LkyJE6DZCIiIhKVpGSg4ULF8LR0RGLFi1CWloaAMDJyQlTpkzBRx99pNMAiYiIqGQVKTkwMjLC1KlTMXXqVGRlZQEAJyISEdFro4yOBuhMkedj5ubmYvfu3Vi/fr00pnL9+nXcv39fZ8ERERHpA+ccFMGVK1fQtWtXXL16FSqVCp06dYK5uTnmzZsHlUqFlStX6jpOIiIiKiFF6jn44IMP0KxZM9y9exempqZSed++fbFnzx6dBUdEREQlr0g9BwcOHMDhw4dhbGwsK3d1dcU///yjk8CIiIj0pYyOBuhMkZKD/Px85OXlFSi/du0azM3NXzkoIiIivTLw7KBIwwqdO3fGkiVLpH2FQoH79+9j5syZ6Natm65iIyIiIj0oUs/BokWL0KVLF9SrVw+PHj3CsGHDkJSUBFtbW6xfv17XMRIREZUohZFh9xwUKTmoUqUKTp06hQ0bNuD06dO4f/8+Ro0aheHDh8smKBIREVHZU6Tk4NGjRzAxMcGIESN0HQ8RERHpWZHmHNjb28Pf3x+7du3ii5aIiOi1o1DobiuLipQchIeH48GDB+jduzfeeOMNfPjhhzhx4oSuYyMiItILQ39CYpGSg759+2LTpk24ceMG5syZg3PnzqFVq1aoVasWQkJCdB0jERERlaAiv1sBAMzNzTFy5Ejs3LkTp0+fRqVKlTBr1ixdxUZERER6UKQJiU89evQIv/76KyIjI7Fjxw44ODhgypQpuoqNilHC+QuI/G07zqdewe2MDIR+OBHtmnlKx4UQ+OGXaGyN2Y97Dx7Ao1ZNTB75P1R1dNRj1ES65VinChp1bwlbNwdUsjbHH19uxpX4JOm4a7NaqNexMWxdHWFibopfPlmN21duSsfNbC0wbOm7hba9a2k0Uo9dKPZ7oOJRRkcDdKZIycEff/yByMhIREdHo3z58hgwYAB27tyJdu3a6To+KiYPVSrUqFYV3du1xSdLvypwPGLb7/h55y5MHzcaTnZ2+P7nzQic9yXWzfsCSuMKeoiYSPcqKI1x++pNXNh/Gp0n9St43KQC0i9cQ8qR82g/xq/A8ezb97D2Pfnfn7odGsGjewv8fepSscVNVNyKlBz07dsXPXr0wJo1a9CtWzdUqMAfFmWNVyMPeDXyKPSYEAI/7dgF/9490bbpk96EGe+MQc/xH+BA/El09GpZkqESFZu/T1164Q/xpINnATzpISiMEAIPM7NlZa7NauHS0QvIVeXoLlAqeQbedVCk5ODGjRt8h8Jr7PqtW7idmYlmDepLZWYVK6Keuzv+SkpmckD0HLauDrB1dcChsF36DoXolWicHGRlZcHC4kn2LIRAVlbWc+s+rUdl052MTACAjdqfo42FBW5nZuojJKIyoba3B+7+8y9uJPHttGUdH5+sIWtra6SlpcHe3h5WVlaFrt0UQkChUBT6xsZnqVQqqFQqednjx1CqvQKaiKisKFehPGq0roeT0Yf1HQrRK9N4KePevXthY2MjfV3YFhMTg7179760rdDQUFhaWsq2pWFri34XpFM2VpYAgDtqvUN3srJQ2dJSHyERlXrVW9ZGeWUFJB34S9+hkA7o6wmJwcHBBR6iVKdOHen4o0ePMH78eFSuXBlmZmbo378/bty4oeO716LnoH379tLX3t7er3TRoKAgBAYGysrunTn5Sm2S7jjb2aGypSXiz55DLZdqAIDsBw9xLiUFfX199BwdUelUu70HrpxMxqN7D/UdCumCHick1q9fH7t375b2y5f/70f1pEmT8Ntvv2HTpk2wtLTEhAkT0K9fPxw6dEinMRRpQmLNmjUxfPhwDB8+HDVr1tT6fKVSCaVSKSt7zCGFEvXg0SNcu/Hfeu3rt27h4pWrsKhUCY62lTGoayeER29FFQcHONvb4vufo2BrZS2tXiB6HZRXVoClo7W0b2Fnicou9nh0/yGyb9+DspIJzGwtUNHKDABg6fSk9/RBRrZslYKFgxWc6lTF9gWbSvYG6LVUvnx5OBbyTJnMzEz8+OOPiIyMRIcOHQAAq1evRt26dXHkyBG0atVKdzEU5aT33nsPkZGRmD17Njw9PTFixAgMHjy40Juh0un8pcuYOGeetL88YgMAwK9tG0wfNxrDe3TDQ9VjzF8VhvsPHsCjVi0smhrIZxzQa8WuuiN6Th8m7Xv9zxcAcCH2DPZ/+ztcmtaA97ju0vGOE3sDAOJ/OYj4zf/9pla7vQey79zDtTOpJRQ5vc6SkpLg7OwMExMTeHl5ITQ0FNWqVUN8fDxycnLQsWNHqW6dOnVQrVo1xMXF6TQ5UAghRFFPvnjxIiIiIrB+/XqkpqbCx8cHI0aMwFtvvaV1W/8e5yQeInWblxzQdwhEpdLYiGnF2n7ijxt11lb1EX0KTMIvrAcdALZv34779++jdu3aSEtLw6xZs/DPP//gr7/+wtatWzFy5MgCbbVo0QI+Pj6YN29egfaK6pXerVCrVi3MmjULFy9exIEDB3Dr1i2MHDlSV7ERERGVeYVNwg8NDS20rp+fHwYOHAgPDw906dIFv//+OzIyMvDTTz+VaMyv9G4FADh27BgiIyOxceNGZGVlYeDAgbqIi4iISG90+ZyDwibhF9ZrUBgrKyvUqlULycnJ6NSpEx4/foyMjAxYWVlJdW7cuKHzYf0i9RxcvHgRM2fORK1atdCmTRskJiZi3rx5uHHjBjZs2KDTAImIiMoypVIJCwsL2aZpcnD//n2kpKTAyckJTZs2RYUKFbBnzx7p+IULF3D16lV4eXnpNOYi9RzUqVMHzZs3x/jx4zFkyBA4ODjoNCgiIiJDNHnyZPTs2RMuLi64fv06Zs6ciXLlymHo0KGwtLTEqFGjEBgYCBsbG1hYWGDixInw8vLS6WREoAjJQV5eHr799lsMGDAA1tbWLz+BiIiojCnsKcAl4dq1axg6dChu374NOzs7vPnmmzhy5Ajs7OwAAIsXL4aRkRH69+8PlUqFLl264JtvvtF5HEVarWBiYoLExES4ubnpLBCuViAqiKsViApX3KsVLoTr7pkVtf3L3ly8Is05aNCgAS5d4rvKiYiIXkdFSg4+//xzTJ48Gdu2bUNaWhqysrJkGxEREZVdRZqQ2K1bNwBAr169ZOMymr6VkYiIqDTT15yD0qJIyUFMTIyu4yAiIio1mBwUwbNvaCQiIqLXS5GSg9jY2Bceb9euXZGCISIiKhVe6eUCZV+RkgNvb+8CZc92wXDOARERUdlVpNzo7t27su3mzZvYsWMHmjdvjp07d+o6RiIiIipBReo5sLS0LFDWqVMnGBsbIzAwEPHx8a8cGBERkb5wQqIOOTg44MKFC7pskoiIqMQxOSiC06dPy/aFEEhLS8PcuXPRuHFjXcRFREREelKk5KBx48ZQKBRQfy1Dq1atsGrVKp0ERkRERPpRpOQgNTVVtm9kZAQ7OzuYmJjoJCgiIiK9MuxRBe1WK8TFxWHbtm1wcXGRtv3796Ndu3aoVq0axo4dC5VKVVyxEhERlQiFkUJnW1mkVXIQEhKCs2fPSvtnzpzBqFGj0LFjR3z88cfYunUrQkNDdR4kERERlRytkoOEhAT4+vpK+xs2bEDLli3x/fffIzAwEMuWLcNPP/2k8yCJiIio5Gg15+Du3btwcHCQ9vfv3w8/Pz9pv3nz5vj77791Fx0REZE+GPhSRq16DhwcHKTJiI8fP8bJkyfRqlUr6fi9e/dQoUIF3UZIREREJUqr5KBbt274+OOPceDAAQQFBaFixYpo27atdPz06dNwd3fXeZBEREQlSaHQ3VYWaTWsMHv2bPTr1w/t27eHmZkZwsPDYWxsLB1ftWoVOnfurPMgiYiIShKfkKgFW1tbxMbGIjMzE2ZmZihXrpzs+KZNm2BmZqbTAImIiKhk6ezFSwBgY2PzSsEQERGR/un0xUtERESvhTL68CJd0WpCIhEREb3+2HNARESkxtAnJLLngIiIiGTYc0BERKTOsDsO2HNAREREcuw5ICIiUmPocw6YHBAREalRcCkjERER0X+YHBAREZEMhxWIiIjUGficA/YcEBERkQx7DoiIiNQY+moF9hwQERGRDJMDIiKiUiI0NBTNmzeHubk57O3t0adPH1y4cEFWx9vbGwqFQra98847Oo2DyQEREZE6hQ43Lezfvx/jx4/HkSNHsGvXLuTk5KBz587Izs6W1RszZgzS0tKkbf78+UW+1cJwzgEREZEafT0EaceOHbL9sLAw2NvbIz4+Hu3atZPKK1asCEdHx2KLgz0HRERExUilUiErK0u2qVQqjc7NzMwEANjY2MjKIyIiYGtriwYNGiAoKAgPHjzQacxMDoiIiIpRaGgoLC0tZVtoaOhLz8vPz8eHH36INm3aoEGDBlL5sGHDsG7dOsTExCAoKAhr167FiBEjdBozhxWIiIjU6XApY1BQEAIDA2VlSqXypeeNHz8ef/31Fw4ePCgrHzt2rPR1w4YN4eTkBF9fX6SkpMDd3V0nMTM5ICIiUqPL5xwolUqNkoFnTZgwAdu2bUNsbCyqVKnywrotW7YEACQnJzM5ICIiet0IITBx4kRERUVh3759cHNze+k5CQkJAAAnJyedxcHkgIiISJ2eViuMHz8ekZGR2LJlC8zNzZGeng4AsLS0hKmpKVJSUhAZGYlu3bqhcuXKOH36NCZNmoR27drBw8NDZ3EwOSAiIiolVqxYAeDJg46etXr1agQEBMDY2Bi7d+/GkiVLkJ2djapVq6J///6YPn26TuNgckBERFRKCCFeeLxq1arYv39/scfB5ICIiEiNob94ickBERGROsPODfgQJCIiIpJjckBEREQyHFYgIiJSwzkHREREJKen5xyUFhxWICIiIhkmB0RERCTDYQUiIiI1hj7ngD0HREREJMOeAyIiInUG3nPA5ICIiEgNhxWIiIiInsHkgIiIiGQ4rEBERKSOD0EiIiIi+g97DoiIiNRwQiIRERHRM9hzQEREpI49B0RERET/Yc8BERGRGgVXKxARERH9h8kBERERyXBYgYiISJ2BT0hkckBERKSGzzkgIiIiegZ7DoiIiNSx54CIiIjoP0wOiIiISIbDCkRERGoM/SFITA6IiIjUcc4BERER0X+YHBAREZEMhxWIiIjUGfiwgkIIIfQdBJUeKpUKoaGhCAoKglKp1Hc4RKUC/16QoWFyQDJZWVmwtLREZmYmLCws9B0OUanAvxdkaDjngIiIiGSYHBAREZEMkwMiIiKSYXJAMkqlEjNnzuSkK6Jn8O8FGRpOSCQiIiIZ9hwQERGRDJMDIiIikmFyQERERDJMDkjngoOD0bhx42K/jqurK5YsWVLs1yF61r59+6BQKJCRkVGs1wkICECfPn2K9RpEz8PkoAQEBARAoVBg7ty5svLo6GgotHx+t6Y/EE+dOoVevXrB3t4eJiYmcHV1xeDBg3Hz5k2trlcUkydPxp49e4r9OmTYbt26hXfffRfVqlWDUqmEo6MjunTpgkOHDhXrdVu3bo20tDRYWloW63WI9InJQQkxMTHBvHnzcPfu3WK/1q1bt+Dr6wsbGxv88ccfSExMxOrVq+Hs7Izs7Owit/v48WON6pmZmaFy5cpFvg6RJvr3748///wT4eHhuHjxIn799Vd4e3vj9u3bRWpPCIHc3NyX1jM2Noajo6PWiT1RWcLkoIR07NgRjo6OCA0NfWG9X375BfXr14dSqYSrqysWLVokHfP29saVK1cwadIkKBSK5/7jdOjQIWRmZuKHH35AkyZN4ObmBh8fHyxevBhubm4AgLCwMFhZWcnOU+/JeDo88MMPP8DNzQ0mJib47rvv4OzsjPz8fNm5vXv3xttvvy07DwB27twJExOTAl2wH3zwATp06CDtHzx4EG3btoWpqSmqVq2K999/X5bI3Lx5Ez179oSpqSnc3NwQERHxwu8jvd4yMjJw4MABzJs3Dz4+PnBxcUGLFi0QFBSEXr164fLly1AoFEhISJCdo1AosG/fPgD/DQ9s374dTZs2hVKpxKpVq6BQKHD+/HnZ9RYvXgx3d3fZeRkZGcjKyoKpqSm2b98uqx8VFQVzc3M8ePAAAPD3339j0KBBsLKygo2NDXr37o3Lly9L9fPy8hAYGAgrKytUrlwZU6dOBVeZkz4xOSgh5cqVw5w5c7B8+XJcu3at0Drx8fEYNGgQhgwZgjNnziA4OBgzZsxAWFgYAGDz5s2oUqUKQkJCkJaWhrS0tELbcXR0RG5uLqKiol75H5jk5GT88ssv2Lx5MxISEjBw4EDcvn0bMTExUp07d+5gx44dGD58eIHzfX19YWVlhV9++UUqy8vLw8aNG6X6KSkp6Nq1K/r374/Tp09j48aNOHjwICZMmCCdExAQgL///hsxMTH4+eef8c0335TIEAmVTmZmZjAzM0N0dDRUKtUrtfXxxx9j7ty5SExMxIABA9CsWbMCyWdERASGDRtW4FwLCwv06NEDkZGRBer36dMHFStWRE5ODrp06QJzc3McOHAAhw4dgpmZGbp27Sr1xi1atAhhYWFYtWoVDh48iDt37iAqKuqV7ovolQgqdv7+/qJ3795CCCFatWol3n77bSGEEFFRUeLZP4Jhw4aJTp06yc6dMmWKqFevnrTv4uIiFi9e/NJrfvLJJ6J8+fLCxsZGdO3aVcyfP1+kp6dLx1evXi0sLS1l56jHM3PmTFGhQgVx8+ZNWb3evXtL9yCEEN9++61wdnYWeXl50nmNGjWSjn/wwQeiQ4cO0v4ff/whlEqluHv3rhBCiFGjRomxY8fKrnHgwAFhZGQkHj58KC5cuCAAiGPHjknHExMTBQCNvhf0evr555+FtbW1MDExEa1btxZBQUHi1KlTQgghUlNTBQDx559/SvXv3r0rAIiYmBghhBAxMTECgIiOjpa1u3jxYuHu7i7tP/38JSYmys57+vmNiooSZmZmIjs7WwghRGZmpjAxMRHbt28XQgixdu1aUbt2bZGfny+1qVKphKmpqfjjjz+EEEI4OTmJ+fPnS8dzcnJElSpVpH83iEoaew5K2Lx58xAeHo7ExMQCxxITE9GmTRtZWZs2bZCUlIS8vDytrvPFF18gPT0dK1euRP369bFy5UrUqVMHZ86c0aodFxcX2NnZycqGDx+OX375RfqNLSIiAkOGDIGRUeEfp+HDh2Pfvn24fv26VL979+7SsMapU6cQFhYm/TZoZmaGLl26ID8/H6mpqUhMTET58uXRtGlTqc06deoUGBYhw9K/f39cv34dv/76K7p27Yp9+/bB09NT6mnTVLNmzWT7Q4YMweXLl3HkyBEATz6vnp6eqFOnTqHnd+vWDRUqVMCvv/4K4MnQoIWFBTp27Ajgyec7OTkZ5ubm0ufbxsYGjx49QkpKCjIzM5GWloaWLVtKbZYvX75AXEQliclBCWvXrh26dOmCoKCgYr9W5cqVMXDgQCxcuBCJiYlwdnbGwoULAQBGRkYFhhxycnIKtFGpUqUCZT179oQQAr/99hv+/vtvHDhwoNAhhaeaN28Od3d3bNiwAQ8fPkRUVJSs/v379zFu3DgkJCRI26lTp5CUlCSN8xIVxsTEBJ06dcKMGTNw+PBhBAQEYObMmVKi+uxnvLDPN1DwM+7o6IgOHTpIQwWRkZEv/HwbGxtjwIABsvqDBw9G+fLlATz5fDdt2lT2+U5ISMDFixcLHaogKg3K6zsAQzR37lw0btwYtWvXlpXXrVu3wDKsQ4cOoVatWihXrhyAJ/8QaduL8PQ8d3d3aZKfnZ0d7t27h+zsbOkfx2cnb72IiYkJ+vXrh4iICCQnJ6N27drw9PR84TnDhw9HREQEqlSpAiMjI3Tv3l065unpiXPnzqFGjRqFnlunTh3k5uYiPj4ezZs3BwBcuHCh2NeZU9lTr149REdHS71daWlpaNKkCQDNP9/Ak8/r1KlTMXToUFy6dAlDhgx5af1OnTrh7Nmz2Lt3Lz7//HPpmKenJzZu3Ah7e3tYWFgUer6TkxOOHj2Kdu3aAYD0eX/Z3yuiYqPnYQ2D8Oycg6f+97//CRMTE9kYf3x8vDAyMhIhISHiwoULIiwsTJiamorVq1dLdTp16iR69eolrl27Jm7dulXo9bZu3SqGDx8utm7dKi5cuCDOnz8vFixYIMqVKyfWrFkjhBDi9u3bolKlSuL9998XycnJIiIiQjg7OxeYc/Ds3IFn7dq1SyiVSlG7dm0xe/Zs2bHCzktKShIAhIeHhxg1apTs2KlTp4SpqakYP368+PPPP8XFixdFdHS0GD9+vFSna9euokmTJuLIkSPixIkT4s033xSmpqacc2Cg/v33X+Hj4yPWrl0rTp06JS5duiR++ukn4eDgIM2HadWqlWjbtq04d+6c2Ldvn2jRokWhcw6ezh14VlZWljA1NRWNGjUSvr6+smOFnZefny+qVq0qGjVqJJuvIIQQ2dnZombNmsLb21vExsaKS5cuiZiYGDFx4kTx999/CyGEmDt3rrCxsRFRUVEiMTFRjBkzRpibm3POAekNk4MSUFhykJqaKoyNjYV6fvbzzz+LevXqiQoVKohq1aqJBQsWyI7HxcUJDw8PoVQqC5z7VEpKihgzZoyoVauWMDU1FVZWVqJ58+ayJEOIJxOpatSoIUxNTUWPHj3Ed999p3FykJeXJ5ycnAQAkZKSIjv2vPOe/uO8d+/eAseOHTsmOnXqJMzMzESlSpWEh4eH+OKLL6TjaWlponv37kKpVIpq1aqJNWvWaDw5k14/jx49Eh9//LHw9PQUlpaWomLFiqJ27dpi+vTp4sGDB0IIIc6dOye8vLyEqampaNy4sdi5c6fGyYEQQgwaNEgAEKtWrZKVP++8qVOnCgDis88+K9BWWlqaeOutt4Stra1QKpWievXqYsyYMSIzM1MI8WQC4gcffCAsLCyElZWVCAwMFG+99RaTA9IbvrKZiIiIZDghkYiIiGSYHBAREZEMkwMiIiKSYXJAREREMkwOiIiISIbJAREREckwOSAiIiIZJgdEREQkw+SAiIiIZJgcEBERkQyTAyIiIpJhckBEREQy/wfnZbZdVyB2MgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2_cf = confusion_matrix(y_test_normalize, pred)\n",
    "plot_cm(model2_cf, 'Model 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Survived</th>\n",
       "      <td>0.952607</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.960725</td>\n",
       "      <td>0.960725</td>\n",
       "      <td>0.960725</td>\n",
       "      <td>0.960725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.963803</td>\n",
       "      <td>0.953277</td>\n",
       "      <td>0.958022</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.961199</td>\n",
       "      <td>0.960725</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "Not Survived   0.952607  0.985294  0.968675  204.000000\n",
       "Survived       0.975000  0.921260  0.947368  127.000000\n",
       "accuracy       0.960725  0.960725  0.960725    0.960725\n",
       "macro avg      0.963803  0.953277  0.958022  331.000000\n",
       "weighted avg   0.961199  0.960725  0.960500  331.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_report = classification_report(y_test_normalize, pred, output_dict=True, target_names=['Not Survived',\"Survived\"])\n",
    "pd.DataFrame(model2_report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data tidak dinormalisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: Training Accuracy = 68.68%\n",
      "Epoch 2/1000: Training Accuracy = 68.96%\n",
      "Epoch 3/1000: Training Accuracy = 71.91%\n",
      "Epoch 4/1000: Training Accuracy = 69.24%\n",
      "Epoch 5/1000: Training Accuracy = 70.79%\n",
      "Epoch 6/1000: Training Accuracy = 70.51%\n",
      "Epoch 7/1000: Training Accuracy = 58.85%\n",
      "Epoch 8/1000: Training Accuracy = 66.15%\n",
      "Epoch 9/1000: Training Accuracy = 67.98%\n",
      "Epoch 10/1000: Training Accuracy = 69.52%\n",
      "Epoch 11/1000: Training Accuracy = 69.94%\n",
      "Epoch 12/1000: Training Accuracy = 67.42%\n",
      "Epoch 13/1000: Training Accuracy = 67.98%\n",
      "Epoch 14/1000: Training Accuracy = 73.88%\n",
      "Epoch 15/1000: Training Accuracy = 68.40%\n",
      "Epoch 16/1000: Training Accuracy = 72.33%\n",
      "Epoch 17/1000: Training Accuracy = 72.47%\n",
      "Epoch 18/1000: Training Accuracy = 76.12%\n",
      "Epoch 19/1000: Training Accuracy = 74.30%\n",
      "Epoch 20/1000: Training Accuracy = 70.08%\n",
      "Epoch 21/1000: Training Accuracy = 73.31%\n",
      "Epoch 22/1000: Training Accuracy = 71.07%\n",
      "Epoch 23/1000: Training Accuracy = 74.16%\n",
      "Epoch 24/1000: Training Accuracy = 71.21%\n",
      "Epoch 25/1000: Training Accuracy = 73.31%\n",
      "Epoch 26/1000: Training Accuracy = 72.33%\n",
      "Epoch 27/1000: Training Accuracy = 71.35%\n",
      "Epoch 28/1000: Training Accuracy = 75.14%\n",
      "Epoch 29/1000: Training Accuracy = 70.79%\n",
      "Epoch 30/1000: Training Accuracy = 74.44%\n",
      "Epoch 31/1000: Training Accuracy = 71.77%\n",
      "Epoch 32/1000: Training Accuracy = 71.49%\n",
      "Epoch 33/1000: Training Accuracy = 75.28%\n",
      "Epoch 34/1000: Training Accuracy = 72.05%\n",
      "Epoch 35/1000: Training Accuracy = 72.19%\n",
      "Epoch 36/1000: Training Accuracy = 70.37%\n",
      "Epoch 37/1000: Training Accuracy = 75.70%\n",
      "Epoch 38/1000: Training Accuracy = 73.60%\n",
      "Epoch 39/1000: Training Accuracy = 71.21%\n",
      "Epoch 40/1000: Training Accuracy = 74.30%\n",
      "Epoch 41/1000: Training Accuracy = 75.28%\n",
      "Epoch 42/1000: Training Accuracy = 75.42%\n",
      "Epoch 43/1000: Training Accuracy = 71.77%\n",
      "Epoch 44/1000: Training Accuracy = 75.56%\n",
      "Epoch 45/1000: Training Accuracy = 71.21%\n",
      "Epoch 46/1000: Training Accuracy = 74.30%\n",
      "Epoch 47/1000: Training Accuracy = 74.02%\n",
      "Epoch 48/1000: Training Accuracy = 73.88%\n",
      "Epoch 49/1000: Training Accuracy = 73.03%\n",
      "Epoch 50/1000: Training Accuracy = 75.14%\n",
      "Epoch 51/1000: Training Accuracy = 72.19%\n",
      "Epoch 52/1000: Training Accuracy = 74.30%\n",
      "Epoch 53/1000: Training Accuracy = 74.16%\n",
      "Epoch 54/1000: Training Accuracy = 74.44%\n",
      "Epoch 55/1000: Training Accuracy = 74.44%\n",
      "Epoch 56/1000: Training Accuracy = 76.97%\n",
      "Epoch 57/1000: Training Accuracy = 74.86%\n",
      "Epoch 58/1000: Training Accuracy = 74.44%\n",
      "Epoch 59/1000: Training Accuracy = 77.39%\n",
      "Epoch 60/1000: Training Accuracy = 75.98%\n",
      "Epoch 61/1000: Training Accuracy = 74.58%\n",
      "Epoch 62/1000: Training Accuracy = 76.12%\n",
      "Epoch 63/1000: Training Accuracy = 73.88%\n",
      "Epoch 64/1000: Training Accuracy = 76.12%\n",
      "Epoch 65/1000: Training Accuracy = 76.12%\n",
      "Epoch 66/1000: Training Accuracy = 76.12%\n",
      "Epoch 67/1000: Training Accuracy = 75.98%\n",
      "Epoch 68/1000: Training Accuracy = 73.03%\n",
      "Epoch 69/1000: Training Accuracy = 73.74%\n",
      "Epoch 70/1000: Training Accuracy = 76.69%\n",
      "Epoch 71/1000: Training Accuracy = 76.26%\n",
      "Epoch 72/1000: Training Accuracy = 74.16%\n",
      "Epoch 73/1000: Training Accuracy = 73.46%\n",
      "Epoch 74/1000: Training Accuracy = 76.40%\n",
      "Epoch 75/1000: Training Accuracy = 73.60%\n",
      "Epoch 76/1000: Training Accuracy = 76.40%\n",
      "Epoch 77/1000: Training Accuracy = 77.11%\n",
      "Epoch 78/1000: Training Accuracy = 73.31%\n",
      "Epoch 79/1000: Training Accuracy = 73.17%\n",
      "Epoch 80/1000: Training Accuracy = 71.77%\n",
      "Epoch 81/1000: Training Accuracy = 73.60%\n",
      "Epoch 82/1000: Training Accuracy = 73.74%\n",
      "Epoch 83/1000: Training Accuracy = 71.07%\n",
      "Epoch 84/1000: Training Accuracy = 73.88%\n",
      "Epoch 85/1000: Training Accuracy = 76.12%\n",
      "Epoch 86/1000: Training Accuracy = 76.12%\n",
      "Epoch 87/1000: Training Accuracy = 73.60%\n",
      "Epoch 88/1000: Training Accuracy = 73.17%\n",
      "Epoch 89/1000: Training Accuracy = 75.70%\n",
      "Epoch 90/1000: Training Accuracy = 74.72%\n",
      "Epoch 91/1000: Training Accuracy = 76.12%\n",
      "Epoch 92/1000: Training Accuracy = 74.58%\n",
      "Epoch 93/1000: Training Accuracy = 77.53%\n",
      "Epoch 94/1000: Training Accuracy = 73.60%\n",
      "Epoch 95/1000: Training Accuracy = 74.30%\n",
      "Epoch 96/1000: Training Accuracy = 76.12%\n",
      "Epoch 97/1000: Training Accuracy = 77.67%\n",
      "Epoch 98/1000: Training Accuracy = 75.42%\n",
      "Epoch 99/1000: Training Accuracy = 76.69%\n",
      "Epoch 100/1000: Training Accuracy = 76.69%\n",
      "Epoch 101/1000: Training Accuracy = 75.84%\n",
      "Epoch 102/1000: Training Accuracy = 76.69%\n",
      "Epoch 103/1000: Training Accuracy = 73.60%\n",
      "Epoch 104/1000: Training Accuracy = 76.26%\n",
      "Epoch 105/1000: Training Accuracy = 77.53%\n",
      "Epoch 106/1000: Training Accuracy = 76.97%\n",
      "Epoch 107/1000: Training Accuracy = 73.60%\n",
      "Epoch 108/1000: Training Accuracy = 74.86%\n",
      "Epoch 109/1000: Training Accuracy = 75.00%\n",
      "Epoch 110/1000: Training Accuracy = 74.30%\n",
      "Epoch 111/1000: Training Accuracy = 75.56%\n",
      "Epoch 112/1000: Training Accuracy = 74.44%\n",
      "Epoch 113/1000: Training Accuracy = 74.58%\n",
      "Epoch 114/1000: Training Accuracy = 76.69%\n",
      "Epoch 115/1000: Training Accuracy = 76.26%\n",
      "Epoch 116/1000: Training Accuracy = 76.40%\n",
      "Epoch 117/1000: Training Accuracy = 75.98%\n",
      "Epoch 118/1000: Training Accuracy = 74.72%\n",
      "Epoch 119/1000: Training Accuracy = 75.84%\n",
      "Epoch 120/1000: Training Accuracy = 76.26%\n",
      "Epoch 121/1000: Training Accuracy = 75.98%\n",
      "Epoch 122/1000: Training Accuracy = 77.25%\n",
      "Epoch 123/1000: Training Accuracy = 76.97%\n",
      "Epoch 124/1000: Training Accuracy = 75.14%\n",
      "Epoch 125/1000: Training Accuracy = 73.60%\n",
      "Epoch 126/1000: Training Accuracy = 76.54%\n",
      "Epoch 127/1000: Training Accuracy = 75.70%\n",
      "Epoch 128/1000: Training Accuracy = 75.14%\n",
      "Epoch 129/1000: Training Accuracy = 75.84%\n",
      "Epoch 130/1000: Training Accuracy = 73.74%\n",
      "Epoch 131/1000: Training Accuracy = 75.84%\n",
      "Epoch 132/1000: Training Accuracy = 75.14%\n",
      "Epoch 133/1000: Training Accuracy = 74.86%\n",
      "Epoch 134/1000: Training Accuracy = 75.84%\n",
      "Epoch 135/1000: Training Accuracy = 74.86%\n",
      "Epoch 136/1000: Training Accuracy = 76.83%\n",
      "Epoch 137/1000: Training Accuracy = 75.98%\n",
      "Epoch 138/1000: Training Accuracy = 76.12%\n",
      "Epoch 139/1000: Training Accuracy = 74.02%\n",
      "Epoch 140/1000: Training Accuracy = 76.69%\n",
      "Epoch 141/1000: Training Accuracy = 75.70%\n",
      "Epoch 142/1000: Training Accuracy = 76.12%\n",
      "Epoch 143/1000: Training Accuracy = 74.72%\n",
      "Epoch 144/1000: Training Accuracy = 76.12%\n",
      "Epoch 145/1000: Training Accuracy = 76.12%\n",
      "Epoch 146/1000: Training Accuracy = 76.12%\n",
      "Epoch 147/1000: Training Accuracy = 76.12%\n",
      "Epoch 148/1000: Training Accuracy = 76.97%\n",
      "Epoch 149/1000: Training Accuracy = 76.12%\n",
      "Epoch 150/1000: Training Accuracy = 75.98%\n",
      "Epoch 151/1000: Training Accuracy = 75.70%\n",
      "Epoch 152/1000: Training Accuracy = 76.40%\n",
      "Epoch 153/1000: Training Accuracy = 77.25%\n",
      "Epoch 154/1000: Training Accuracy = 75.84%\n",
      "Epoch 155/1000: Training Accuracy = 77.11%\n",
      "Epoch 156/1000: Training Accuracy = 74.58%\n",
      "Epoch 157/1000: Training Accuracy = 77.39%\n",
      "Epoch 158/1000: Training Accuracy = 75.00%\n",
      "Epoch 159/1000: Training Accuracy = 76.26%\n",
      "Epoch 160/1000: Training Accuracy = 74.02%\n",
      "Epoch 161/1000: Training Accuracy = 74.72%\n",
      "Epoch 162/1000: Training Accuracy = 76.12%\n",
      "Epoch 163/1000: Training Accuracy = 74.16%\n",
      "Epoch 164/1000: Training Accuracy = 75.84%\n",
      "Epoch 165/1000: Training Accuracy = 76.83%\n",
      "Epoch 166/1000: Training Accuracy = 77.25%\n",
      "Epoch 167/1000: Training Accuracy = 74.86%\n",
      "Epoch 168/1000: Training Accuracy = 76.26%\n",
      "Epoch 169/1000: Training Accuracy = 75.56%\n",
      "Epoch 170/1000: Training Accuracy = 75.98%\n",
      "Epoch 171/1000: Training Accuracy = 75.14%\n",
      "Epoch 172/1000: Training Accuracy = 75.98%\n",
      "Epoch 173/1000: Training Accuracy = 75.84%\n",
      "Epoch 174/1000: Training Accuracy = 75.56%\n",
      "Epoch 175/1000: Training Accuracy = 74.58%\n",
      "Epoch 176/1000: Training Accuracy = 76.12%\n",
      "Epoch 177/1000: Training Accuracy = 74.86%\n",
      "Epoch 178/1000: Training Accuracy = 76.54%\n",
      "Epoch 179/1000: Training Accuracy = 76.12%\n",
      "Epoch 180/1000: Training Accuracy = 76.26%\n",
      "Epoch 181/1000: Training Accuracy = 76.12%\n",
      "Epoch 182/1000: Training Accuracy = 75.84%\n",
      "Epoch 183/1000: Training Accuracy = 76.12%\n",
      "Epoch 184/1000: Training Accuracy = 75.70%\n",
      "Epoch 185/1000: Training Accuracy = 76.26%\n",
      "Epoch 186/1000: Training Accuracy = 76.97%\n",
      "Epoch 187/1000: Training Accuracy = 76.40%\n",
      "Epoch 188/1000: Training Accuracy = 76.26%\n",
      "Epoch 189/1000: Training Accuracy = 76.40%\n",
      "Epoch 190/1000: Training Accuracy = 75.00%\n",
      "Epoch 191/1000: Training Accuracy = 76.26%\n",
      "Epoch 192/1000: Training Accuracy = 75.98%\n",
      "Epoch 193/1000: Training Accuracy = 76.12%\n",
      "Epoch 194/1000: Training Accuracy = 76.97%\n",
      "Epoch 195/1000: Training Accuracy = 76.83%\n",
      "Epoch 196/1000: Training Accuracy = 77.11%\n",
      "Epoch 197/1000: Training Accuracy = 76.97%\n",
      "Epoch 198/1000: Training Accuracy = 76.97%\n",
      "Epoch 199/1000: Training Accuracy = 76.97%\n",
      "Epoch 200/1000: Training Accuracy = 76.97%\n",
      "Epoch 201/1000: Training Accuracy = 75.84%\n",
      "Epoch 202/1000: Training Accuracy = 76.40%\n",
      "Epoch 203/1000: Training Accuracy = 76.12%\n",
      "Epoch 204/1000: Training Accuracy = 69.38%\n",
      "Epoch 205/1000: Training Accuracy = 75.70%\n",
      "Epoch 206/1000: Training Accuracy = 76.12%\n",
      "Epoch 207/1000: Training Accuracy = 76.69%\n",
      "Epoch 208/1000: Training Accuracy = 76.69%\n",
      "Epoch 209/1000: Training Accuracy = 76.97%\n",
      "Epoch 210/1000: Training Accuracy = 75.84%\n",
      "Epoch 211/1000: Training Accuracy = 76.83%\n",
      "Epoch 212/1000: Training Accuracy = 76.26%\n",
      "Epoch 213/1000: Training Accuracy = 75.28%\n",
      "Epoch 214/1000: Training Accuracy = 75.56%\n",
      "Epoch 215/1000: Training Accuracy = 76.40%\n",
      "Epoch 216/1000: Training Accuracy = 76.97%\n",
      "Epoch 217/1000: Training Accuracy = 76.97%\n",
      "Epoch 218/1000: Training Accuracy = 76.83%\n",
      "Epoch 219/1000: Training Accuracy = 76.69%\n",
      "Epoch 220/1000: Training Accuracy = 75.00%\n",
      "Epoch 221/1000: Training Accuracy = 77.25%\n",
      "Epoch 222/1000: Training Accuracy = 75.98%\n",
      "Epoch 223/1000: Training Accuracy = 77.25%\n",
      "Epoch 224/1000: Training Accuracy = 77.11%\n",
      "Epoch 225/1000: Training Accuracy = 75.14%\n",
      "Epoch 226/1000: Training Accuracy = 76.83%\n",
      "Epoch 227/1000: Training Accuracy = 75.84%\n",
      "Epoch 228/1000: Training Accuracy = 76.83%\n",
      "Epoch 229/1000: Training Accuracy = 76.54%\n",
      "Epoch 230/1000: Training Accuracy = 77.39%\n",
      "Epoch 231/1000: Training Accuracy = 74.44%\n",
      "Epoch 232/1000: Training Accuracy = 77.95%\n",
      "Epoch 233/1000: Training Accuracy = 71.35%\n",
      "Epoch 234/1000: Training Accuracy = 76.54%\n",
      "Epoch 235/1000: Training Accuracy = 75.98%\n",
      "Epoch 236/1000: Training Accuracy = 76.40%\n",
      "Epoch 237/1000: Training Accuracy = 76.83%\n",
      "Epoch 238/1000: Training Accuracy = 71.21%\n",
      "Epoch 239/1000: Training Accuracy = 75.42%\n",
      "Epoch 240/1000: Training Accuracy = 76.69%\n",
      "Epoch 241/1000: Training Accuracy = 77.25%\n",
      "Epoch 242/1000: Training Accuracy = 72.05%\n",
      "Epoch 243/1000: Training Accuracy = 77.25%\n",
      "Epoch 244/1000: Training Accuracy = 76.40%\n",
      "Epoch 245/1000: Training Accuracy = 76.26%\n",
      "Epoch 246/1000: Training Accuracy = 77.53%\n",
      "Epoch 247/1000: Training Accuracy = 76.97%\n",
      "Epoch 248/1000: Training Accuracy = 76.83%\n",
      "Epoch 249/1000: Training Accuracy = 76.26%\n",
      "Epoch 250/1000: Training Accuracy = 76.12%\n",
      "Epoch 251/1000: Training Accuracy = 71.91%\n",
      "Epoch 252/1000: Training Accuracy = 76.97%\n",
      "Epoch 253/1000: Training Accuracy = 76.97%\n",
      "Epoch 254/1000: Training Accuracy = 77.53%\n",
      "Epoch 255/1000: Training Accuracy = 76.83%\n",
      "Epoch 256/1000: Training Accuracy = 77.39%\n",
      "Epoch 257/1000: Training Accuracy = 69.66%\n",
      "Epoch 258/1000: Training Accuracy = 77.39%\n",
      "Epoch 259/1000: Training Accuracy = 77.53%\n",
      "Epoch 260/1000: Training Accuracy = 74.30%\n",
      "Epoch 261/1000: Training Accuracy = 74.30%\n",
      "Epoch 262/1000: Training Accuracy = 71.91%\n",
      "Epoch 263/1000: Training Accuracy = 77.11%\n",
      "Epoch 264/1000: Training Accuracy = 77.25%\n",
      "Epoch 265/1000: Training Accuracy = 76.97%\n",
      "Epoch 266/1000: Training Accuracy = 76.54%\n",
      "Epoch 267/1000: Training Accuracy = 76.97%\n",
      "Epoch 268/1000: Training Accuracy = 77.39%\n",
      "Epoch 269/1000: Training Accuracy = 77.53%\n",
      "Epoch 270/1000: Training Accuracy = 76.69%\n",
      "Epoch 271/1000: Training Accuracy = 75.42%\n",
      "Epoch 272/1000: Training Accuracy = 75.70%\n",
      "Epoch 273/1000: Training Accuracy = 71.63%\n",
      "Epoch 274/1000: Training Accuracy = 76.54%\n",
      "Epoch 275/1000: Training Accuracy = 77.25%\n",
      "Epoch 276/1000: Training Accuracy = 72.19%\n",
      "Epoch 277/1000: Training Accuracy = 75.98%\n",
      "Epoch 278/1000: Training Accuracy = 76.69%\n",
      "Epoch 279/1000: Training Accuracy = 75.28%\n",
      "Epoch 280/1000: Training Accuracy = 75.98%\n",
      "Epoch 281/1000: Training Accuracy = 76.40%\n",
      "Epoch 282/1000: Training Accuracy = 76.54%\n",
      "Epoch 283/1000: Training Accuracy = 77.53%\n",
      "Epoch 284/1000: Training Accuracy = 76.69%\n",
      "Epoch 285/1000: Training Accuracy = 77.25%\n",
      "Epoch 286/1000: Training Accuracy = 77.25%\n",
      "Epoch 287/1000: Training Accuracy = 76.40%\n",
      "Epoch 288/1000: Training Accuracy = 76.83%\n",
      "Epoch 289/1000: Training Accuracy = 75.98%\n",
      "Epoch 290/1000: Training Accuracy = 77.39%\n",
      "Epoch 291/1000: Training Accuracy = 77.11%\n",
      "Epoch 292/1000: Training Accuracy = 75.70%\n",
      "Epoch 293/1000: Training Accuracy = 77.53%\n",
      "Epoch 294/1000: Training Accuracy = 76.83%\n",
      "Epoch 295/1000: Training Accuracy = 77.53%\n",
      "Epoch 296/1000: Training Accuracy = 75.98%\n",
      "Epoch 297/1000: Training Accuracy = 76.83%\n",
      "Epoch 298/1000: Training Accuracy = 76.83%\n",
      "Epoch 299/1000: Training Accuracy = 76.54%\n",
      "Epoch 300/1000: Training Accuracy = 71.21%\n",
      "Epoch 301/1000: Training Accuracy = 77.53%\n",
      "Epoch 302/1000: Training Accuracy = 76.26%\n",
      "Epoch 303/1000: Training Accuracy = 75.98%\n",
      "Epoch 304/1000: Training Accuracy = 76.54%\n",
      "Epoch 305/1000: Training Accuracy = 75.84%\n",
      "Epoch 306/1000: Training Accuracy = 76.69%\n",
      "Epoch 307/1000: Training Accuracy = 76.97%\n",
      "Epoch 308/1000: Training Accuracy = 77.39%\n",
      "Epoch 309/1000: Training Accuracy = 76.69%\n",
      "Epoch 310/1000: Training Accuracy = 77.11%\n",
      "Epoch 311/1000: Training Accuracy = 77.11%\n",
      "Epoch 312/1000: Training Accuracy = 77.25%\n",
      "Epoch 313/1000: Training Accuracy = 76.97%\n",
      "Epoch 314/1000: Training Accuracy = 77.25%\n",
      "Epoch 315/1000: Training Accuracy = 76.40%\n",
      "Epoch 316/1000: Training Accuracy = 76.69%\n",
      "Epoch 317/1000: Training Accuracy = 75.28%\n",
      "Epoch 318/1000: Training Accuracy = 75.70%\n",
      "Epoch 319/1000: Training Accuracy = 76.83%\n",
      "Epoch 320/1000: Training Accuracy = 77.11%\n",
      "Epoch 321/1000: Training Accuracy = 76.40%\n",
      "Epoch 322/1000: Training Accuracy = 76.69%\n",
      "Epoch 323/1000: Training Accuracy = 77.67%\n",
      "Epoch 324/1000: Training Accuracy = 77.11%\n",
      "Epoch 325/1000: Training Accuracy = 76.26%\n",
      "Epoch 326/1000: Training Accuracy = 76.97%\n",
      "Epoch 327/1000: Training Accuracy = 76.54%\n",
      "Epoch 328/1000: Training Accuracy = 76.83%\n",
      "Epoch 329/1000: Training Accuracy = 76.83%\n",
      "Epoch 330/1000: Training Accuracy = 77.39%\n",
      "Epoch 331/1000: Training Accuracy = 75.70%\n",
      "Epoch 332/1000: Training Accuracy = 75.70%\n",
      "Epoch 333/1000: Training Accuracy = 76.83%\n",
      "Epoch 334/1000: Training Accuracy = 75.98%\n",
      "Epoch 335/1000: Training Accuracy = 77.67%\n",
      "Epoch 336/1000: Training Accuracy = 76.40%\n",
      "Epoch 337/1000: Training Accuracy = 76.83%\n",
      "Epoch 338/1000: Training Accuracy = 76.69%\n",
      "Epoch 339/1000: Training Accuracy = 77.25%\n",
      "Epoch 340/1000: Training Accuracy = 75.98%\n",
      "Epoch 341/1000: Training Accuracy = 76.26%\n",
      "Epoch 342/1000: Training Accuracy = 77.25%\n",
      "Epoch 343/1000: Training Accuracy = 75.84%\n",
      "Epoch 344/1000: Training Accuracy = 77.39%\n",
      "Epoch 345/1000: Training Accuracy = 76.26%\n",
      "Epoch 346/1000: Training Accuracy = 76.97%\n",
      "Epoch 347/1000: Training Accuracy = 77.39%\n",
      "Epoch 348/1000: Training Accuracy = 76.69%\n",
      "Epoch 349/1000: Training Accuracy = 76.83%\n",
      "Epoch 350/1000: Training Accuracy = 76.69%\n",
      "Epoch 351/1000: Training Accuracy = 76.97%\n",
      "Epoch 352/1000: Training Accuracy = 77.11%\n",
      "Epoch 353/1000: Training Accuracy = 77.11%\n",
      "Epoch 354/1000: Training Accuracy = 76.69%\n",
      "Epoch 355/1000: Training Accuracy = 77.11%\n",
      "Epoch 356/1000: Training Accuracy = 76.97%\n",
      "Epoch 357/1000: Training Accuracy = 76.40%\n",
      "Epoch 358/1000: Training Accuracy = 77.39%\n",
      "Epoch 359/1000: Training Accuracy = 77.11%\n",
      "Epoch 360/1000: Training Accuracy = 74.86%\n",
      "Epoch 361/1000: Training Accuracy = 76.12%\n",
      "Epoch 362/1000: Training Accuracy = 76.97%\n",
      "Epoch 363/1000: Training Accuracy = 76.54%\n",
      "Epoch 364/1000: Training Accuracy = 77.25%\n",
      "Epoch 365/1000: Training Accuracy = 73.31%\n",
      "Epoch 366/1000: Training Accuracy = 76.83%\n",
      "Epoch 367/1000: Training Accuracy = 77.39%\n",
      "Epoch 368/1000: Training Accuracy = 77.67%\n",
      "Epoch 369/1000: Training Accuracy = 77.25%\n",
      "Epoch 370/1000: Training Accuracy = 76.54%\n",
      "Epoch 371/1000: Training Accuracy = 73.17%\n",
      "Epoch 372/1000: Training Accuracy = 76.54%\n",
      "Epoch 373/1000: Training Accuracy = 76.26%\n",
      "Epoch 374/1000: Training Accuracy = 77.39%\n",
      "Epoch 375/1000: Training Accuracy = 76.97%\n",
      "Epoch 376/1000: Training Accuracy = 76.83%\n",
      "Epoch 377/1000: Training Accuracy = 77.25%\n",
      "Epoch 378/1000: Training Accuracy = 76.97%\n",
      "Epoch 379/1000: Training Accuracy = 76.54%\n",
      "Epoch 380/1000: Training Accuracy = 77.39%\n",
      "Epoch 381/1000: Training Accuracy = 76.83%\n",
      "Epoch 382/1000: Training Accuracy = 77.25%\n",
      "Epoch 383/1000: Training Accuracy = 76.97%\n",
      "Epoch 384/1000: Training Accuracy = 76.12%\n",
      "Epoch 385/1000: Training Accuracy = 76.40%\n",
      "Epoch 386/1000: Training Accuracy = 76.83%\n",
      "Epoch 387/1000: Training Accuracy = 76.26%\n",
      "Epoch 388/1000: Training Accuracy = 76.83%\n",
      "Epoch 389/1000: Training Accuracy = 76.40%\n",
      "Epoch 390/1000: Training Accuracy = 76.26%\n",
      "Epoch 391/1000: Training Accuracy = 76.26%\n",
      "Epoch 392/1000: Training Accuracy = 77.25%\n",
      "Epoch 393/1000: Training Accuracy = 77.25%\n",
      "Epoch 394/1000: Training Accuracy = 76.69%\n",
      "Epoch 395/1000: Training Accuracy = 77.67%\n",
      "Epoch 396/1000: Training Accuracy = 76.26%\n",
      "Epoch 397/1000: Training Accuracy = 77.39%\n",
      "Epoch 398/1000: Training Accuracy = 75.42%\n",
      "Epoch 399/1000: Training Accuracy = 75.98%\n",
      "Epoch 400/1000: Training Accuracy = 76.97%\n",
      "Epoch 401/1000: Training Accuracy = 71.35%\n",
      "Epoch 402/1000: Training Accuracy = 77.25%\n",
      "Epoch 403/1000: Training Accuracy = 76.69%\n",
      "Epoch 404/1000: Training Accuracy = 77.25%\n",
      "Epoch 405/1000: Training Accuracy = 76.97%\n",
      "Epoch 406/1000: Training Accuracy = 77.25%\n",
      "Epoch 407/1000: Training Accuracy = 77.39%\n",
      "Epoch 408/1000: Training Accuracy = 74.44%\n",
      "Epoch 409/1000: Training Accuracy = 77.39%\n",
      "Epoch 410/1000: Training Accuracy = 72.47%\n",
      "Epoch 411/1000: Training Accuracy = 77.25%\n",
      "Epoch 412/1000: Training Accuracy = 77.11%\n",
      "Epoch 413/1000: Training Accuracy = 77.39%\n",
      "Epoch 414/1000: Training Accuracy = 77.39%\n",
      "Epoch 415/1000: Training Accuracy = 76.54%\n",
      "Epoch 416/1000: Training Accuracy = 76.97%\n",
      "Epoch 417/1000: Training Accuracy = 77.25%\n",
      "Epoch 418/1000: Training Accuracy = 76.54%\n",
      "Epoch 419/1000: Training Accuracy = 77.11%\n",
      "Epoch 420/1000: Training Accuracy = 75.42%\n",
      "Epoch 421/1000: Training Accuracy = 77.67%\n",
      "Epoch 422/1000: Training Accuracy = 77.67%\n",
      "Epoch 423/1000: Training Accuracy = 77.11%\n",
      "Epoch 424/1000: Training Accuracy = 77.11%\n",
      "Epoch 425/1000: Training Accuracy = 76.97%\n",
      "Epoch 426/1000: Training Accuracy = 76.40%\n",
      "Epoch 427/1000: Training Accuracy = 77.39%\n",
      "Epoch 428/1000: Training Accuracy = 77.53%\n",
      "Epoch 429/1000: Training Accuracy = 76.97%\n",
      "Epoch 430/1000: Training Accuracy = 76.26%\n",
      "Epoch 431/1000: Training Accuracy = 77.39%\n",
      "Epoch 432/1000: Training Accuracy = 76.69%\n",
      "Epoch 433/1000: Training Accuracy = 76.54%\n",
      "Epoch 434/1000: Training Accuracy = 76.26%\n",
      "Epoch 435/1000: Training Accuracy = 78.09%\n",
      "Epoch 436/1000: Training Accuracy = 77.67%\n",
      "Epoch 437/1000: Training Accuracy = 77.25%\n",
      "Epoch 438/1000: Training Accuracy = 74.86%\n",
      "Epoch 439/1000: Training Accuracy = 76.97%\n",
      "Epoch 440/1000: Training Accuracy = 75.00%\n",
      "Epoch 441/1000: Training Accuracy = 77.39%\n",
      "Epoch 442/1000: Training Accuracy = 77.95%\n",
      "Epoch 443/1000: Training Accuracy = 77.53%\n",
      "Epoch 444/1000: Training Accuracy = 77.39%\n",
      "Epoch 445/1000: Training Accuracy = 76.83%\n",
      "Epoch 446/1000: Training Accuracy = 77.39%\n",
      "Epoch 447/1000: Training Accuracy = 75.56%\n",
      "Epoch 448/1000: Training Accuracy = 77.53%\n",
      "Epoch 449/1000: Training Accuracy = 77.39%\n",
      "Epoch 450/1000: Training Accuracy = 77.25%\n",
      "Epoch 451/1000: Training Accuracy = 75.70%\n",
      "Epoch 452/1000: Training Accuracy = 77.11%\n",
      "Epoch 453/1000: Training Accuracy = 77.39%\n",
      "Epoch 454/1000: Training Accuracy = 77.53%\n",
      "Epoch 455/1000: Training Accuracy = 77.53%\n",
      "Epoch 456/1000: Training Accuracy = 77.11%\n",
      "Epoch 457/1000: Training Accuracy = 77.39%\n",
      "Epoch 458/1000: Training Accuracy = 75.70%\n",
      "Epoch 459/1000: Training Accuracy = 77.53%\n",
      "Epoch 460/1000: Training Accuracy = 76.69%\n",
      "Epoch 461/1000: Training Accuracy = 77.81%\n",
      "Epoch 462/1000: Training Accuracy = 74.58%\n",
      "Epoch 463/1000: Training Accuracy = 77.53%\n",
      "Epoch 464/1000: Training Accuracy = 77.39%\n",
      "Epoch 465/1000: Training Accuracy = 78.09%\n",
      "Epoch 466/1000: Training Accuracy = 77.53%\n",
      "Epoch 467/1000: Training Accuracy = 77.53%\n",
      "Epoch 468/1000: Training Accuracy = 77.95%\n",
      "Epoch 469/1000: Training Accuracy = 77.53%\n",
      "Epoch 470/1000: Training Accuracy = 77.11%\n",
      "Epoch 471/1000: Training Accuracy = 77.39%\n",
      "Epoch 472/1000: Training Accuracy = 76.69%\n",
      "Epoch 473/1000: Training Accuracy = 77.39%\n",
      "Epoch 474/1000: Training Accuracy = 77.25%\n",
      "Epoch 475/1000: Training Accuracy = 76.12%\n",
      "Epoch 476/1000: Training Accuracy = 77.39%\n",
      "Epoch 477/1000: Training Accuracy = 76.40%\n",
      "Epoch 478/1000: Training Accuracy = 76.83%\n",
      "Epoch 479/1000: Training Accuracy = 77.25%\n",
      "Epoch 480/1000: Training Accuracy = 76.26%\n",
      "Epoch 481/1000: Training Accuracy = 77.67%\n",
      "Epoch 482/1000: Training Accuracy = 77.53%\n",
      "Epoch 483/1000: Training Accuracy = 75.84%\n",
      "Epoch 484/1000: Training Accuracy = 77.67%\n",
      "Epoch 485/1000: Training Accuracy = 77.25%\n",
      "Epoch 486/1000: Training Accuracy = 77.39%\n",
      "Epoch 487/1000: Training Accuracy = 76.26%\n",
      "Epoch 488/1000: Training Accuracy = 77.81%\n",
      "Epoch 489/1000: Training Accuracy = 76.97%\n",
      "Epoch 490/1000: Training Accuracy = 77.39%\n",
      "Epoch 491/1000: Training Accuracy = 77.39%\n",
      "Epoch 492/1000: Training Accuracy = 76.12%\n",
      "Epoch 493/1000: Training Accuracy = 74.44%\n",
      "Epoch 494/1000: Training Accuracy = 76.83%\n",
      "Epoch 495/1000: Training Accuracy = 77.67%\n",
      "Epoch 496/1000: Training Accuracy = 77.39%\n",
      "Epoch 497/1000: Training Accuracy = 77.95%\n",
      "Epoch 498/1000: Training Accuracy = 76.12%\n",
      "Epoch 499/1000: Training Accuracy = 77.95%\n",
      "Epoch 500/1000: Training Accuracy = 74.44%\n",
      "Epoch 501/1000: Training Accuracy = 77.39%\n",
      "Epoch 502/1000: Training Accuracy = 76.40%\n",
      "Epoch 503/1000: Training Accuracy = 77.81%\n",
      "Epoch 504/1000: Training Accuracy = 76.54%\n",
      "Epoch 505/1000: Training Accuracy = 77.25%\n",
      "Epoch 506/1000: Training Accuracy = 74.44%\n",
      "Epoch 507/1000: Training Accuracy = 75.00%\n",
      "Epoch 508/1000: Training Accuracy = 77.25%\n",
      "Epoch 509/1000: Training Accuracy = 76.40%\n",
      "Epoch 510/1000: Training Accuracy = 75.98%\n",
      "Epoch 511/1000: Training Accuracy = 76.97%\n",
      "Epoch 512/1000: Training Accuracy = 76.26%\n",
      "Epoch 513/1000: Training Accuracy = 77.67%\n",
      "Epoch 514/1000: Training Accuracy = 77.53%\n",
      "Epoch 515/1000: Training Accuracy = 77.39%\n",
      "Epoch 516/1000: Training Accuracy = 77.25%\n",
      "Epoch 517/1000: Training Accuracy = 77.39%\n",
      "Epoch 518/1000: Training Accuracy = 77.39%\n",
      "Epoch 519/1000: Training Accuracy = 77.11%\n",
      "Epoch 520/1000: Training Accuracy = 77.67%\n",
      "Epoch 521/1000: Training Accuracy = 76.54%\n",
      "Epoch 522/1000: Training Accuracy = 76.69%\n",
      "Epoch 523/1000: Training Accuracy = 77.53%\n",
      "Epoch 524/1000: Training Accuracy = 77.53%\n",
      "Epoch 525/1000: Training Accuracy = 76.54%\n",
      "Epoch 526/1000: Training Accuracy = 77.39%\n",
      "Epoch 527/1000: Training Accuracy = 76.54%\n",
      "Epoch 528/1000: Training Accuracy = 77.53%\n",
      "Epoch 529/1000: Training Accuracy = 76.40%\n",
      "Epoch 530/1000: Training Accuracy = 77.53%\n",
      "Epoch 531/1000: Training Accuracy = 74.72%\n",
      "Epoch 532/1000: Training Accuracy = 77.39%\n",
      "Epoch 533/1000: Training Accuracy = 75.00%\n",
      "Epoch 534/1000: Training Accuracy = 76.26%\n",
      "Epoch 535/1000: Training Accuracy = 77.25%\n",
      "Epoch 536/1000: Training Accuracy = 77.25%\n",
      "Epoch 537/1000: Training Accuracy = 77.53%\n",
      "Epoch 538/1000: Training Accuracy = 76.54%\n",
      "Epoch 539/1000: Training Accuracy = 76.83%\n",
      "Epoch 540/1000: Training Accuracy = 77.67%\n",
      "Epoch 541/1000: Training Accuracy = 77.53%\n",
      "Epoch 542/1000: Training Accuracy = 76.97%\n",
      "Epoch 543/1000: Training Accuracy = 77.53%\n",
      "Epoch 544/1000: Training Accuracy = 75.56%\n",
      "Epoch 545/1000: Training Accuracy = 77.67%\n",
      "Epoch 546/1000: Training Accuracy = 76.69%\n",
      "Epoch 547/1000: Training Accuracy = 77.67%\n",
      "Epoch 548/1000: Training Accuracy = 74.72%\n",
      "Epoch 549/1000: Training Accuracy = 75.56%\n",
      "Epoch 550/1000: Training Accuracy = 77.53%\n",
      "Epoch 551/1000: Training Accuracy = 76.97%\n",
      "Epoch 552/1000: Training Accuracy = 77.39%\n",
      "Epoch 553/1000: Training Accuracy = 76.97%\n",
      "Epoch 554/1000: Training Accuracy = 77.67%\n",
      "Epoch 555/1000: Training Accuracy = 76.54%\n",
      "Epoch 556/1000: Training Accuracy = 74.44%\n",
      "Epoch 557/1000: Training Accuracy = 77.53%\n",
      "Epoch 558/1000: Training Accuracy = 76.97%\n",
      "Epoch 559/1000: Training Accuracy = 77.25%\n",
      "Epoch 560/1000: Training Accuracy = 76.54%\n",
      "Epoch 561/1000: Training Accuracy = 77.25%\n",
      "Epoch 562/1000: Training Accuracy = 77.67%\n",
      "Epoch 563/1000: Training Accuracy = 76.97%\n",
      "Epoch 564/1000: Training Accuracy = 76.97%\n",
      "Epoch 565/1000: Training Accuracy = 77.39%\n",
      "Epoch 566/1000: Training Accuracy = 75.84%\n",
      "Epoch 567/1000: Training Accuracy = 75.70%\n",
      "Epoch 568/1000: Training Accuracy = 77.67%\n",
      "Epoch 569/1000: Training Accuracy = 76.83%\n",
      "Epoch 570/1000: Training Accuracy = 77.25%\n",
      "Epoch 571/1000: Training Accuracy = 76.26%\n",
      "Epoch 572/1000: Training Accuracy = 77.81%\n",
      "Epoch 573/1000: Training Accuracy = 76.54%\n",
      "Epoch 574/1000: Training Accuracy = 77.81%\n",
      "Epoch 575/1000: Training Accuracy = 76.69%\n",
      "Epoch 576/1000: Training Accuracy = 77.25%\n",
      "Epoch 577/1000: Training Accuracy = 74.72%\n",
      "Epoch 578/1000: Training Accuracy = 76.26%\n",
      "Epoch 579/1000: Training Accuracy = 76.54%\n",
      "Epoch 580/1000: Training Accuracy = 77.25%\n",
      "Epoch 581/1000: Training Accuracy = 77.39%\n",
      "Epoch 582/1000: Training Accuracy = 77.25%\n",
      "Epoch 583/1000: Training Accuracy = 76.69%\n",
      "Epoch 584/1000: Training Accuracy = 76.83%\n",
      "Epoch 585/1000: Training Accuracy = 76.69%\n",
      "Epoch 586/1000: Training Accuracy = 77.53%\n",
      "Epoch 587/1000: Training Accuracy = 77.53%\n",
      "Epoch 588/1000: Training Accuracy = 76.97%\n",
      "Epoch 589/1000: Training Accuracy = 77.95%\n",
      "Epoch 590/1000: Training Accuracy = 76.40%\n",
      "Epoch 591/1000: Training Accuracy = 77.11%\n",
      "Epoch 592/1000: Training Accuracy = 75.00%\n",
      "Epoch 593/1000: Training Accuracy = 76.12%\n",
      "Epoch 594/1000: Training Accuracy = 76.83%\n",
      "Epoch 595/1000: Training Accuracy = 77.81%\n",
      "Epoch 596/1000: Training Accuracy = 76.97%\n",
      "Epoch 597/1000: Training Accuracy = 76.69%\n",
      "Epoch 598/1000: Training Accuracy = 77.11%\n",
      "Epoch 599/1000: Training Accuracy = 77.25%\n",
      "Epoch 600/1000: Training Accuracy = 76.26%\n",
      "Epoch 601/1000: Training Accuracy = 77.67%\n",
      "Epoch 602/1000: Training Accuracy = 75.42%\n",
      "Epoch 603/1000: Training Accuracy = 77.67%\n",
      "Epoch 604/1000: Training Accuracy = 77.11%\n",
      "Epoch 605/1000: Training Accuracy = 75.00%\n",
      "Epoch 606/1000: Training Accuracy = 77.53%\n",
      "Epoch 607/1000: Training Accuracy = 76.40%\n",
      "Epoch 608/1000: Training Accuracy = 77.25%\n",
      "Epoch 609/1000: Training Accuracy = 77.81%\n",
      "Epoch 610/1000: Training Accuracy = 74.72%\n",
      "Epoch 611/1000: Training Accuracy = 77.53%\n",
      "Epoch 612/1000: Training Accuracy = 74.30%\n",
      "Epoch 613/1000: Training Accuracy = 77.11%\n",
      "Epoch 614/1000: Training Accuracy = 76.83%\n",
      "Epoch 615/1000: Training Accuracy = 77.95%\n",
      "Epoch 616/1000: Training Accuracy = 75.42%\n",
      "Epoch 617/1000: Training Accuracy = 77.25%\n",
      "Epoch 618/1000: Training Accuracy = 74.30%\n",
      "Epoch 619/1000: Training Accuracy = 77.95%\n",
      "Epoch 620/1000: Training Accuracy = 77.67%\n",
      "Epoch 621/1000: Training Accuracy = 77.67%\n",
      "Epoch 622/1000: Training Accuracy = 77.67%\n",
      "Epoch 623/1000: Training Accuracy = 76.69%\n",
      "Epoch 624/1000: Training Accuracy = 74.30%\n",
      "Epoch 625/1000: Training Accuracy = 74.30%\n",
      "Epoch 626/1000: Training Accuracy = 77.11%\n",
      "Epoch 627/1000: Training Accuracy = 77.11%\n",
      "Epoch 628/1000: Training Accuracy = 77.11%\n",
      "Epoch 629/1000: Training Accuracy = 77.53%\n",
      "Epoch 630/1000: Training Accuracy = 74.86%\n",
      "Epoch 631/1000: Training Accuracy = 77.11%\n",
      "Epoch 632/1000: Training Accuracy = 77.25%\n",
      "Epoch 633/1000: Training Accuracy = 76.97%\n",
      "Epoch 634/1000: Training Accuracy = 78.79%\n",
      "Epoch 635/1000: Training Accuracy = 77.39%\n",
      "Epoch 636/1000: Training Accuracy = 77.25%\n",
      "Epoch 637/1000: Training Accuracy = 77.81%\n",
      "Epoch 638/1000: Training Accuracy = 74.58%\n",
      "Epoch 639/1000: Training Accuracy = 77.11%\n",
      "Epoch 640/1000: Training Accuracy = 77.25%\n",
      "Epoch 641/1000: Training Accuracy = 76.97%\n",
      "Epoch 642/1000: Training Accuracy = 77.53%\n",
      "Epoch 643/1000: Training Accuracy = 77.25%\n",
      "Epoch 644/1000: Training Accuracy = 75.98%\n",
      "Epoch 645/1000: Training Accuracy = 75.84%\n",
      "Epoch 646/1000: Training Accuracy = 76.97%\n",
      "Epoch 647/1000: Training Accuracy = 77.53%\n",
      "Epoch 648/1000: Training Accuracy = 77.53%\n",
      "Epoch 649/1000: Training Accuracy = 77.11%\n",
      "Epoch 650/1000: Training Accuracy = 76.69%\n",
      "Epoch 651/1000: Training Accuracy = 75.42%\n",
      "Epoch 652/1000: Training Accuracy = 77.39%\n",
      "Epoch 653/1000: Training Accuracy = 77.53%\n",
      "Epoch 654/1000: Training Accuracy = 77.25%\n",
      "Epoch 655/1000: Training Accuracy = 77.53%\n",
      "Epoch 656/1000: Training Accuracy = 75.14%\n",
      "Epoch 657/1000: Training Accuracy = 77.39%\n",
      "Epoch 658/1000: Training Accuracy = 76.69%\n",
      "Epoch 659/1000: Training Accuracy = 76.97%\n",
      "Epoch 660/1000: Training Accuracy = 76.12%\n",
      "Epoch 661/1000: Training Accuracy = 77.39%\n",
      "Epoch 662/1000: Training Accuracy = 76.83%\n",
      "Epoch 663/1000: Training Accuracy = 76.83%\n",
      "Epoch 664/1000: Training Accuracy = 77.11%\n",
      "Epoch 665/1000: Training Accuracy = 76.97%\n",
      "Epoch 666/1000: Training Accuracy = 77.39%\n",
      "Epoch 667/1000: Training Accuracy = 77.53%\n",
      "Epoch 668/1000: Training Accuracy = 77.67%\n",
      "Epoch 669/1000: Training Accuracy = 77.25%\n",
      "Epoch 670/1000: Training Accuracy = 76.83%\n",
      "Epoch 671/1000: Training Accuracy = 76.69%\n",
      "Epoch 672/1000: Training Accuracy = 76.40%\n",
      "Epoch 673/1000: Training Accuracy = 77.53%\n",
      "Epoch 674/1000: Training Accuracy = 76.97%\n",
      "Epoch 675/1000: Training Accuracy = 76.97%\n",
      "Epoch 676/1000: Training Accuracy = 76.26%\n",
      "Epoch 677/1000: Training Accuracy = 76.40%\n",
      "Epoch 678/1000: Training Accuracy = 76.40%\n",
      "Epoch 679/1000: Training Accuracy = 75.28%\n",
      "Epoch 680/1000: Training Accuracy = 76.12%\n",
      "Epoch 681/1000: Training Accuracy = 77.53%\n",
      "Epoch 682/1000: Training Accuracy = 77.11%\n",
      "Epoch 683/1000: Training Accuracy = 77.53%\n",
      "Epoch 684/1000: Training Accuracy = 77.81%\n",
      "Epoch 685/1000: Training Accuracy = 77.81%\n",
      "Epoch 686/1000: Training Accuracy = 75.00%\n",
      "Epoch 687/1000: Training Accuracy = 77.39%\n",
      "Epoch 688/1000: Training Accuracy = 77.53%\n",
      "Epoch 689/1000: Training Accuracy = 75.84%\n",
      "Epoch 690/1000: Training Accuracy = 75.00%\n",
      "Epoch 691/1000: Training Accuracy = 76.40%\n",
      "Epoch 692/1000: Training Accuracy = 77.39%\n",
      "Epoch 693/1000: Training Accuracy = 74.58%\n",
      "Epoch 694/1000: Training Accuracy = 74.44%\n",
      "Epoch 695/1000: Training Accuracy = 77.25%\n",
      "Epoch 696/1000: Training Accuracy = 77.11%\n",
      "Epoch 697/1000: Training Accuracy = 77.53%\n",
      "Epoch 698/1000: Training Accuracy = 75.70%\n",
      "Epoch 699/1000: Training Accuracy = 74.30%\n",
      "Epoch 700/1000: Training Accuracy = 75.84%\n",
      "Epoch 701/1000: Training Accuracy = 77.67%\n",
      "Epoch 702/1000: Training Accuracy = 77.39%\n",
      "Epoch 703/1000: Training Accuracy = 77.25%\n",
      "Epoch 704/1000: Training Accuracy = 76.54%\n",
      "Epoch 705/1000: Training Accuracy = 76.83%\n",
      "Epoch 706/1000: Training Accuracy = 75.56%\n",
      "Epoch 707/1000: Training Accuracy = 77.11%\n",
      "Epoch 708/1000: Training Accuracy = 77.53%\n",
      "Epoch 709/1000: Training Accuracy = 77.39%\n",
      "Epoch 710/1000: Training Accuracy = 77.53%\n",
      "Epoch 711/1000: Training Accuracy = 77.11%\n",
      "Epoch 712/1000: Training Accuracy = 76.83%\n",
      "Epoch 713/1000: Training Accuracy = 75.98%\n",
      "Epoch 714/1000: Training Accuracy = 77.39%\n",
      "Epoch 715/1000: Training Accuracy = 77.81%\n",
      "Epoch 716/1000: Training Accuracy = 77.67%\n",
      "Epoch 717/1000: Training Accuracy = 74.44%\n",
      "Epoch 718/1000: Training Accuracy = 77.39%\n",
      "Epoch 719/1000: Training Accuracy = 76.12%\n",
      "Epoch 720/1000: Training Accuracy = 77.53%\n",
      "Epoch 721/1000: Training Accuracy = 77.25%\n",
      "Epoch 722/1000: Training Accuracy = 76.97%\n",
      "Epoch 723/1000: Training Accuracy = 76.83%\n",
      "Epoch 724/1000: Training Accuracy = 77.39%\n",
      "Epoch 725/1000: Training Accuracy = 76.97%\n",
      "Epoch 726/1000: Training Accuracy = 77.53%\n",
      "Epoch 727/1000: Training Accuracy = 77.81%\n",
      "Epoch 728/1000: Training Accuracy = 77.39%\n",
      "Epoch 729/1000: Training Accuracy = 75.98%\n",
      "Epoch 730/1000: Training Accuracy = 75.84%\n",
      "Epoch 731/1000: Training Accuracy = 77.81%\n",
      "Epoch 732/1000: Training Accuracy = 74.72%\n",
      "Epoch 733/1000: Training Accuracy = 75.00%\n",
      "Epoch 734/1000: Training Accuracy = 76.83%\n",
      "Epoch 735/1000: Training Accuracy = 77.81%\n",
      "Epoch 736/1000: Training Accuracy = 77.81%\n",
      "Epoch 737/1000: Training Accuracy = 77.25%\n",
      "Epoch 738/1000: Training Accuracy = 77.25%\n",
      "Epoch 739/1000: Training Accuracy = 77.25%\n",
      "Epoch 740/1000: Training Accuracy = 77.53%\n",
      "Epoch 741/1000: Training Accuracy = 77.25%\n",
      "Epoch 742/1000: Training Accuracy = 76.97%\n",
      "Epoch 743/1000: Training Accuracy = 77.53%\n",
      "Epoch 744/1000: Training Accuracy = 77.25%\n",
      "Epoch 745/1000: Training Accuracy = 76.69%\n",
      "Epoch 746/1000: Training Accuracy = 77.67%\n",
      "Epoch 747/1000: Training Accuracy = 77.81%\n",
      "Epoch 748/1000: Training Accuracy = 76.97%\n",
      "Epoch 749/1000: Training Accuracy = 75.84%\n",
      "Epoch 750/1000: Training Accuracy = 77.53%\n",
      "Epoch 751/1000: Training Accuracy = 77.67%\n",
      "Epoch 752/1000: Training Accuracy = 78.09%\n",
      "Epoch 753/1000: Training Accuracy = 76.83%\n",
      "Epoch 754/1000: Training Accuracy = 77.39%\n",
      "Epoch 755/1000: Training Accuracy = 77.67%\n",
      "Epoch 756/1000: Training Accuracy = 77.67%\n",
      "Epoch 757/1000: Training Accuracy = 77.11%\n",
      "Epoch 758/1000: Training Accuracy = 75.84%\n",
      "Epoch 759/1000: Training Accuracy = 75.28%\n",
      "Epoch 760/1000: Training Accuracy = 77.81%\n",
      "Epoch 761/1000: Training Accuracy = 76.54%\n",
      "Epoch 762/1000: Training Accuracy = 76.12%\n",
      "Epoch 763/1000: Training Accuracy = 77.39%\n",
      "Epoch 764/1000: Training Accuracy = 75.84%\n",
      "Epoch 765/1000: Training Accuracy = 76.83%\n",
      "Epoch 766/1000: Training Accuracy = 75.14%\n",
      "Epoch 767/1000: Training Accuracy = 77.67%\n",
      "Epoch 768/1000: Training Accuracy = 76.12%\n",
      "Epoch 769/1000: Training Accuracy = 75.00%\n",
      "Epoch 770/1000: Training Accuracy = 77.25%\n",
      "Epoch 771/1000: Training Accuracy = 75.28%\n",
      "Epoch 772/1000: Training Accuracy = 77.67%\n",
      "Epoch 773/1000: Training Accuracy = 77.53%\n",
      "Epoch 774/1000: Training Accuracy = 75.84%\n",
      "Epoch 775/1000: Training Accuracy = 77.81%\n",
      "Epoch 776/1000: Training Accuracy = 75.42%\n",
      "Epoch 777/1000: Training Accuracy = 76.97%\n",
      "Epoch 778/1000: Training Accuracy = 77.67%\n",
      "Epoch 779/1000: Training Accuracy = 77.53%\n",
      "Epoch 780/1000: Training Accuracy = 75.98%\n",
      "Epoch 781/1000: Training Accuracy = 77.39%\n",
      "Epoch 782/1000: Training Accuracy = 77.11%\n",
      "Epoch 783/1000: Training Accuracy = 75.56%\n",
      "Epoch 784/1000: Training Accuracy = 74.86%\n",
      "Epoch 785/1000: Training Accuracy = 77.25%\n",
      "Epoch 786/1000: Training Accuracy = 77.53%\n",
      "Epoch 787/1000: Training Accuracy = 75.84%\n",
      "Epoch 788/1000: Training Accuracy = 77.53%\n",
      "Epoch 789/1000: Training Accuracy = 76.54%\n",
      "Epoch 790/1000: Training Accuracy = 77.67%\n",
      "Epoch 791/1000: Training Accuracy = 77.81%\n",
      "Epoch 792/1000: Training Accuracy = 75.98%\n",
      "Epoch 793/1000: Training Accuracy = 77.53%\n",
      "Epoch 794/1000: Training Accuracy = 75.98%\n",
      "Epoch 795/1000: Training Accuracy = 75.84%\n",
      "Epoch 796/1000: Training Accuracy = 77.81%\n",
      "Epoch 797/1000: Training Accuracy = 76.69%\n",
      "Epoch 798/1000: Training Accuracy = 76.83%\n",
      "Epoch 799/1000: Training Accuracy = 77.81%\n",
      "Epoch 800/1000: Training Accuracy = 76.26%\n",
      "Epoch 801/1000: Training Accuracy = 75.42%\n",
      "Epoch 802/1000: Training Accuracy = 77.67%\n",
      "Epoch 803/1000: Training Accuracy = 77.39%\n",
      "Epoch 804/1000: Training Accuracy = 77.81%\n",
      "Epoch 805/1000: Training Accuracy = 78.23%\n",
      "Epoch 806/1000: Training Accuracy = 77.53%\n",
      "Epoch 807/1000: Training Accuracy = 75.28%\n",
      "Epoch 808/1000: Training Accuracy = 77.53%\n",
      "Epoch 809/1000: Training Accuracy = 75.84%\n",
      "Epoch 810/1000: Training Accuracy = 77.53%\n",
      "Epoch 811/1000: Training Accuracy = 77.39%\n",
      "Epoch 812/1000: Training Accuracy = 77.53%\n",
      "Epoch 813/1000: Training Accuracy = 76.26%\n",
      "Epoch 814/1000: Training Accuracy = 74.72%\n",
      "Epoch 815/1000: Training Accuracy = 77.67%\n",
      "Epoch 816/1000: Training Accuracy = 76.54%\n",
      "Epoch 817/1000: Training Accuracy = 76.69%\n",
      "Epoch 818/1000: Training Accuracy = 74.58%\n",
      "Epoch 819/1000: Training Accuracy = 76.69%\n",
      "Epoch 820/1000: Training Accuracy = 75.70%\n",
      "Epoch 821/1000: Training Accuracy = 77.67%\n",
      "Epoch 822/1000: Training Accuracy = 77.53%\n",
      "Epoch 823/1000: Training Accuracy = 77.67%\n",
      "Epoch 824/1000: Training Accuracy = 77.95%\n",
      "Epoch 825/1000: Training Accuracy = 77.11%\n",
      "Epoch 826/1000: Training Accuracy = 77.11%\n",
      "Epoch 827/1000: Training Accuracy = 75.84%\n",
      "Epoch 828/1000: Training Accuracy = 77.95%\n",
      "Epoch 829/1000: Training Accuracy = 77.95%\n",
      "Epoch 830/1000: Training Accuracy = 77.81%\n",
      "Epoch 831/1000: Training Accuracy = 76.97%\n",
      "Epoch 832/1000: Training Accuracy = 74.44%\n",
      "Epoch 833/1000: Training Accuracy = 74.58%\n",
      "Epoch 834/1000: Training Accuracy = 75.98%\n",
      "Epoch 835/1000: Training Accuracy = 75.28%\n",
      "Epoch 836/1000: Training Accuracy = 77.25%\n",
      "Epoch 837/1000: Training Accuracy = 77.67%\n",
      "Epoch 838/1000: Training Accuracy = 76.12%\n",
      "Epoch 839/1000: Training Accuracy = 76.69%\n",
      "Epoch 840/1000: Training Accuracy = 76.40%\n",
      "Epoch 841/1000: Training Accuracy = 75.98%\n",
      "Epoch 842/1000: Training Accuracy = 77.67%\n",
      "Epoch 843/1000: Training Accuracy = 77.53%\n",
      "Epoch 844/1000: Training Accuracy = 75.84%\n",
      "Epoch 845/1000: Training Accuracy = 74.72%\n",
      "Epoch 846/1000: Training Accuracy = 75.70%\n",
      "Epoch 847/1000: Training Accuracy = 75.70%\n",
      "Epoch 848/1000: Training Accuracy = 77.53%\n",
      "Epoch 849/1000: Training Accuracy = 77.67%\n",
      "Epoch 850/1000: Training Accuracy = 77.67%\n",
      "Epoch 851/1000: Training Accuracy = 77.81%\n",
      "Epoch 852/1000: Training Accuracy = 75.14%\n",
      "Epoch 853/1000: Training Accuracy = 76.83%\n",
      "Epoch 854/1000: Training Accuracy = 75.98%\n",
      "Epoch 855/1000: Training Accuracy = 76.97%\n",
      "Epoch 856/1000: Training Accuracy = 76.83%\n",
      "Epoch 857/1000: Training Accuracy = 77.67%\n",
      "Epoch 858/1000: Training Accuracy = 77.25%\n",
      "Epoch 859/1000: Training Accuracy = 76.12%\n",
      "Epoch 860/1000: Training Accuracy = 76.40%\n",
      "Epoch 861/1000: Training Accuracy = 77.53%\n",
      "Epoch 862/1000: Training Accuracy = 77.81%\n",
      "Epoch 863/1000: Training Accuracy = 77.81%\n",
      "Epoch 864/1000: Training Accuracy = 78.23%\n",
      "Epoch 865/1000: Training Accuracy = 77.95%\n",
      "Epoch 866/1000: Training Accuracy = 77.95%\n",
      "Epoch 867/1000: Training Accuracy = 77.81%\n",
      "Epoch 868/1000: Training Accuracy = 77.95%\n",
      "Epoch 869/1000: Training Accuracy = 76.83%\n",
      "Epoch 870/1000: Training Accuracy = 77.81%\n",
      "Epoch 871/1000: Training Accuracy = 77.81%\n",
      "Epoch 872/1000: Training Accuracy = 76.83%\n",
      "Epoch 873/1000: Training Accuracy = 77.81%\n",
      "Epoch 874/1000: Training Accuracy = 77.67%\n",
      "Epoch 875/1000: Training Accuracy = 76.83%\n",
      "Epoch 876/1000: Training Accuracy = 77.67%\n",
      "Epoch 877/1000: Training Accuracy = 76.26%\n",
      "Epoch 878/1000: Training Accuracy = 77.53%\n",
      "Epoch 879/1000: Training Accuracy = 77.53%\n",
      "Epoch 880/1000: Training Accuracy = 75.70%\n",
      "Epoch 881/1000: Training Accuracy = 76.40%\n",
      "Epoch 882/1000: Training Accuracy = 77.67%\n",
      "Epoch 883/1000: Training Accuracy = 76.69%\n",
      "Epoch 884/1000: Training Accuracy = 77.53%\n",
      "Epoch 885/1000: Training Accuracy = 77.53%\n",
      "Epoch 886/1000: Training Accuracy = 77.53%\n",
      "Epoch 887/1000: Training Accuracy = 77.67%\n",
      "Epoch 888/1000: Training Accuracy = 77.95%\n",
      "Epoch 889/1000: Training Accuracy = 76.26%\n",
      "Epoch 890/1000: Training Accuracy = 77.53%\n",
      "Epoch 891/1000: Training Accuracy = 75.56%\n",
      "Epoch 892/1000: Training Accuracy = 77.95%\n",
      "Epoch 893/1000: Training Accuracy = 76.40%\n",
      "Epoch 894/1000: Training Accuracy = 75.84%\n",
      "Epoch 895/1000: Training Accuracy = 75.84%\n",
      "Epoch 896/1000: Training Accuracy = 77.11%\n",
      "Epoch 897/1000: Training Accuracy = 77.95%\n",
      "Epoch 898/1000: Training Accuracy = 77.67%\n",
      "Epoch 899/1000: Training Accuracy = 77.81%\n",
      "Epoch 900/1000: Training Accuracy = 78.09%\n",
      "Epoch 901/1000: Training Accuracy = 75.28%\n",
      "Epoch 902/1000: Training Accuracy = 77.67%\n",
      "Epoch 903/1000: Training Accuracy = 77.67%\n",
      "Epoch 904/1000: Training Accuracy = 77.39%\n",
      "Epoch 905/1000: Training Accuracy = 77.67%\n",
      "Epoch 906/1000: Training Accuracy = 75.84%\n",
      "Epoch 907/1000: Training Accuracy = 77.81%\n",
      "Epoch 908/1000: Training Accuracy = 75.98%\n",
      "Epoch 909/1000: Training Accuracy = 77.53%\n",
      "Epoch 910/1000: Training Accuracy = 76.97%\n",
      "Epoch 911/1000: Training Accuracy = 77.25%\n",
      "Epoch 912/1000: Training Accuracy = 77.67%\n",
      "Epoch 913/1000: Training Accuracy = 77.53%\n",
      "Epoch 914/1000: Training Accuracy = 75.56%\n",
      "Epoch 915/1000: Training Accuracy = 77.53%\n",
      "Epoch 916/1000: Training Accuracy = 77.67%\n",
      "Epoch 917/1000: Training Accuracy = 75.28%\n",
      "Epoch 918/1000: Training Accuracy = 76.97%\n",
      "Epoch 919/1000: Training Accuracy = 76.83%\n",
      "Epoch 920/1000: Training Accuracy = 77.67%\n",
      "Epoch 921/1000: Training Accuracy = 77.53%\n",
      "Epoch 922/1000: Training Accuracy = 76.12%\n",
      "Epoch 923/1000: Training Accuracy = 77.81%\n",
      "Epoch 924/1000: Training Accuracy = 77.67%\n",
      "Epoch 925/1000: Training Accuracy = 75.84%\n",
      "Epoch 926/1000: Training Accuracy = 77.67%\n",
      "Epoch 927/1000: Training Accuracy = 77.11%\n",
      "Epoch 928/1000: Training Accuracy = 77.95%\n",
      "Epoch 929/1000: Training Accuracy = 77.53%\n",
      "Epoch 930/1000: Training Accuracy = 77.39%\n",
      "Epoch 931/1000: Training Accuracy = 77.25%\n",
      "Epoch 932/1000: Training Accuracy = 76.26%\n",
      "Epoch 933/1000: Training Accuracy = 75.28%\n",
      "Epoch 934/1000: Training Accuracy = 77.81%\n",
      "Epoch 935/1000: Training Accuracy = 75.70%\n",
      "Epoch 936/1000: Training Accuracy = 77.81%\n",
      "Epoch 937/1000: Training Accuracy = 77.67%\n",
      "Epoch 938/1000: Training Accuracy = 77.53%\n",
      "Epoch 939/1000: Training Accuracy = 77.53%\n",
      "Epoch 940/1000: Training Accuracy = 76.69%\n",
      "Epoch 941/1000: Training Accuracy = 75.42%\n",
      "Epoch 942/1000: Training Accuracy = 76.97%\n",
      "Epoch 943/1000: Training Accuracy = 77.11%\n",
      "Epoch 944/1000: Training Accuracy = 77.25%\n",
      "Epoch 945/1000: Training Accuracy = 77.67%\n",
      "Epoch 946/1000: Training Accuracy = 76.26%\n",
      "Epoch 947/1000: Training Accuracy = 76.83%\n",
      "Epoch 948/1000: Training Accuracy = 76.97%\n",
      "Epoch 949/1000: Training Accuracy = 75.70%\n",
      "Epoch 950/1000: Training Accuracy = 77.67%\n",
      "Epoch 951/1000: Training Accuracy = 75.56%\n",
      "Epoch 952/1000: Training Accuracy = 75.56%\n",
      "Epoch 953/1000: Training Accuracy = 76.83%\n",
      "Epoch 954/1000: Training Accuracy = 77.25%\n",
      "Epoch 955/1000: Training Accuracy = 77.81%\n",
      "Epoch 956/1000: Training Accuracy = 75.56%\n",
      "Epoch 957/1000: Training Accuracy = 76.54%\n",
      "Epoch 958/1000: Training Accuracy = 77.53%\n",
      "Epoch 959/1000: Training Accuracy = 77.39%\n",
      "Epoch 960/1000: Training Accuracy = 77.39%\n",
      "Epoch 961/1000: Training Accuracy = 75.84%\n",
      "Epoch 962/1000: Training Accuracy = 77.11%\n",
      "Epoch 963/1000: Training Accuracy = 76.12%\n",
      "Epoch 964/1000: Training Accuracy = 77.25%\n",
      "Epoch 965/1000: Training Accuracy = 77.67%\n",
      "Epoch 966/1000: Training Accuracy = 75.70%\n",
      "Epoch 967/1000: Training Accuracy = 77.25%\n",
      "Epoch 968/1000: Training Accuracy = 76.83%\n",
      "Epoch 969/1000: Training Accuracy = 77.67%\n",
      "Epoch 970/1000: Training Accuracy = 77.81%\n",
      "Epoch 971/1000: Training Accuracy = 77.67%\n",
      "Epoch 972/1000: Training Accuracy = 76.26%\n",
      "Epoch 973/1000: Training Accuracy = 75.70%\n",
      "Epoch 974/1000: Training Accuracy = 77.25%\n",
      "Epoch 975/1000: Training Accuracy = 77.39%\n",
      "Epoch 976/1000: Training Accuracy = 76.69%\n",
      "Epoch 977/1000: Training Accuracy = 78.09%\n",
      "Epoch 978/1000: Training Accuracy = 77.81%\n",
      "Epoch 979/1000: Training Accuracy = 77.53%\n",
      "Epoch 980/1000: Training Accuracy = 76.40%\n",
      "Epoch 981/1000: Training Accuracy = 77.67%\n",
      "Epoch 982/1000: Training Accuracy = 76.97%\n",
      "Epoch 983/1000: Training Accuracy = 75.98%\n",
      "Epoch 984/1000: Training Accuracy = 76.69%\n",
      "Epoch 985/1000: Training Accuracy = 77.39%\n",
      "Epoch 986/1000: Training Accuracy = 77.39%\n",
      "Epoch 987/1000: Training Accuracy = 77.53%\n",
      "Epoch 988/1000: Training Accuracy = 76.97%\n",
      "Epoch 989/1000: Training Accuracy = 77.67%\n",
      "Epoch 990/1000: Training Accuracy = 77.39%\n",
      "Epoch 991/1000: Training Accuracy = 76.83%\n",
      "Epoch 992/1000: Training Accuracy = 77.67%\n",
      "Epoch 993/1000: Training Accuracy = 76.69%\n",
      "Epoch 994/1000: Training Accuracy = 77.67%\n",
      "Epoch 995/1000: Training Accuracy = 77.53%\n",
      "Epoch 996/1000: Training Accuracy = 76.97%\n",
      "Epoch 997/1000: Training Accuracy = 77.11%\n",
      "Epoch 998/1000: Training Accuracy = 74.86%\n",
      "Epoch 999/1000: Training Accuracy = 77.67%\n",
      "Epoch 1000/1000: Training Accuracy = 77.11%\n"
     ]
    }
   ],
   "source": [
    "input_size_2 = x_train.shape[1]\n",
    "perceptron_2 = SingleLayerPerceptron(input_size_2, learning_rate=lr, epochs=epochs)\n",
    "perceptron_2.train(x_train, y_train)\n",
    "pred_2 = perceptron_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2_cf2 = confusion_matrix(y_test, pred_2)\n",
    "plot_cm(model2_cf2, 'Model 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Survived</th>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.879154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.873277</td>\n",
       "      <td>0.893045</td>\n",
       "      <td>0.876446</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.894826</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.880701</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "Not Survived   0.965909  0.833333  0.894737  204.000000\n",
       "Survived       0.780645  0.952756  0.858156  127.000000\n",
       "accuracy       0.879154  0.879154  0.879154    0.879154\n",
       "macro avg      0.873277  0.893045  0.876446  331.000000\n",
       "weighted avg   0.894826  0.879154  0.880701  331.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_report2 = classification_report(y_test, pred_2, output_dict=True, target_names=['Not Survived',\"Survived\"])\n",
    "pd.DataFrame(model2_report2).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Menggunakan kolom Sex & Age saja**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data train 2 kolom\n",
    "x_train_2col = train_normalize.iloc[:, 2:4].values\n",
    "y_train_2col = train_normalize.iloc[:, -1].values\n",
    "\n",
    "# data test 2 kolom\n",
    "x_test_2col = test_normalize.iloc[:, 2:4].values\n",
    "y_test_2col = test_normalize.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: Training Accuracy = 75.98%\n",
      "Epoch 2/1000: Training Accuracy = 77.67%\n",
      "Epoch 3/1000: Training Accuracy = 75.56%\n",
      "Epoch 4/1000: Training Accuracy = 75.98%\n",
      "Epoch 5/1000: Training Accuracy = 75.98%\n",
      "Epoch 6/1000: Training Accuracy = 77.67%\n",
      "Epoch 7/1000: Training Accuracy = 75.56%\n",
      "Epoch 8/1000: Training Accuracy = 77.95%\n",
      "Epoch 9/1000: Training Accuracy = 77.67%\n",
      "Epoch 10/1000: Training Accuracy = 75.98%\n",
      "Epoch 11/1000: Training Accuracy = 75.98%\n",
      "Epoch 12/1000: Training Accuracy = 77.67%\n",
      "Epoch 13/1000: Training Accuracy = 75.56%\n",
      "Epoch 14/1000: Training Accuracy = 77.95%\n",
      "Epoch 15/1000: Training Accuracy = 77.67%\n",
      "Epoch 16/1000: Training Accuracy = 77.95%\n",
      "Epoch 17/1000: Training Accuracy = 77.95%\n",
      "Epoch 18/1000: Training Accuracy = 77.67%\n",
      "Epoch 19/1000: Training Accuracy = 77.95%\n",
      "Epoch 20/1000: Training Accuracy = 77.95%\n",
      "Epoch 21/1000: Training Accuracy = 77.67%\n",
      "Epoch 22/1000: Training Accuracy = 77.95%\n",
      "Epoch 23/1000: Training Accuracy = 77.95%\n",
      "Epoch 24/1000: Training Accuracy = 77.95%\n",
      "Epoch 25/1000: Training Accuracy = 77.95%\n",
      "Epoch 26/1000: Training Accuracy = 77.95%\n",
      "Epoch 27/1000: Training Accuracy = 77.95%\n",
      "Epoch 28/1000: Training Accuracy = 77.95%\n",
      "Epoch 29/1000: Training Accuracy = 77.95%\n",
      "Epoch 30/1000: Training Accuracy = 77.95%\n",
      "Epoch 31/1000: Training Accuracy = 77.95%\n",
      "Epoch 32/1000: Training Accuracy = 77.95%\n",
      "Epoch 33/1000: Training Accuracy = 77.95%\n",
      "Epoch 34/1000: Training Accuracy = 77.95%\n",
      "Epoch 35/1000: Training Accuracy = 77.95%\n",
      "Epoch 36/1000: Training Accuracy = 77.95%\n",
      "Epoch 37/1000: Training Accuracy = 77.95%\n",
      "Epoch 38/1000: Training Accuracy = 77.95%\n",
      "Epoch 39/1000: Training Accuracy = 77.95%\n",
      "Epoch 40/1000: Training Accuracy = 77.95%\n",
      "Epoch 41/1000: Training Accuracy = 77.95%\n",
      "Epoch 42/1000: Training Accuracy = 77.95%\n",
      "Epoch 43/1000: Training Accuracy = 77.95%\n",
      "Epoch 44/1000: Training Accuracy = 77.95%\n",
      "Epoch 45/1000: Training Accuracy = 77.95%\n",
      "Epoch 46/1000: Training Accuracy = 77.95%\n",
      "Epoch 47/1000: Training Accuracy = 77.95%\n",
      "Epoch 48/1000: Training Accuracy = 77.95%\n",
      "Epoch 49/1000: Training Accuracy = 77.95%\n",
      "Epoch 50/1000: Training Accuracy = 77.95%\n",
      "Epoch 51/1000: Training Accuracy = 77.95%\n",
      "Epoch 52/1000: Training Accuracy = 77.95%\n",
      "Epoch 53/1000: Training Accuracy = 77.95%\n",
      "Epoch 54/1000: Training Accuracy = 77.95%\n",
      "Epoch 55/1000: Training Accuracy = 77.95%\n",
      "Epoch 56/1000: Training Accuracy = 77.95%\n",
      "Epoch 57/1000: Training Accuracy = 77.95%\n",
      "Epoch 58/1000: Training Accuracy = 77.95%\n",
      "Epoch 59/1000: Training Accuracy = 77.95%\n",
      "Epoch 60/1000: Training Accuracy = 77.95%\n",
      "Epoch 61/1000: Training Accuracy = 77.95%\n",
      "Epoch 62/1000: Training Accuracy = 77.95%\n",
      "Epoch 63/1000: Training Accuracy = 77.95%\n",
      "Epoch 64/1000: Training Accuracy = 77.95%\n",
      "Epoch 65/1000: Training Accuracy = 77.95%\n",
      "Epoch 66/1000: Training Accuracy = 77.95%\n",
      "Epoch 67/1000: Training Accuracy = 77.95%\n",
      "Epoch 68/1000: Training Accuracy = 77.95%\n",
      "Epoch 69/1000: Training Accuracy = 77.95%\n",
      "Epoch 70/1000: Training Accuracy = 77.95%\n",
      "Epoch 71/1000: Training Accuracy = 77.95%\n",
      "Epoch 72/1000: Training Accuracy = 77.95%\n",
      "Epoch 73/1000: Training Accuracy = 77.95%\n",
      "Epoch 74/1000: Training Accuracy = 77.95%\n",
      "Epoch 75/1000: Training Accuracy = 77.95%\n",
      "Epoch 76/1000: Training Accuracy = 77.95%\n",
      "Epoch 77/1000: Training Accuracy = 77.95%\n",
      "Epoch 78/1000: Training Accuracy = 77.95%\n",
      "Epoch 79/1000: Training Accuracy = 77.95%\n",
      "Epoch 80/1000: Training Accuracy = 77.95%\n",
      "Epoch 81/1000: Training Accuracy = 77.95%\n",
      "Epoch 82/1000: Training Accuracy = 77.95%\n",
      "Epoch 83/1000: Training Accuracy = 77.95%\n",
      "Epoch 84/1000: Training Accuracy = 77.95%\n",
      "Epoch 85/1000: Training Accuracy = 77.95%\n",
      "Epoch 86/1000: Training Accuracy = 77.95%\n",
      "Epoch 87/1000: Training Accuracy = 77.95%\n",
      "Epoch 88/1000: Training Accuracy = 77.95%\n",
      "Epoch 89/1000: Training Accuracy = 77.95%\n",
      "Epoch 90/1000: Training Accuracy = 77.95%\n",
      "Epoch 91/1000: Training Accuracy = 77.95%\n",
      "Epoch 92/1000: Training Accuracy = 77.95%\n",
      "Epoch 93/1000: Training Accuracy = 77.95%\n",
      "Epoch 94/1000: Training Accuracy = 77.95%\n",
      "Epoch 95/1000: Training Accuracy = 77.95%\n",
      "Epoch 96/1000: Training Accuracy = 77.95%\n",
      "Epoch 97/1000: Training Accuracy = 77.95%\n",
      "Epoch 98/1000: Training Accuracy = 77.95%\n",
      "Epoch 99/1000: Training Accuracy = 77.95%\n",
      "Epoch 100/1000: Training Accuracy = 77.95%\n",
      "Epoch 101/1000: Training Accuracy = 77.95%\n",
      "Epoch 102/1000: Training Accuracy = 77.95%\n",
      "Epoch 103/1000: Training Accuracy = 77.95%\n",
      "Epoch 104/1000: Training Accuracy = 77.95%\n",
      "Epoch 105/1000: Training Accuracy = 77.95%\n",
      "Epoch 106/1000: Training Accuracy = 77.95%\n",
      "Epoch 107/1000: Training Accuracy = 77.95%\n",
      "Epoch 108/1000: Training Accuracy = 77.95%\n",
      "Epoch 109/1000: Training Accuracy = 77.95%\n",
      "Epoch 110/1000: Training Accuracy = 77.95%\n",
      "Epoch 111/1000: Training Accuracy = 77.95%\n",
      "Epoch 112/1000: Training Accuracy = 77.95%\n",
      "Epoch 113/1000: Training Accuracy = 77.95%\n",
      "Epoch 114/1000: Training Accuracy = 77.95%\n",
      "Epoch 115/1000: Training Accuracy = 77.95%\n",
      "Epoch 116/1000: Training Accuracy = 77.95%\n",
      "Epoch 117/1000: Training Accuracy = 77.95%\n",
      "Epoch 118/1000: Training Accuracy = 77.95%\n",
      "Epoch 119/1000: Training Accuracy = 77.95%\n",
      "Epoch 120/1000: Training Accuracy = 77.95%\n",
      "Epoch 121/1000: Training Accuracy = 77.95%\n",
      "Epoch 122/1000: Training Accuracy = 77.95%\n",
      "Epoch 123/1000: Training Accuracy = 77.95%\n",
      "Epoch 124/1000: Training Accuracy = 77.95%\n",
      "Epoch 125/1000: Training Accuracy = 77.95%\n",
      "Epoch 126/1000: Training Accuracy = 77.95%\n",
      "Epoch 127/1000: Training Accuracy = 77.95%\n",
      "Epoch 128/1000: Training Accuracy = 77.95%\n",
      "Epoch 129/1000: Training Accuracy = 77.95%\n",
      "Epoch 130/1000: Training Accuracy = 77.95%\n",
      "Epoch 131/1000: Training Accuracy = 77.95%\n",
      "Epoch 132/1000: Training Accuracy = 77.95%\n",
      "Epoch 133/1000: Training Accuracy = 77.95%\n",
      "Epoch 134/1000: Training Accuracy = 77.95%\n",
      "Epoch 135/1000: Training Accuracy = 77.95%\n",
      "Epoch 136/1000: Training Accuracy = 77.95%\n",
      "Epoch 137/1000: Training Accuracy = 77.95%\n",
      "Epoch 138/1000: Training Accuracy = 77.95%\n",
      "Epoch 139/1000: Training Accuracy = 77.95%\n",
      "Epoch 140/1000: Training Accuracy = 77.95%\n",
      "Epoch 141/1000: Training Accuracy = 77.95%\n",
      "Epoch 142/1000: Training Accuracy = 75.56%\n",
      "Epoch 143/1000: Training Accuracy = 75.98%\n",
      "Epoch 144/1000: Training Accuracy = 75.98%\n",
      "Epoch 145/1000: Training Accuracy = 77.67%\n",
      "Epoch 146/1000: Training Accuracy = 75.56%\n",
      "Epoch 147/1000: Training Accuracy = 75.56%\n",
      "Epoch 148/1000: Training Accuracy = 75.98%\n",
      "Epoch 149/1000: Training Accuracy = 76.12%\n",
      "Epoch 150/1000: Training Accuracy = 77.67%\n",
      "Epoch 151/1000: Training Accuracy = 75.56%\n",
      "Epoch 152/1000: Training Accuracy = 75.98%\n",
      "Epoch 153/1000: Training Accuracy = 75.98%\n",
      "Epoch 154/1000: Training Accuracy = 77.67%\n",
      "Epoch 155/1000: Training Accuracy = 75.56%\n",
      "Epoch 156/1000: Training Accuracy = 75.56%\n",
      "Epoch 157/1000: Training Accuracy = 75.98%\n",
      "Epoch 158/1000: Training Accuracy = 76.12%\n",
      "Epoch 159/1000: Training Accuracy = 77.67%\n",
      "Epoch 160/1000: Training Accuracy = 75.56%\n",
      "Epoch 161/1000: Training Accuracy = 75.98%\n",
      "Epoch 162/1000: Training Accuracy = 75.98%\n",
      "Epoch 163/1000: Training Accuracy = 77.67%\n",
      "Epoch 164/1000: Training Accuracy = 75.56%\n",
      "Epoch 165/1000: Training Accuracy = 75.98%\n",
      "Epoch 166/1000: Training Accuracy = 75.98%\n",
      "Epoch 167/1000: Training Accuracy = 77.67%\n",
      "Epoch 168/1000: Training Accuracy = 75.56%\n",
      "Epoch 169/1000: Training Accuracy = 77.95%\n",
      "Epoch 170/1000: Training Accuracy = 77.95%\n",
      "Epoch 171/1000: Training Accuracy = 77.95%\n",
      "Epoch 172/1000: Training Accuracy = 75.56%\n",
      "Epoch 173/1000: Training Accuracy = 75.98%\n",
      "Epoch 174/1000: Training Accuracy = 75.98%\n",
      "Epoch 175/1000: Training Accuracy = 77.67%\n",
      "Epoch 176/1000: Training Accuracy = 75.56%\n",
      "Epoch 177/1000: Training Accuracy = 75.98%\n",
      "Epoch 178/1000: Training Accuracy = 75.98%\n",
      "Epoch 179/1000: Training Accuracy = 77.67%\n",
      "Epoch 180/1000: Training Accuracy = 75.56%\n",
      "Epoch 181/1000: Training Accuracy = 77.95%\n",
      "Epoch 182/1000: Training Accuracy = 77.67%\n",
      "Epoch 183/1000: Training Accuracy = 75.98%\n",
      "Epoch 184/1000: Training Accuracy = 75.98%\n",
      "Epoch 185/1000: Training Accuracy = 77.67%\n",
      "Epoch 186/1000: Training Accuracy = 75.56%\n",
      "Epoch 187/1000: Training Accuracy = 77.95%\n",
      "Epoch 188/1000: Training Accuracy = 77.67%\n",
      "Epoch 189/1000: Training Accuracy = 75.98%\n",
      "Epoch 190/1000: Training Accuracy = 75.98%\n",
      "Epoch 191/1000: Training Accuracy = 77.67%\n",
      "Epoch 192/1000: Training Accuracy = 75.56%\n",
      "Epoch 193/1000: Training Accuracy = 77.95%\n",
      "Epoch 194/1000: Training Accuracy = 77.67%\n",
      "Epoch 195/1000: Training Accuracy = 75.98%\n",
      "Epoch 196/1000: Training Accuracy = 75.98%\n",
      "Epoch 197/1000: Training Accuracy = 77.67%\n",
      "Epoch 198/1000: Training Accuracy = 75.56%\n",
      "Epoch 199/1000: Training Accuracy = 77.95%\n",
      "Epoch 200/1000: Training Accuracy = 77.67%\n",
      "Epoch 201/1000: Training Accuracy = 75.98%\n",
      "Epoch 202/1000: Training Accuracy = 75.98%\n",
      "Epoch 203/1000: Training Accuracy = 77.67%\n",
      "Epoch 204/1000: Training Accuracy = 75.56%\n",
      "Epoch 205/1000: Training Accuracy = 77.95%\n",
      "Epoch 206/1000: Training Accuracy = 77.67%\n",
      "Epoch 207/1000: Training Accuracy = 75.98%\n",
      "Epoch 208/1000: Training Accuracy = 75.98%\n",
      "Epoch 209/1000: Training Accuracy = 77.67%\n",
      "Epoch 210/1000: Training Accuracy = 75.56%\n",
      "Epoch 211/1000: Training Accuracy = 77.95%\n",
      "Epoch 212/1000: Training Accuracy = 77.67%\n",
      "Epoch 213/1000: Training Accuracy = 77.95%\n",
      "Epoch 214/1000: Training Accuracy = 77.95%\n",
      "Epoch 215/1000: Training Accuracy = 77.67%\n",
      "Epoch 216/1000: Training Accuracy = 77.95%\n",
      "Epoch 217/1000: Training Accuracy = 77.95%\n",
      "Epoch 218/1000: Training Accuracy = 77.67%\n",
      "Epoch 219/1000: Training Accuracy = 77.95%\n",
      "Epoch 220/1000: Training Accuracy = 77.95%\n",
      "Epoch 221/1000: Training Accuracy = 77.67%\n",
      "Epoch 222/1000: Training Accuracy = 77.95%\n",
      "Epoch 223/1000: Training Accuracy = 77.95%\n",
      "Epoch 224/1000: Training Accuracy = 77.95%\n",
      "Epoch 225/1000: Training Accuracy = 77.95%\n",
      "Epoch 226/1000: Training Accuracy = 77.95%\n",
      "Epoch 227/1000: Training Accuracy = 77.95%\n",
      "Epoch 228/1000: Training Accuracy = 77.95%\n",
      "Epoch 229/1000: Training Accuracy = 77.95%\n",
      "Epoch 230/1000: Training Accuracy = 77.95%\n",
      "Epoch 231/1000: Training Accuracy = 77.95%\n",
      "Epoch 232/1000: Training Accuracy = 77.95%\n",
      "Epoch 233/1000: Training Accuracy = 77.95%\n",
      "Epoch 234/1000: Training Accuracy = 77.95%\n",
      "Epoch 235/1000: Training Accuracy = 77.95%\n",
      "Epoch 236/1000: Training Accuracy = 77.95%\n",
      "Epoch 237/1000: Training Accuracy = 77.95%\n",
      "Epoch 238/1000: Training Accuracy = 77.95%\n",
      "Epoch 239/1000: Training Accuracy = 77.95%\n",
      "Epoch 240/1000: Training Accuracy = 77.95%\n",
      "Epoch 241/1000: Training Accuracy = 77.95%\n",
      "Epoch 242/1000: Training Accuracy = 77.95%\n",
      "Epoch 243/1000: Training Accuracy = 77.95%\n",
      "Epoch 244/1000: Training Accuracy = 77.95%\n",
      "Epoch 245/1000: Training Accuracy = 77.95%\n",
      "Epoch 246/1000: Training Accuracy = 77.95%\n",
      "Epoch 247/1000: Training Accuracy = 77.95%\n",
      "Epoch 248/1000: Training Accuracy = 77.95%\n",
      "Epoch 249/1000: Training Accuracy = 77.95%\n",
      "Epoch 250/1000: Training Accuracy = 77.95%\n",
      "Epoch 251/1000: Training Accuracy = 77.95%\n",
      "Epoch 252/1000: Training Accuracy = 77.95%\n",
      "Epoch 253/1000: Training Accuracy = 77.95%\n",
      "Epoch 254/1000: Training Accuracy = 77.95%\n",
      "Epoch 255/1000: Training Accuracy = 77.95%\n",
      "Epoch 256/1000: Training Accuracy = 77.95%\n",
      "Epoch 257/1000: Training Accuracy = 77.95%\n",
      "Epoch 258/1000: Training Accuracy = 77.95%\n",
      "Epoch 259/1000: Training Accuracy = 77.95%\n",
      "Epoch 260/1000: Training Accuracy = 77.95%\n",
      "Epoch 261/1000: Training Accuracy = 77.95%\n",
      "Epoch 262/1000: Training Accuracy = 77.95%\n",
      "Epoch 263/1000: Training Accuracy = 77.95%\n",
      "Epoch 264/1000: Training Accuracy = 77.95%\n",
      "Epoch 265/1000: Training Accuracy = 77.95%\n",
      "Epoch 266/1000: Training Accuracy = 77.95%\n",
      "Epoch 267/1000: Training Accuracy = 77.95%\n",
      "Epoch 268/1000: Training Accuracy = 77.95%\n",
      "Epoch 269/1000: Training Accuracy = 77.95%\n",
      "Epoch 270/1000: Training Accuracy = 77.95%\n",
      "Epoch 271/1000: Training Accuracy = 77.95%\n",
      "Epoch 272/1000: Training Accuracy = 77.95%\n",
      "Epoch 273/1000: Training Accuracy = 77.95%\n",
      "Epoch 274/1000: Training Accuracy = 77.95%\n",
      "Epoch 275/1000: Training Accuracy = 77.95%\n",
      "Epoch 276/1000: Training Accuracy = 77.95%\n",
      "Epoch 277/1000: Training Accuracy = 77.95%\n",
      "Epoch 278/1000: Training Accuracy = 77.95%\n",
      "Epoch 279/1000: Training Accuracy = 77.95%\n",
      "Epoch 280/1000: Training Accuracy = 77.95%\n",
      "Epoch 281/1000: Training Accuracy = 77.95%\n",
      "Epoch 282/1000: Training Accuracy = 77.95%\n",
      "Epoch 283/1000: Training Accuracy = 77.95%\n",
      "Epoch 284/1000: Training Accuracy = 77.95%\n",
      "Epoch 285/1000: Training Accuracy = 77.95%\n",
      "Epoch 286/1000: Training Accuracy = 77.95%\n",
      "Epoch 287/1000: Training Accuracy = 77.95%\n",
      "Epoch 288/1000: Training Accuracy = 77.95%\n",
      "Epoch 289/1000: Training Accuracy = 77.95%\n",
      "Epoch 290/1000: Training Accuracy = 77.95%\n",
      "Epoch 291/1000: Training Accuracy = 77.95%\n",
      "Epoch 292/1000: Training Accuracy = 77.95%\n",
      "Epoch 293/1000: Training Accuracy = 77.95%\n",
      "Epoch 294/1000: Training Accuracy = 77.95%\n",
      "Epoch 295/1000: Training Accuracy = 77.95%\n",
      "Epoch 296/1000: Training Accuracy = 77.95%\n",
      "Epoch 297/1000: Training Accuracy = 77.95%\n",
      "Epoch 298/1000: Training Accuracy = 77.95%\n",
      "Epoch 299/1000: Training Accuracy = 77.95%\n",
      "Epoch 300/1000: Training Accuracy = 77.95%\n",
      "Epoch 301/1000: Training Accuracy = 77.95%\n",
      "Epoch 302/1000: Training Accuracy = 77.95%\n",
      "Epoch 303/1000: Training Accuracy = 77.95%\n",
      "Epoch 304/1000: Training Accuracy = 77.95%\n",
      "Epoch 305/1000: Training Accuracy = 77.95%\n",
      "Epoch 306/1000: Training Accuracy = 77.95%\n",
      "Epoch 307/1000: Training Accuracy = 77.95%\n",
      "Epoch 308/1000: Training Accuracy = 77.95%\n",
      "Epoch 309/1000: Training Accuracy = 77.95%\n",
      "Epoch 310/1000: Training Accuracy = 77.95%\n",
      "Epoch 311/1000: Training Accuracy = 77.95%\n",
      "Epoch 312/1000: Training Accuracy = 77.95%\n",
      "Epoch 313/1000: Training Accuracy = 77.95%\n",
      "Epoch 314/1000: Training Accuracy = 77.95%\n",
      "Epoch 315/1000: Training Accuracy = 77.95%\n",
      "Epoch 316/1000: Training Accuracy = 77.95%\n",
      "Epoch 317/1000: Training Accuracy = 77.95%\n",
      "Epoch 318/1000: Training Accuracy = 77.95%\n",
      "Epoch 319/1000: Training Accuracy = 77.95%\n",
      "Epoch 320/1000: Training Accuracy = 77.95%\n",
      "Epoch 321/1000: Training Accuracy = 77.95%\n",
      "Epoch 322/1000: Training Accuracy = 77.95%\n",
      "Epoch 323/1000: Training Accuracy = 77.95%\n",
      "Epoch 324/1000: Training Accuracy = 77.95%\n",
      "Epoch 325/1000: Training Accuracy = 77.95%\n",
      "Epoch 326/1000: Training Accuracy = 77.95%\n",
      "Epoch 327/1000: Training Accuracy = 77.95%\n",
      "Epoch 328/1000: Training Accuracy = 77.95%\n",
      "Epoch 329/1000: Training Accuracy = 77.95%\n",
      "Epoch 330/1000: Training Accuracy = 77.95%\n",
      "Epoch 331/1000: Training Accuracy = 77.95%\n",
      "Epoch 332/1000: Training Accuracy = 77.95%\n",
      "Epoch 333/1000: Training Accuracy = 77.95%\n",
      "Epoch 334/1000: Training Accuracy = 77.95%\n",
      "Epoch 335/1000: Training Accuracy = 77.95%\n",
      "Epoch 336/1000: Training Accuracy = 77.95%\n",
      "Epoch 337/1000: Training Accuracy = 77.95%\n",
      "Epoch 338/1000: Training Accuracy = 77.95%\n",
      "Epoch 339/1000: Training Accuracy = 77.95%\n",
      "Epoch 340/1000: Training Accuracy = 77.95%\n",
      "Epoch 341/1000: Training Accuracy = 77.95%\n",
      "Epoch 342/1000: Training Accuracy = 75.56%\n",
      "Epoch 343/1000: Training Accuracy = 75.98%\n",
      "Epoch 344/1000: Training Accuracy = 75.98%\n",
      "Epoch 345/1000: Training Accuracy = 77.67%\n",
      "Epoch 346/1000: Training Accuracy = 75.56%\n",
      "Epoch 347/1000: Training Accuracy = 75.56%\n",
      "Epoch 348/1000: Training Accuracy = 75.98%\n",
      "Epoch 349/1000: Training Accuracy = 76.12%\n",
      "Epoch 350/1000: Training Accuracy = 77.67%\n",
      "Epoch 351/1000: Training Accuracy = 75.56%\n",
      "Epoch 352/1000: Training Accuracy = 75.98%\n",
      "Epoch 353/1000: Training Accuracy = 75.98%\n",
      "Epoch 354/1000: Training Accuracy = 77.67%\n",
      "Epoch 355/1000: Training Accuracy = 75.56%\n",
      "Epoch 356/1000: Training Accuracy = 75.56%\n",
      "Epoch 357/1000: Training Accuracy = 75.98%\n",
      "Epoch 358/1000: Training Accuracy = 76.12%\n",
      "Epoch 359/1000: Training Accuracy = 77.67%\n",
      "Epoch 360/1000: Training Accuracy = 75.56%\n",
      "Epoch 361/1000: Training Accuracy = 75.98%\n",
      "Epoch 362/1000: Training Accuracy = 75.98%\n",
      "Epoch 363/1000: Training Accuracy = 77.67%\n",
      "Epoch 364/1000: Training Accuracy = 75.56%\n",
      "Epoch 365/1000: Training Accuracy = 75.98%\n",
      "Epoch 366/1000: Training Accuracy = 75.98%\n",
      "Epoch 367/1000: Training Accuracy = 77.67%\n",
      "Epoch 368/1000: Training Accuracy = 75.56%\n",
      "Epoch 369/1000: Training Accuracy = 77.95%\n",
      "Epoch 370/1000: Training Accuracy = 77.95%\n",
      "Epoch 371/1000: Training Accuracy = 77.95%\n",
      "Epoch 372/1000: Training Accuracy = 75.56%\n",
      "Epoch 373/1000: Training Accuracy = 75.98%\n",
      "Epoch 374/1000: Training Accuracy = 75.98%\n",
      "Epoch 375/1000: Training Accuracy = 77.67%\n",
      "Epoch 376/1000: Training Accuracy = 75.56%\n",
      "Epoch 377/1000: Training Accuracy = 75.98%\n",
      "Epoch 378/1000: Training Accuracy = 75.98%\n",
      "Epoch 379/1000: Training Accuracy = 77.67%\n",
      "Epoch 380/1000: Training Accuracy = 75.56%\n",
      "Epoch 381/1000: Training Accuracy = 77.95%\n",
      "Epoch 382/1000: Training Accuracy = 77.67%\n",
      "Epoch 383/1000: Training Accuracy = 75.98%\n",
      "Epoch 384/1000: Training Accuracy = 75.98%\n",
      "Epoch 385/1000: Training Accuracy = 77.67%\n",
      "Epoch 386/1000: Training Accuracy = 75.56%\n",
      "Epoch 387/1000: Training Accuracy = 77.95%\n",
      "Epoch 388/1000: Training Accuracy = 77.67%\n",
      "Epoch 389/1000: Training Accuracy = 75.98%\n",
      "Epoch 390/1000: Training Accuracy = 75.98%\n",
      "Epoch 391/1000: Training Accuracy = 77.67%\n",
      "Epoch 392/1000: Training Accuracy = 75.56%\n",
      "Epoch 393/1000: Training Accuracy = 77.95%\n",
      "Epoch 394/1000: Training Accuracy = 77.67%\n",
      "Epoch 395/1000: Training Accuracy = 75.98%\n",
      "Epoch 396/1000: Training Accuracy = 75.98%\n",
      "Epoch 397/1000: Training Accuracy = 77.67%\n",
      "Epoch 398/1000: Training Accuracy = 75.56%\n",
      "Epoch 399/1000: Training Accuracy = 77.95%\n",
      "Epoch 400/1000: Training Accuracy = 77.67%\n",
      "Epoch 401/1000: Training Accuracy = 75.98%\n",
      "Epoch 402/1000: Training Accuracy = 75.98%\n",
      "Epoch 403/1000: Training Accuracy = 77.67%\n",
      "Epoch 404/1000: Training Accuracy = 75.56%\n",
      "Epoch 405/1000: Training Accuracy = 77.95%\n",
      "Epoch 406/1000: Training Accuracy = 77.67%\n",
      "Epoch 407/1000: Training Accuracy = 75.98%\n",
      "Epoch 408/1000: Training Accuracy = 75.98%\n",
      "Epoch 409/1000: Training Accuracy = 77.67%\n",
      "Epoch 410/1000: Training Accuracy = 75.56%\n",
      "Epoch 411/1000: Training Accuracy = 77.95%\n",
      "Epoch 412/1000: Training Accuracy = 77.67%\n",
      "Epoch 413/1000: Training Accuracy = 77.95%\n",
      "Epoch 414/1000: Training Accuracy = 77.95%\n",
      "Epoch 415/1000: Training Accuracy = 77.67%\n",
      "Epoch 416/1000: Training Accuracy = 77.95%\n",
      "Epoch 417/1000: Training Accuracy = 77.95%\n",
      "Epoch 418/1000: Training Accuracy = 77.67%\n",
      "Epoch 419/1000: Training Accuracy = 77.95%\n",
      "Epoch 420/1000: Training Accuracy = 77.95%\n",
      "Epoch 421/1000: Training Accuracy = 77.67%\n",
      "Epoch 422/1000: Training Accuracy = 77.95%\n",
      "Epoch 423/1000: Training Accuracy = 77.95%\n",
      "Epoch 424/1000: Training Accuracy = 77.95%\n",
      "Epoch 425/1000: Training Accuracy = 77.95%\n",
      "Epoch 426/1000: Training Accuracy = 77.95%\n",
      "Epoch 427/1000: Training Accuracy = 77.95%\n",
      "Epoch 428/1000: Training Accuracy = 77.95%\n",
      "Epoch 429/1000: Training Accuracy = 77.95%\n",
      "Epoch 430/1000: Training Accuracy = 77.95%\n",
      "Epoch 431/1000: Training Accuracy = 77.95%\n",
      "Epoch 432/1000: Training Accuracy = 77.95%\n",
      "Epoch 433/1000: Training Accuracy = 77.95%\n",
      "Epoch 434/1000: Training Accuracy = 77.95%\n",
      "Epoch 435/1000: Training Accuracy = 77.95%\n",
      "Epoch 436/1000: Training Accuracy = 77.95%\n",
      "Epoch 437/1000: Training Accuracy = 77.95%\n",
      "Epoch 438/1000: Training Accuracy = 77.95%\n",
      "Epoch 439/1000: Training Accuracy = 77.95%\n",
      "Epoch 440/1000: Training Accuracy = 77.95%\n",
      "Epoch 441/1000: Training Accuracy = 77.95%\n",
      "Epoch 442/1000: Training Accuracy = 77.95%\n",
      "Epoch 443/1000: Training Accuracy = 77.95%\n",
      "Epoch 444/1000: Training Accuracy = 77.95%\n",
      "Epoch 445/1000: Training Accuracy = 77.95%\n",
      "Epoch 446/1000: Training Accuracy = 77.95%\n",
      "Epoch 447/1000: Training Accuracy = 77.95%\n",
      "Epoch 448/1000: Training Accuracy = 77.95%\n",
      "Epoch 449/1000: Training Accuracy = 77.95%\n",
      "Epoch 450/1000: Training Accuracy = 77.95%\n",
      "Epoch 451/1000: Training Accuracy = 77.95%\n",
      "Epoch 452/1000: Training Accuracy = 77.95%\n",
      "Epoch 453/1000: Training Accuracy = 77.95%\n",
      "Epoch 454/1000: Training Accuracy = 77.95%\n",
      "Epoch 455/1000: Training Accuracy = 77.95%\n",
      "Epoch 456/1000: Training Accuracy = 77.95%\n",
      "Epoch 457/1000: Training Accuracy = 77.95%\n",
      "Epoch 458/1000: Training Accuracy = 77.95%\n",
      "Epoch 459/1000: Training Accuracy = 77.95%\n",
      "Epoch 460/1000: Training Accuracy = 77.95%\n",
      "Epoch 461/1000: Training Accuracy = 77.95%\n",
      "Epoch 462/1000: Training Accuracy = 77.95%\n",
      "Epoch 463/1000: Training Accuracy = 77.95%\n",
      "Epoch 464/1000: Training Accuracy = 77.95%\n",
      "Epoch 465/1000: Training Accuracy = 77.95%\n",
      "Epoch 466/1000: Training Accuracy = 77.95%\n",
      "Epoch 467/1000: Training Accuracy = 77.95%\n",
      "Epoch 468/1000: Training Accuracy = 77.95%\n",
      "Epoch 469/1000: Training Accuracy = 77.95%\n",
      "Epoch 470/1000: Training Accuracy = 77.95%\n",
      "Epoch 471/1000: Training Accuracy = 77.95%\n",
      "Epoch 472/1000: Training Accuracy = 77.95%\n",
      "Epoch 473/1000: Training Accuracy = 77.95%\n",
      "Epoch 474/1000: Training Accuracy = 77.95%\n",
      "Epoch 475/1000: Training Accuracy = 77.95%\n",
      "Epoch 476/1000: Training Accuracy = 77.95%\n",
      "Epoch 477/1000: Training Accuracy = 77.95%\n",
      "Epoch 478/1000: Training Accuracy = 77.95%\n",
      "Epoch 479/1000: Training Accuracy = 77.95%\n",
      "Epoch 480/1000: Training Accuracy = 77.95%\n",
      "Epoch 481/1000: Training Accuracy = 77.95%\n",
      "Epoch 482/1000: Training Accuracy = 77.95%\n",
      "Epoch 483/1000: Training Accuracy = 77.95%\n",
      "Epoch 484/1000: Training Accuracy = 77.95%\n",
      "Epoch 485/1000: Training Accuracy = 77.95%\n",
      "Epoch 486/1000: Training Accuracy = 77.95%\n",
      "Epoch 487/1000: Training Accuracy = 77.95%\n",
      "Epoch 488/1000: Training Accuracy = 77.95%\n",
      "Epoch 489/1000: Training Accuracy = 77.95%\n",
      "Epoch 490/1000: Training Accuracy = 77.95%\n",
      "Epoch 491/1000: Training Accuracy = 77.95%\n",
      "Epoch 492/1000: Training Accuracy = 77.95%\n",
      "Epoch 493/1000: Training Accuracy = 77.95%\n",
      "Epoch 494/1000: Training Accuracy = 77.95%\n",
      "Epoch 495/1000: Training Accuracy = 77.95%\n",
      "Epoch 496/1000: Training Accuracy = 77.95%\n",
      "Epoch 497/1000: Training Accuracy = 77.95%\n",
      "Epoch 498/1000: Training Accuracy = 77.95%\n",
      "Epoch 499/1000: Training Accuracy = 77.95%\n",
      "Epoch 500/1000: Training Accuracy = 77.95%\n",
      "Epoch 501/1000: Training Accuracy = 77.95%\n",
      "Epoch 502/1000: Training Accuracy = 77.95%\n",
      "Epoch 503/1000: Training Accuracy = 77.95%\n",
      "Epoch 504/1000: Training Accuracy = 77.95%\n",
      "Epoch 505/1000: Training Accuracy = 77.95%\n",
      "Epoch 506/1000: Training Accuracy = 77.95%\n",
      "Epoch 507/1000: Training Accuracy = 77.95%\n",
      "Epoch 508/1000: Training Accuracy = 77.95%\n",
      "Epoch 509/1000: Training Accuracy = 77.95%\n",
      "Epoch 510/1000: Training Accuracy = 77.95%\n",
      "Epoch 511/1000: Training Accuracy = 77.95%\n",
      "Epoch 512/1000: Training Accuracy = 77.95%\n",
      "Epoch 513/1000: Training Accuracy = 77.95%\n",
      "Epoch 514/1000: Training Accuracy = 77.95%\n",
      "Epoch 515/1000: Training Accuracy = 77.95%\n",
      "Epoch 516/1000: Training Accuracy = 77.95%\n",
      "Epoch 517/1000: Training Accuracy = 77.95%\n",
      "Epoch 518/1000: Training Accuracy = 77.95%\n",
      "Epoch 519/1000: Training Accuracy = 77.95%\n",
      "Epoch 520/1000: Training Accuracy = 77.95%\n",
      "Epoch 521/1000: Training Accuracy = 77.95%\n",
      "Epoch 522/1000: Training Accuracy = 77.95%\n",
      "Epoch 523/1000: Training Accuracy = 77.95%\n",
      "Epoch 524/1000: Training Accuracy = 77.95%\n",
      "Epoch 525/1000: Training Accuracy = 77.95%\n",
      "Epoch 526/1000: Training Accuracy = 77.95%\n",
      "Epoch 527/1000: Training Accuracy = 77.95%\n",
      "Epoch 528/1000: Training Accuracy = 77.95%\n",
      "Epoch 529/1000: Training Accuracy = 77.95%\n",
      "Epoch 530/1000: Training Accuracy = 77.95%\n",
      "Epoch 531/1000: Training Accuracy = 77.95%\n",
      "Epoch 532/1000: Training Accuracy = 77.95%\n",
      "Epoch 533/1000: Training Accuracy = 77.95%\n",
      "Epoch 534/1000: Training Accuracy = 77.95%\n",
      "Epoch 535/1000: Training Accuracy = 77.95%\n",
      "Epoch 536/1000: Training Accuracy = 77.95%\n",
      "Epoch 537/1000: Training Accuracy = 77.95%\n",
      "Epoch 538/1000: Training Accuracy = 77.95%\n",
      "Epoch 539/1000: Training Accuracy = 77.95%\n",
      "Epoch 540/1000: Training Accuracy = 77.95%\n",
      "Epoch 541/1000: Training Accuracy = 77.95%\n",
      "Epoch 542/1000: Training Accuracy = 75.56%\n",
      "Epoch 543/1000: Training Accuracy = 75.98%\n",
      "Epoch 544/1000: Training Accuracy = 75.98%\n",
      "Epoch 545/1000: Training Accuracy = 77.67%\n",
      "Epoch 546/1000: Training Accuracy = 75.56%\n",
      "Epoch 547/1000: Training Accuracy = 75.56%\n",
      "Epoch 548/1000: Training Accuracy = 75.98%\n",
      "Epoch 549/1000: Training Accuracy = 76.12%\n",
      "Epoch 550/1000: Training Accuracy = 77.67%\n",
      "Epoch 551/1000: Training Accuracy = 75.56%\n",
      "Epoch 552/1000: Training Accuracy = 75.98%\n",
      "Epoch 553/1000: Training Accuracy = 75.98%\n",
      "Epoch 554/1000: Training Accuracy = 77.67%\n",
      "Epoch 555/1000: Training Accuracy = 75.56%\n",
      "Epoch 556/1000: Training Accuracy = 75.56%\n",
      "Epoch 557/1000: Training Accuracy = 75.98%\n",
      "Epoch 558/1000: Training Accuracy = 76.12%\n",
      "Epoch 559/1000: Training Accuracy = 77.67%\n",
      "Epoch 560/1000: Training Accuracy = 75.56%\n",
      "Epoch 561/1000: Training Accuracy = 75.98%\n",
      "Epoch 562/1000: Training Accuracy = 75.98%\n",
      "Epoch 563/1000: Training Accuracy = 77.67%\n",
      "Epoch 564/1000: Training Accuracy = 75.56%\n",
      "Epoch 565/1000: Training Accuracy = 75.98%\n",
      "Epoch 566/1000: Training Accuracy = 75.98%\n",
      "Epoch 567/1000: Training Accuracy = 77.67%\n",
      "Epoch 568/1000: Training Accuracy = 75.56%\n",
      "Epoch 569/1000: Training Accuracy = 77.95%\n",
      "Epoch 570/1000: Training Accuracy = 77.95%\n",
      "Epoch 571/1000: Training Accuracy = 77.95%\n",
      "Epoch 572/1000: Training Accuracy = 75.56%\n",
      "Epoch 573/1000: Training Accuracy = 75.98%\n",
      "Epoch 574/1000: Training Accuracy = 75.98%\n",
      "Epoch 575/1000: Training Accuracy = 77.67%\n",
      "Epoch 576/1000: Training Accuracy = 75.56%\n",
      "Epoch 577/1000: Training Accuracy = 75.98%\n",
      "Epoch 578/1000: Training Accuracy = 75.98%\n",
      "Epoch 579/1000: Training Accuracy = 77.67%\n",
      "Epoch 580/1000: Training Accuracy = 75.56%\n",
      "Epoch 581/1000: Training Accuracy = 77.95%\n",
      "Epoch 582/1000: Training Accuracy = 77.67%\n",
      "Epoch 583/1000: Training Accuracy = 75.98%\n",
      "Epoch 584/1000: Training Accuracy = 75.98%\n",
      "Epoch 585/1000: Training Accuracy = 77.67%\n",
      "Epoch 586/1000: Training Accuracy = 75.56%\n",
      "Epoch 587/1000: Training Accuracy = 77.95%\n",
      "Epoch 588/1000: Training Accuracy = 77.67%\n",
      "Epoch 589/1000: Training Accuracy = 75.98%\n",
      "Epoch 590/1000: Training Accuracy = 75.98%\n",
      "Epoch 591/1000: Training Accuracy = 77.67%\n",
      "Epoch 592/1000: Training Accuracy = 75.56%\n",
      "Epoch 593/1000: Training Accuracy = 77.95%\n",
      "Epoch 594/1000: Training Accuracy = 77.67%\n",
      "Epoch 595/1000: Training Accuracy = 75.98%\n",
      "Epoch 596/1000: Training Accuracy = 75.98%\n",
      "Epoch 597/1000: Training Accuracy = 77.67%\n",
      "Epoch 598/1000: Training Accuracy = 75.56%\n",
      "Epoch 599/1000: Training Accuracy = 77.95%\n",
      "Epoch 600/1000: Training Accuracy = 77.67%\n",
      "Epoch 601/1000: Training Accuracy = 75.98%\n",
      "Epoch 602/1000: Training Accuracy = 75.98%\n",
      "Epoch 603/1000: Training Accuracy = 77.67%\n",
      "Epoch 604/1000: Training Accuracy = 75.56%\n",
      "Epoch 605/1000: Training Accuracy = 77.95%\n",
      "Epoch 606/1000: Training Accuracy = 77.67%\n",
      "Epoch 607/1000: Training Accuracy = 75.98%\n",
      "Epoch 608/1000: Training Accuracy = 75.98%\n",
      "Epoch 609/1000: Training Accuracy = 77.67%\n",
      "Epoch 610/1000: Training Accuracy = 75.56%\n",
      "Epoch 611/1000: Training Accuracy = 77.95%\n",
      "Epoch 612/1000: Training Accuracy = 77.67%\n",
      "Epoch 613/1000: Training Accuracy = 77.95%\n",
      "Epoch 614/1000: Training Accuracy = 77.95%\n",
      "Epoch 615/1000: Training Accuracy = 77.67%\n",
      "Epoch 616/1000: Training Accuracy = 77.95%\n",
      "Epoch 617/1000: Training Accuracy = 77.95%\n",
      "Epoch 618/1000: Training Accuracy = 77.67%\n",
      "Epoch 619/1000: Training Accuracy = 77.95%\n",
      "Epoch 620/1000: Training Accuracy = 77.95%\n",
      "Epoch 621/1000: Training Accuracy = 77.67%\n",
      "Epoch 622/1000: Training Accuracy = 77.95%\n",
      "Epoch 623/1000: Training Accuracy = 77.95%\n",
      "Epoch 624/1000: Training Accuracy = 77.95%\n",
      "Epoch 625/1000: Training Accuracy = 77.95%\n",
      "Epoch 626/1000: Training Accuracy = 77.95%\n",
      "Epoch 627/1000: Training Accuracy = 77.95%\n",
      "Epoch 628/1000: Training Accuracy = 77.95%\n",
      "Epoch 629/1000: Training Accuracy = 77.95%\n",
      "Epoch 630/1000: Training Accuracy = 77.95%\n",
      "Epoch 631/1000: Training Accuracy = 77.95%\n",
      "Epoch 632/1000: Training Accuracy = 77.95%\n",
      "Epoch 633/1000: Training Accuracy = 77.95%\n",
      "Epoch 634/1000: Training Accuracy = 77.95%\n",
      "Epoch 635/1000: Training Accuracy = 77.95%\n",
      "Epoch 636/1000: Training Accuracy = 77.95%\n",
      "Epoch 637/1000: Training Accuracy = 77.95%\n",
      "Epoch 638/1000: Training Accuracy = 77.95%\n",
      "Epoch 639/1000: Training Accuracy = 77.95%\n",
      "Epoch 640/1000: Training Accuracy = 77.95%\n",
      "Epoch 641/1000: Training Accuracy = 77.95%\n",
      "Epoch 642/1000: Training Accuracy = 77.95%\n",
      "Epoch 643/1000: Training Accuracy = 77.95%\n",
      "Epoch 644/1000: Training Accuracy = 77.95%\n",
      "Epoch 645/1000: Training Accuracy = 77.95%\n",
      "Epoch 646/1000: Training Accuracy = 77.95%\n",
      "Epoch 647/1000: Training Accuracy = 77.95%\n",
      "Epoch 648/1000: Training Accuracy = 77.95%\n",
      "Epoch 649/1000: Training Accuracy = 77.95%\n",
      "Epoch 650/1000: Training Accuracy = 77.95%\n",
      "Epoch 651/1000: Training Accuracy = 77.95%\n",
      "Epoch 652/1000: Training Accuracy = 77.95%\n",
      "Epoch 653/1000: Training Accuracy = 77.95%\n",
      "Epoch 654/1000: Training Accuracy = 77.95%\n",
      "Epoch 655/1000: Training Accuracy = 77.95%\n",
      "Epoch 656/1000: Training Accuracy = 77.95%\n",
      "Epoch 657/1000: Training Accuracy = 77.95%\n",
      "Epoch 658/1000: Training Accuracy = 77.95%\n",
      "Epoch 659/1000: Training Accuracy = 77.95%\n",
      "Epoch 660/1000: Training Accuracy = 77.95%\n",
      "Epoch 661/1000: Training Accuracy = 77.95%\n",
      "Epoch 662/1000: Training Accuracy = 77.95%\n",
      "Epoch 663/1000: Training Accuracy = 77.95%\n",
      "Epoch 664/1000: Training Accuracy = 77.95%\n",
      "Epoch 665/1000: Training Accuracy = 77.95%\n",
      "Epoch 666/1000: Training Accuracy = 77.95%\n",
      "Epoch 667/1000: Training Accuracy = 77.95%\n",
      "Epoch 668/1000: Training Accuracy = 77.95%\n",
      "Epoch 669/1000: Training Accuracy = 77.95%\n",
      "Epoch 670/1000: Training Accuracy = 77.95%\n",
      "Epoch 671/1000: Training Accuracy = 77.95%\n",
      "Epoch 672/1000: Training Accuracy = 77.95%\n",
      "Epoch 673/1000: Training Accuracy = 77.95%\n",
      "Epoch 674/1000: Training Accuracy = 77.95%\n",
      "Epoch 675/1000: Training Accuracy = 77.95%\n",
      "Epoch 676/1000: Training Accuracy = 77.95%\n",
      "Epoch 677/1000: Training Accuracy = 77.95%\n",
      "Epoch 678/1000: Training Accuracy = 77.95%\n",
      "Epoch 679/1000: Training Accuracy = 77.95%\n",
      "Epoch 680/1000: Training Accuracy = 77.95%\n",
      "Epoch 681/1000: Training Accuracy = 77.95%\n",
      "Epoch 682/1000: Training Accuracy = 77.95%\n",
      "Epoch 683/1000: Training Accuracy = 77.95%\n",
      "Epoch 684/1000: Training Accuracy = 77.95%\n",
      "Epoch 685/1000: Training Accuracy = 77.95%\n",
      "Epoch 686/1000: Training Accuracy = 77.95%\n",
      "Epoch 687/1000: Training Accuracy = 77.95%\n",
      "Epoch 688/1000: Training Accuracy = 77.95%\n",
      "Epoch 689/1000: Training Accuracy = 77.95%\n",
      "Epoch 690/1000: Training Accuracy = 77.95%\n",
      "Epoch 691/1000: Training Accuracy = 77.95%\n",
      "Epoch 692/1000: Training Accuracy = 77.95%\n",
      "Epoch 693/1000: Training Accuracy = 77.95%\n",
      "Epoch 694/1000: Training Accuracy = 77.95%\n",
      "Epoch 695/1000: Training Accuracy = 77.95%\n",
      "Epoch 696/1000: Training Accuracy = 77.95%\n",
      "Epoch 697/1000: Training Accuracy = 77.95%\n",
      "Epoch 698/1000: Training Accuracy = 77.95%\n",
      "Epoch 699/1000: Training Accuracy = 77.95%\n",
      "Epoch 700/1000: Training Accuracy = 77.95%\n",
      "Epoch 701/1000: Training Accuracy = 77.95%\n",
      "Epoch 702/1000: Training Accuracy = 77.95%\n",
      "Epoch 703/1000: Training Accuracy = 77.95%\n",
      "Epoch 704/1000: Training Accuracy = 77.95%\n",
      "Epoch 705/1000: Training Accuracy = 77.95%\n",
      "Epoch 706/1000: Training Accuracy = 77.95%\n",
      "Epoch 707/1000: Training Accuracy = 77.95%\n",
      "Epoch 708/1000: Training Accuracy = 77.95%\n",
      "Epoch 709/1000: Training Accuracy = 77.95%\n",
      "Epoch 710/1000: Training Accuracy = 77.95%\n",
      "Epoch 711/1000: Training Accuracy = 77.95%\n",
      "Epoch 712/1000: Training Accuracy = 77.95%\n",
      "Epoch 713/1000: Training Accuracy = 77.95%\n",
      "Epoch 714/1000: Training Accuracy = 77.95%\n",
      "Epoch 715/1000: Training Accuracy = 77.95%\n",
      "Epoch 716/1000: Training Accuracy = 77.95%\n",
      "Epoch 717/1000: Training Accuracy = 77.95%\n",
      "Epoch 718/1000: Training Accuracy = 77.95%\n",
      "Epoch 719/1000: Training Accuracy = 77.95%\n",
      "Epoch 720/1000: Training Accuracy = 77.95%\n",
      "Epoch 721/1000: Training Accuracy = 77.95%\n",
      "Epoch 722/1000: Training Accuracy = 77.95%\n",
      "Epoch 723/1000: Training Accuracy = 77.95%\n",
      "Epoch 724/1000: Training Accuracy = 77.95%\n",
      "Epoch 725/1000: Training Accuracy = 77.95%\n",
      "Epoch 726/1000: Training Accuracy = 77.95%\n",
      "Epoch 727/1000: Training Accuracy = 77.95%\n",
      "Epoch 728/1000: Training Accuracy = 77.95%\n",
      "Epoch 729/1000: Training Accuracy = 77.95%\n",
      "Epoch 730/1000: Training Accuracy = 77.95%\n",
      "Epoch 731/1000: Training Accuracy = 77.95%\n",
      "Epoch 732/1000: Training Accuracy = 77.95%\n",
      "Epoch 733/1000: Training Accuracy = 77.95%\n",
      "Epoch 734/1000: Training Accuracy = 77.95%\n",
      "Epoch 735/1000: Training Accuracy = 77.95%\n",
      "Epoch 736/1000: Training Accuracy = 77.95%\n",
      "Epoch 737/1000: Training Accuracy = 77.95%\n",
      "Epoch 738/1000: Training Accuracy = 77.95%\n",
      "Epoch 739/1000: Training Accuracy = 77.95%\n",
      "Epoch 740/1000: Training Accuracy = 77.95%\n",
      "Epoch 741/1000: Training Accuracy = 77.95%\n",
      "Epoch 742/1000: Training Accuracy = 75.56%\n",
      "Epoch 743/1000: Training Accuracy = 75.98%\n",
      "Epoch 744/1000: Training Accuracy = 75.98%\n",
      "Epoch 745/1000: Training Accuracy = 77.67%\n",
      "Epoch 746/1000: Training Accuracy = 75.56%\n",
      "Epoch 747/1000: Training Accuracy = 75.56%\n",
      "Epoch 748/1000: Training Accuracy = 75.98%\n",
      "Epoch 749/1000: Training Accuracy = 76.12%\n",
      "Epoch 750/1000: Training Accuracy = 77.67%\n",
      "Epoch 751/1000: Training Accuracy = 75.56%\n",
      "Epoch 752/1000: Training Accuracy = 75.98%\n",
      "Epoch 753/1000: Training Accuracy = 75.98%\n",
      "Epoch 754/1000: Training Accuracy = 77.67%\n",
      "Epoch 755/1000: Training Accuracy = 75.56%\n",
      "Epoch 756/1000: Training Accuracy = 75.56%\n",
      "Epoch 757/1000: Training Accuracy = 75.98%\n",
      "Epoch 758/1000: Training Accuracy = 76.12%\n",
      "Epoch 759/1000: Training Accuracy = 77.67%\n",
      "Epoch 760/1000: Training Accuracy = 75.56%\n",
      "Epoch 761/1000: Training Accuracy = 75.98%\n",
      "Epoch 762/1000: Training Accuracy = 75.98%\n",
      "Epoch 763/1000: Training Accuracy = 77.67%\n",
      "Epoch 764/1000: Training Accuracy = 75.56%\n",
      "Epoch 765/1000: Training Accuracy = 75.98%\n",
      "Epoch 766/1000: Training Accuracy = 75.98%\n",
      "Epoch 767/1000: Training Accuracy = 77.67%\n",
      "Epoch 768/1000: Training Accuracy = 75.56%\n",
      "Epoch 769/1000: Training Accuracy = 77.95%\n",
      "Epoch 770/1000: Training Accuracy = 77.95%\n",
      "Epoch 771/1000: Training Accuracy = 77.95%\n",
      "Epoch 772/1000: Training Accuracy = 75.56%\n",
      "Epoch 773/1000: Training Accuracy = 75.98%\n",
      "Epoch 774/1000: Training Accuracy = 75.98%\n",
      "Epoch 775/1000: Training Accuracy = 77.67%\n",
      "Epoch 776/1000: Training Accuracy = 75.56%\n",
      "Epoch 777/1000: Training Accuracy = 75.98%\n",
      "Epoch 778/1000: Training Accuracy = 75.98%\n",
      "Epoch 779/1000: Training Accuracy = 77.67%\n",
      "Epoch 780/1000: Training Accuracy = 75.56%\n",
      "Epoch 781/1000: Training Accuracy = 77.95%\n",
      "Epoch 782/1000: Training Accuracy = 77.67%\n",
      "Epoch 783/1000: Training Accuracy = 75.98%\n",
      "Epoch 784/1000: Training Accuracy = 75.98%\n",
      "Epoch 785/1000: Training Accuracy = 77.67%\n",
      "Epoch 786/1000: Training Accuracy = 75.56%\n",
      "Epoch 787/1000: Training Accuracy = 77.95%\n",
      "Epoch 788/1000: Training Accuracy = 77.67%\n",
      "Epoch 789/1000: Training Accuracy = 75.98%\n",
      "Epoch 790/1000: Training Accuracy = 75.98%\n",
      "Epoch 791/1000: Training Accuracy = 77.67%\n",
      "Epoch 792/1000: Training Accuracy = 75.56%\n",
      "Epoch 793/1000: Training Accuracy = 77.95%\n",
      "Epoch 794/1000: Training Accuracy = 77.67%\n",
      "Epoch 795/1000: Training Accuracy = 75.98%\n",
      "Epoch 796/1000: Training Accuracy = 75.98%\n",
      "Epoch 797/1000: Training Accuracy = 77.67%\n",
      "Epoch 798/1000: Training Accuracy = 75.56%\n",
      "Epoch 799/1000: Training Accuracy = 77.95%\n",
      "Epoch 800/1000: Training Accuracy = 77.67%\n",
      "Epoch 801/1000: Training Accuracy = 75.98%\n",
      "Epoch 802/1000: Training Accuracy = 75.98%\n",
      "Epoch 803/1000: Training Accuracy = 77.67%\n",
      "Epoch 804/1000: Training Accuracy = 75.56%\n",
      "Epoch 805/1000: Training Accuracy = 77.95%\n",
      "Epoch 806/1000: Training Accuracy = 77.67%\n",
      "Epoch 807/1000: Training Accuracy = 75.98%\n",
      "Epoch 808/1000: Training Accuracy = 75.98%\n",
      "Epoch 809/1000: Training Accuracy = 77.67%\n",
      "Epoch 810/1000: Training Accuracy = 75.56%\n",
      "Epoch 811/1000: Training Accuracy = 77.95%\n",
      "Epoch 812/1000: Training Accuracy = 77.67%\n",
      "Epoch 813/1000: Training Accuracy = 77.95%\n",
      "Epoch 814/1000: Training Accuracy = 77.95%\n",
      "Epoch 815/1000: Training Accuracy = 77.67%\n",
      "Epoch 816/1000: Training Accuracy = 77.95%\n",
      "Epoch 817/1000: Training Accuracy = 77.95%\n",
      "Epoch 818/1000: Training Accuracy = 77.67%\n",
      "Epoch 819/1000: Training Accuracy = 77.95%\n",
      "Epoch 820/1000: Training Accuracy = 77.95%\n",
      "Epoch 821/1000: Training Accuracy = 77.67%\n",
      "Epoch 822/1000: Training Accuracy = 77.95%\n",
      "Epoch 823/1000: Training Accuracy = 77.95%\n",
      "Epoch 824/1000: Training Accuracy = 77.95%\n",
      "Epoch 825/1000: Training Accuracy = 77.95%\n",
      "Epoch 826/1000: Training Accuracy = 77.95%\n",
      "Epoch 827/1000: Training Accuracy = 77.95%\n",
      "Epoch 828/1000: Training Accuracy = 77.95%\n",
      "Epoch 829/1000: Training Accuracy = 77.95%\n",
      "Epoch 830/1000: Training Accuracy = 77.95%\n",
      "Epoch 831/1000: Training Accuracy = 77.95%\n",
      "Epoch 832/1000: Training Accuracy = 77.95%\n",
      "Epoch 833/1000: Training Accuracy = 77.95%\n",
      "Epoch 834/1000: Training Accuracy = 77.95%\n",
      "Epoch 835/1000: Training Accuracy = 77.95%\n",
      "Epoch 836/1000: Training Accuracy = 77.95%\n",
      "Epoch 837/1000: Training Accuracy = 77.95%\n",
      "Epoch 838/1000: Training Accuracy = 77.95%\n",
      "Epoch 839/1000: Training Accuracy = 77.95%\n",
      "Epoch 840/1000: Training Accuracy = 77.95%\n",
      "Epoch 841/1000: Training Accuracy = 77.95%\n",
      "Epoch 842/1000: Training Accuracy = 77.95%\n",
      "Epoch 843/1000: Training Accuracy = 77.95%\n",
      "Epoch 844/1000: Training Accuracy = 77.95%\n",
      "Epoch 845/1000: Training Accuracy = 77.95%\n",
      "Epoch 846/1000: Training Accuracy = 77.95%\n",
      "Epoch 847/1000: Training Accuracy = 77.95%\n",
      "Epoch 848/1000: Training Accuracy = 77.95%\n",
      "Epoch 849/1000: Training Accuracy = 77.95%\n",
      "Epoch 850/1000: Training Accuracy = 77.95%\n",
      "Epoch 851/1000: Training Accuracy = 77.95%\n",
      "Epoch 852/1000: Training Accuracy = 77.95%\n",
      "Epoch 853/1000: Training Accuracy = 77.95%\n",
      "Epoch 854/1000: Training Accuracy = 77.95%\n",
      "Epoch 855/1000: Training Accuracy = 77.95%\n",
      "Epoch 856/1000: Training Accuracy = 77.95%\n",
      "Epoch 857/1000: Training Accuracy = 77.95%\n",
      "Epoch 858/1000: Training Accuracy = 77.95%\n",
      "Epoch 859/1000: Training Accuracy = 77.95%\n",
      "Epoch 860/1000: Training Accuracy = 77.95%\n",
      "Epoch 861/1000: Training Accuracy = 77.95%\n",
      "Epoch 862/1000: Training Accuracy = 77.95%\n",
      "Epoch 863/1000: Training Accuracy = 77.95%\n",
      "Epoch 864/1000: Training Accuracy = 77.95%\n",
      "Epoch 865/1000: Training Accuracy = 77.95%\n",
      "Epoch 866/1000: Training Accuracy = 77.95%\n",
      "Epoch 867/1000: Training Accuracy = 77.95%\n",
      "Epoch 868/1000: Training Accuracy = 77.95%\n",
      "Epoch 869/1000: Training Accuracy = 77.95%\n",
      "Epoch 870/1000: Training Accuracy = 77.95%\n",
      "Epoch 871/1000: Training Accuracy = 77.95%\n",
      "Epoch 872/1000: Training Accuracy = 77.95%\n",
      "Epoch 873/1000: Training Accuracy = 77.95%\n",
      "Epoch 874/1000: Training Accuracy = 77.95%\n",
      "Epoch 875/1000: Training Accuracy = 77.95%\n",
      "Epoch 876/1000: Training Accuracy = 77.95%\n",
      "Epoch 877/1000: Training Accuracy = 77.95%\n",
      "Epoch 878/1000: Training Accuracy = 77.95%\n",
      "Epoch 879/1000: Training Accuracy = 77.95%\n",
      "Epoch 880/1000: Training Accuracy = 77.95%\n",
      "Epoch 881/1000: Training Accuracy = 77.95%\n",
      "Epoch 882/1000: Training Accuracy = 77.95%\n",
      "Epoch 883/1000: Training Accuracy = 77.95%\n",
      "Epoch 884/1000: Training Accuracy = 77.95%\n",
      "Epoch 885/1000: Training Accuracy = 77.95%\n",
      "Epoch 886/1000: Training Accuracy = 77.95%\n",
      "Epoch 887/1000: Training Accuracy = 77.95%\n",
      "Epoch 888/1000: Training Accuracy = 77.95%\n",
      "Epoch 889/1000: Training Accuracy = 77.95%\n",
      "Epoch 890/1000: Training Accuracy = 77.95%\n",
      "Epoch 891/1000: Training Accuracy = 77.95%\n",
      "Epoch 892/1000: Training Accuracy = 77.95%\n",
      "Epoch 893/1000: Training Accuracy = 77.95%\n",
      "Epoch 894/1000: Training Accuracy = 77.95%\n",
      "Epoch 895/1000: Training Accuracy = 77.95%\n",
      "Epoch 896/1000: Training Accuracy = 77.95%\n",
      "Epoch 897/1000: Training Accuracy = 77.95%\n",
      "Epoch 898/1000: Training Accuracy = 77.95%\n",
      "Epoch 899/1000: Training Accuracy = 77.95%\n",
      "Epoch 900/1000: Training Accuracy = 77.95%\n",
      "Epoch 901/1000: Training Accuracy = 77.95%\n",
      "Epoch 902/1000: Training Accuracy = 77.95%\n",
      "Epoch 903/1000: Training Accuracy = 77.95%\n",
      "Epoch 904/1000: Training Accuracy = 77.95%\n",
      "Epoch 905/1000: Training Accuracy = 77.95%\n",
      "Epoch 906/1000: Training Accuracy = 77.95%\n",
      "Epoch 907/1000: Training Accuracy = 77.95%\n",
      "Epoch 908/1000: Training Accuracy = 77.95%\n",
      "Epoch 909/1000: Training Accuracy = 77.95%\n",
      "Epoch 910/1000: Training Accuracy = 77.95%\n",
      "Epoch 911/1000: Training Accuracy = 77.95%\n",
      "Epoch 912/1000: Training Accuracy = 77.95%\n",
      "Epoch 913/1000: Training Accuracy = 77.95%\n",
      "Epoch 914/1000: Training Accuracy = 77.95%\n",
      "Epoch 915/1000: Training Accuracy = 77.95%\n",
      "Epoch 916/1000: Training Accuracy = 77.95%\n",
      "Epoch 917/1000: Training Accuracy = 77.95%\n",
      "Epoch 918/1000: Training Accuracy = 77.95%\n",
      "Epoch 919/1000: Training Accuracy = 77.95%\n",
      "Epoch 920/1000: Training Accuracy = 77.95%\n",
      "Epoch 921/1000: Training Accuracy = 77.95%\n",
      "Epoch 922/1000: Training Accuracy = 77.95%\n",
      "Epoch 923/1000: Training Accuracy = 77.95%\n",
      "Epoch 924/1000: Training Accuracy = 77.95%\n",
      "Epoch 925/1000: Training Accuracy = 77.95%\n",
      "Epoch 926/1000: Training Accuracy = 77.95%\n",
      "Epoch 927/1000: Training Accuracy = 77.95%\n",
      "Epoch 928/1000: Training Accuracy = 77.95%\n",
      "Epoch 929/1000: Training Accuracy = 77.95%\n",
      "Epoch 930/1000: Training Accuracy = 77.95%\n",
      "Epoch 931/1000: Training Accuracy = 77.95%\n",
      "Epoch 932/1000: Training Accuracy = 77.95%\n",
      "Epoch 933/1000: Training Accuracy = 77.95%\n",
      "Epoch 934/1000: Training Accuracy = 77.95%\n",
      "Epoch 935/1000: Training Accuracy = 77.95%\n",
      "Epoch 936/1000: Training Accuracy = 77.95%\n",
      "Epoch 937/1000: Training Accuracy = 77.95%\n",
      "Epoch 938/1000: Training Accuracy = 77.95%\n",
      "Epoch 939/1000: Training Accuracy = 77.95%\n",
      "Epoch 940/1000: Training Accuracy = 77.95%\n",
      "Epoch 941/1000: Training Accuracy = 77.95%\n",
      "Epoch 942/1000: Training Accuracy = 75.56%\n",
      "Epoch 943/1000: Training Accuracy = 75.98%\n",
      "Epoch 944/1000: Training Accuracy = 75.98%\n",
      "Epoch 945/1000: Training Accuracy = 77.67%\n",
      "Epoch 946/1000: Training Accuracy = 75.56%\n",
      "Epoch 947/1000: Training Accuracy = 75.56%\n",
      "Epoch 948/1000: Training Accuracy = 75.98%\n",
      "Epoch 949/1000: Training Accuracy = 76.12%\n",
      "Epoch 950/1000: Training Accuracy = 77.67%\n",
      "Epoch 951/1000: Training Accuracy = 75.56%\n",
      "Epoch 952/1000: Training Accuracy = 75.98%\n",
      "Epoch 953/1000: Training Accuracy = 75.98%\n",
      "Epoch 954/1000: Training Accuracy = 77.67%\n",
      "Epoch 955/1000: Training Accuracy = 75.56%\n",
      "Epoch 956/1000: Training Accuracy = 75.56%\n",
      "Epoch 957/1000: Training Accuracy = 75.98%\n",
      "Epoch 958/1000: Training Accuracy = 76.12%\n",
      "Epoch 959/1000: Training Accuracy = 77.67%\n",
      "Epoch 960/1000: Training Accuracy = 75.56%\n",
      "Epoch 961/1000: Training Accuracy = 75.98%\n",
      "Epoch 962/1000: Training Accuracy = 75.98%\n",
      "Epoch 963/1000: Training Accuracy = 77.67%\n",
      "Epoch 964/1000: Training Accuracy = 75.56%\n",
      "Epoch 965/1000: Training Accuracy = 75.98%\n",
      "Epoch 966/1000: Training Accuracy = 75.98%\n",
      "Epoch 967/1000: Training Accuracy = 77.67%\n",
      "Epoch 968/1000: Training Accuracy = 75.56%\n",
      "Epoch 969/1000: Training Accuracy = 77.95%\n",
      "Epoch 970/1000: Training Accuracy = 77.95%\n",
      "Epoch 971/1000: Training Accuracy = 77.95%\n",
      "Epoch 972/1000: Training Accuracy = 75.56%\n",
      "Epoch 973/1000: Training Accuracy = 75.98%\n",
      "Epoch 974/1000: Training Accuracy = 75.98%\n",
      "Epoch 975/1000: Training Accuracy = 77.67%\n",
      "Epoch 976/1000: Training Accuracy = 75.56%\n",
      "Epoch 977/1000: Training Accuracy = 75.98%\n",
      "Epoch 978/1000: Training Accuracy = 75.98%\n",
      "Epoch 979/1000: Training Accuracy = 77.67%\n",
      "Epoch 980/1000: Training Accuracy = 75.56%\n",
      "Epoch 981/1000: Training Accuracy = 77.95%\n",
      "Epoch 982/1000: Training Accuracy = 77.67%\n",
      "Epoch 983/1000: Training Accuracy = 75.98%\n",
      "Epoch 984/1000: Training Accuracy = 75.98%\n",
      "Epoch 985/1000: Training Accuracy = 77.67%\n",
      "Epoch 986/1000: Training Accuracy = 75.56%\n",
      "Epoch 987/1000: Training Accuracy = 77.95%\n",
      "Epoch 988/1000: Training Accuracy = 77.67%\n",
      "Epoch 989/1000: Training Accuracy = 75.98%\n",
      "Epoch 990/1000: Training Accuracy = 75.98%\n",
      "Epoch 991/1000: Training Accuracy = 77.67%\n",
      "Epoch 992/1000: Training Accuracy = 75.56%\n",
      "Epoch 993/1000: Training Accuracy = 77.95%\n",
      "Epoch 994/1000: Training Accuracy = 77.67%\n",
      "Epoch 995/1000: Training Accuracy = 75.98%\n",
      "Epoch 996/1000: Training Accuracy = 75.98%\n",
      "Epoch 997/1000: Training Accuracy = 77.67%\n",
      "Epoch 998/1000: Training Accuracy = 75.56%\n",
      "Epoch 999/1000: Training Accuracy = 77.95%\n",
      "Epoch 1000/1000: Training Accuracy = 77.67%\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train_2col.shape[1]\n",
    "perceptron_2col = SingleLayerPerceptron(input_size, learning_rate=lr, epochs=epochs)\n",
    "perceptron_2col.train(x_train_2col, y_train_2col)\n",
    "pred_2col = perceptron_2col.predict(x_test_2col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cf_2col = confusion_matrix(y_test_2col, pred_2col)\n",
    "plot_cm(model_cf_2col, 'Model Sex & Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Survived</th>\n",
       "      <td>0.966825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983133</td>\n",
       "      <td>204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.971660</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.978852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.983412</td>\n",
       "      <td>0.972441</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.979554</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "Not Survived   0.966825  1.000000  0.983133  204.000000\n",
       "Survived       1.000000  0.944882  0.971660  127.000000\n",
       "accuracy       0.978852  0.978852  0.978852    0.978852\n",
       "macro avg      0.983412  0.972441  0.977396  331.000000\n",
       "weighted avg   0.979554  0.978852  0.978731  331.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_report_2col = classification_report(y_test_2col, pred_2col, output_dict=True, target_names=['Not Survived',\"Survived\"])\n",
    "pd.DataFrame(model_report_2col).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Binary Sigmoid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerPerceptronSigmoid:\n",
    "    def __init__(self, input_size, learning_rate, epochs):\n",
    "        np.random.seed(42)\n",
    "        self.weights = np.random.uniform(-0.3,0.3, size=input_size+1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _activation_function_derivative(self, x):\n",
    "        return self._activation_function(x) * (1 - self._activation_function(x))\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return self._activation_function(summation)\n",
    "\n",
    "    def _calculate_accuracy(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy * 100\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, label in zip(X_train, y_train):\n",
    "                prediction = self._predict(inputs)\n",
    "\n",
    "                # Update weights\n",
    "                error = label - prediction\n",
    "                adjustment = error * self._activation_function_derivative(prediction)\n",
    "\n",
    "                self.weights[1:] += self.learning_rate * adjustment * inputs\n",
    "                self.weights[0] += self.learning_rate * adjustment\n",
    "\n",
    "            # Calculate training accuracy at each epoch\n",
    "            training_accuracy = self._calculate_accuracy(X_train, y_train)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}: Training Accuracy = {training_accuracy:.2f}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [np.round(self._predict(inputs)) for inputs in X_test]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: Training Accuracy = 59.55%\n",
      "Epoch 2/1000: Training Accuracy = 59.55%\n",
      "Epoch 3/1000: Training Accuracy = 59.55%\n",
      "Epoch 4/1000: Training Accuracy = 59.55%\n",
      "Epoch 5/1000: Training Accuracy = 63.20%\n",
      "Epoch 6/1000: Training Accuracy = 69.66%\n",
      "Epoch 7/1000: Training Accuracy = 75.56%\n",
      "Epoch 8/1000: Training Accuracy = 78.37%\n",
      "Epoch 9/1000: Training Accuracy = 79.07%\n",
      "Epoch 10/1000: Training Accuracy = 79.21%\n",
      "Epoch 11/1000: Training Accuracy = 78.93%\n",
      "Epoch 12/1000: Training Accuracy = 79.21%\n",
      "Epoch 13/1000: Training Accuracy = 78.37%\n",
      "Epoch 14/1000: Training Accuracy = 77.95%\n",
      "Epoch 15/1000: Training Accuracy = 78.23%\n",
      "Epoch 16/1000: Training Accuracy = 78.65%\n",
      "Epoch 17/1000: Training Accuracy = 78.51%\n",
      "Epoch 18/1000: Training Accuracy = 77.95%\n",
      "Epoch 19/1000: Training Accuracy = 78.23%\n",
      "Epoch 20/1000: Training Accuracy = 78.09%\n",
      "Epoch 21/1000: Training Accuracy = 77.95%\n",
      "Epoch 22/1000: Training Accuracy = 77.95%\n",
      "Epoch 23/1000: Training Accuracy = 77.95%\n",
      "Epoch 24/1000: Training Accuracy = 77.95%\n",
      "Epoch 25/1000: Training Accuracy = 77.95%\n",
      "Epoch 26/1000: Training Accuracy = 77.95%\n",
      "Epoch 27/1000: Training Accuracy = 77.95%\n",
      "Epoch 28/1000: Training Accuracy = 77.95%\n",
      "Epoch 29/1000: Training Accuracy = 77.95%\n",
      "Epoch 30/1000: Training Accuracy = 77.95%\n",
      "Epoch 31/1000: Training Accuracy = 77.95%\n",
      "Epoch 32/1000: Training Accuracy = 77.95%\n",
      "Epoch 33/1000: Training Accuracy = 77.95%\n",
      "Epoch 34/1000: Training Accuracy = 77.95%\n",
      "Epoch 35/1000: Training Accuracy = 77.95%\n",
      "Epoch 36/1000: Training Accuracy = 77.95%\n",
      "Epoch 37/1000: Training Accuracy = 77.95%\n",
      "Epoch 38/1000: Training Accuracy = 77.95%\n",
      "Epoch 39/1000: Training Accuracy = 77.95%\n",
      "Epoch 40/1000: Training Accuracy = 77.95%\n",
      "Epoch 41/1000: Training Accuracy = 77.95%\n",
      "Epoch 42/1000: Training Accuracy = 77.95%\n",
      "Epoch 43/1000: Training Accuracy = 77.95%\n",
      "Epoch 44/1000: Training Accuracy = 77.95%\n",
      "Epoch 45/1000: Training Accuracy = 77.95%\n",
      "Epoch 46/1000: Training Accuracy = 77.95%\n",
      "Epoch 47/1000: Training Accuracy = 77.95%\n",
      "Epoch 48/1000: Training Accuracy = 77.95%\n",
      "Epoch 49/1000: Training Accuracy = 77.95%\n",
      "Epoch 50/1000: Training Accuracy = 77.95%\n",
      "Epoch 51/1000: Training Accuracy = 77.95%\n",
      "Epoch 52/1000: Training Accuracy = 77.95%\n",
      "Epoch 53/1000: Training Accuracy = 77.95%\n",
      "Epoch 54/1000: Training Accuracy = 77.95%\n",
      "Epoch 55/1000: Training Accuracy = 78.09%\n",
      "Epoch 56/1000: Training Accuracy = 78.23%\n",
      "Epoch 57/1000: Training Accuracy = 78.23%\n",
      "Epoch 58/1000: Training Accuracy = 78.23%\n",
      "Epoch 59/1000: Training Accuracy = 78.23%\n",
      "Epoch 60/1000: Training Accuracy = 78.23%\n",
      "Epoch 61/1000: Training Accuracy = 78.23%\n",
      "Epoch 62/1000: Training Accuracy = 78.23%\n",
      "Epoch 63/1000: Training Accuracy = 78.23%\n",
      "Epoch 64/1000: Training Accuracy = 78.23%\n",
      "Epoch 65/1000: Training Accuracy = 78.23%\n",
      "Epoch 66/1000: Training Accuracy = 78.23%\n",
      "Epoch 67/1000: Training Accuracy = 78.23%\n",
      "Epoch 68/1000: Training Accuracy = 78.23%\n",
      "Epoch 69/1000: Training Accuracy = 78.23%\n",
      "Epoch 70/1000: Training Accuracy = 78.23%\n",
      "Epoch 71/1000: Training Accuracy = 78.23%\n",
      "Epoch 72/1000: Training Accuracy = 78.23%\n",
      "Epoch 73/1000: Training Accuracy = 78.23%\n",
      "Epoch 74/1000: Training Accuracy = 78.09%\n",
      "Epoch 75/1000: Training Accuracy = 78.09%\n",
      "Epoch 76/1000: Training Accuracy = 78.09%\n",
      "Epoch 77/1000: Training Accuracy = 78.09%\n",
      "Epoch 78/1000: Training Accuracy = 78.09%\n",
      "Epoch 79/1000: Training Accuracy = 78.09%\n",
      "Epoch 80/1000: Training Accuracy = 77.95%\n",
      "Epoch 81/1000: Training Accuracy = 77.95%\n",
      "Epoch 82/1000: Training Accuracy = 77.95%\n",
      "Epoch 83/1000: Training Accuracy = 77.95%\n",
      "Epoch 84/1000: Training Accuracy = 77.95%\n",
      "Epoch 85/1000: Training Accuracy = 78.09%\n",
      "Epoch 86/1000: Training Accuracy = 78.09%\n",
      "Epoch 87/1000: Training Accuracy = 78.09%\n",
      "Epoch 88/1000: Training Accuracy = 78.09%\n",
      "Epoch 89/1000: Training Accuracy = 77.95%\n",
      "Epoch 90/1000: Training Accuracy = 77.95%\n",
      "Epoch 91/1000: Training Accuracy = 77.95%\n",
      "Epoch 92/1000: Training Accuracy = 77.95%\n",
      "Epoch 93/1000: Training Accuracy = 77.95%\n",
      "Epoch 94/1000: Training Accuracy = 77.95%\n",
      "Epoch 95/1000: Training Accuracy = 77.95%\n",
      "Epoch 96/1000: Training Accuracy = 77.95%\n",
      "Epoch 97/1000: Training Accuracy = 77.95%\n",
      "Epoch 98/1000: Training Accuracy = 77.81%\n",
      "Epoch 99/1000: Training Accuracy = 77.67%\n",
      "Epoch 100/1000: Training Accuracy = 77.67%\n",
      "Epoch 101/1000: Training Accuracy = 77.67%\n",
      "Epoch 102/1000: Training Accuracy = 77.67%\n",
      "Epoch 103/1000: Training Accuracy = 77.67%\n",
      "Epoch 104/1000: Training Accuracy = 77.67%\n",
      "Epoch 105/1000: Training Accuracy = 77.67%\n",
      "Epoch 106/1000: Training Accuracy = 77.67%\n",
      "Epoch 107/1000: Training Accuracy = 77.67%\n",
      "Epoch 108/1000: Training Accuracy = 77.81%\n",
      "Epoch 109/1000: Training Accuracy = 77.81%\n",
      "Epoch 110/1000: Training Accuracy = 77.81%\n",
      "Epoch 111/1000: Training Accuracy = 77.95%\n",
      "Epoch 112/1000: Training Accuracy = 77.95%\n",
      "Epoch 113/1000: Training Accuracy = 78.09%\n",
      "Epoch 114/1000: Training Accuracy = 78.09%\n",
      "Epoch 115/1000: Training Accuracy = 78.23%\n",
      "Epoch 116/1000: Training Accuracy = 78.23%\n",
      "Epoch 117/1000: Training Accuracy = 78.23%\n",
      "Epoch 118/1000: Training Accuracy = 78.23%\n",
      "Epoch 119/1000: Training Accuracy = 78.37%\n",
      "Epoch 120/1000: Training Accuracy = 78.37%\n",
      "Epoch 121/1000: Training Accuracy = 78.37%\n",
      "Epoch 122/1000: Training Accuracy = 78.37%\n",
      "Epoch 123/1000: Training Accuracy = 78.37%\n",
      "Epoch 124/1000: Training Accuracy = 78.37%\n",
      "Epoch 125/1000: Training Accuracy = 78.37%\n",
      "Epoch 126/1000: Training Accuracy = 78.51%\n",
      "Epoch 127/1000: Training Accuracy = 78.65%\n",
      "Epoch 128/1000: Training Accuracy = 78.65%\n",
      "Epoch 129/1000: Training Accuracy = 78.65%\n",
      "Epoch 130/1000: Training Accuracy = 78.65%\n",
      "Epoch 131/1000: Training Accuracy = 78.65%\n",
      "Epoch 132/1000: Training Accuracy = 78.65%\n",
      "Epoch 133/1000: Training Accuracy = 78.65%\n",
      "Epoch 134/1000: Training Accuracy = 78.65%\n",
      "Epoch 135/1000: Training Accuracy = 78.65%\n",
      "Epoch 136/1000: Training Accuracy = 78.51%\n",
      "Epoch 137/1000: Training Accuracy = 78.51%\n",
      "Epoch 138/1000: Training Accuracy = 78.65%\n",
      "Epoch 139/1000: Training Accuracy = 78.65%\n",
      "Epoch 140/1000: Training Accuracy = 78.65%\n",
      "Epoch 141/1000: Training Accuracy = 78.65%\n",
      "Epoch 142/1000: Training Accuracy = 78.65%\n",
      "Epoch 143/1000: Training Accuracy = 78.79%\n",
      "Epoch 144/1000: Training Accuracy = 78.93%\n",
      "Epoch 145/1000: Training Accuracy = 78.93%\n",
      "Epoch 146/1000: Training Accuracy = 79.07%\n",
      "Epoch 147/1000: Training Accuracy = 79.07%\n",
      "Epoch 148/1000: Training Accuracy = 78.93%\n",
      "Epoch 149/1000: Training Accuracy = 78.93%\n",
      "Epoch 150/1000: Training Accuracy = 78.93%\n",
      "Epoch 151/1000: Training Accuracy = 79.07%\n",
      "Epoch 152/1000: Training Accuracy = 79.21%\n",
      "Epoch 153/1000: Training Accuracy = 79.21%\n",
      "Epoch 154/1000: Training Accuracy = 79.21%\n",
      "Epoch 155/1000: Training Accuracy = 79.21%\n",
      "Epoch 156/1000: Training Accuracy = 79.07%\n",
      "Epoch 157/1000: Training Accuracy = 79.07%\n",
      "Epoch 158/1000: Training Accuracy = 79.07%\n",
      "Epoch 159/1000: Training Accuracy = 79.07%\n",
      "Epoch 160/1000: Training Accuracy = 79.07%\n",
      "Epoch 161/1000: Training Accuracy = 79.07%\n",
      "Epoch 162/1000: Training Accuracy = 79.07%\n",
      "Epoch 163/1000: Training Accuracy = 79.07%\n",
      "Epoch 164/1000: Training Accuracy = 79.07%\n",
      "Epoch 165/1000: Training Accuracy = 79.07%\n",
      "Epoch 166/1000: Training Accuracy = 79.07%\n",
      "Epoch 167/1000: Training Accuracy = 79.07%\n",
      "Epoch 168/1000: Training Accuracy = 79.07%\n",
      "Epoch 169/1000: Training Accuracy = 79.07%\n",
      "Epoch 170/1000: Training Accuracy = 79.07%\n",
      "Epoch 171/1000: Training Accuracy = 79.07%\n",
      "Epoch 172/1000: Training Accuracy = 79.07%\n",
      "Epoch 173/1000: Training Accuracy = 79.21%\n",
      "Epoch 174/1000: Training Accuracy = 79.21%\n",
      "Epoch 175/1000: Training Accuracy = 79.21%\n",
      "Epoch 176/1000: Training Accuracy = 79.21%\n",
      "Epoch 177/1000: Training Accuracy = 79.21%\n",
      "Epoch 178/1000: Training Accuracy = 79.21%\n",
      "Epoch 179/1000: Training Accuracy = 79.21%\n",
      "Epoch 180/1000: Training Accuracy = 79.07%\n",
      "Epoch 181/1000: Training Accuracy = 79.07%\n",
      "Epoch 182/1000: Training Accuracy = 79.07%\n",
      "Epoch 183/1000: Training Accuracy = 79.07%\n",
      "Epoch 184/1000: Training Accuracy = 79.07%\n",
      "Epoch 185/1000: Training Accuracy = 79.07%\n",
      "Epoch 186/1000: Training Accuracy = 79.07%\n",
      "Epoch 187/1000: Training Accuracy = 79.07%\n",
      "Epoch 188/1000: Training Accuracy = 79.07%\n",
      "Epoch 189/1000: Training Accuracy = 79.21%\n",
      "Epoch 190/1000: Training Accuracy = 79.07%\n",
      "Epoch 191/1000: Training Accuracy = 79.07%\n",
      "Epoch 192/1000: Training Accuracy = 79.07%\n",
      "Epoch 193/1000: Training Accuracy = 79.07%\n",
      "Epoch 194/1000: Training Accuracy = 79.07%\n",
      "Epoch 195/1000: Training Accuracy = 79.07%\n",
      "Epoch 196/1000: Training Accuracy = 79.07%\n",
      "Epoch 197/1000: Training Accuracy = 78.93%\n",
      "Epoch 198/1000: Training Accuracy = 78.93%\n",
      "Epoch 199/1000: Training Accuracy = 78.93%\n",
      "Epoch 200/1000: Training Accuracy = 78.93%\n",
      "Epoch 201/1000: Training Accuracy = 78.93%\n",
      "Epoch 202/1000: Training Accuracy = 79.07%\n",
      "Epoch 203/1000: Training Accuracy = 79.07%\n",
      "Epoch 204/1000: Training Accuracy = 79.07%\n",
      "Epoch 205/1000: Training Accuracy = 79.07%\n",
      "Epoch 206/1000: Training Accuracy = 79.07%\n",
      "Epoch 207/1000: Training Accuracy = 79.07%\n",
      "Epoch 208/1000: Training Accuracy = 79.07%\n",
      "Epoch 209/1000: Training Accuracy = 79.07%\n",
      "Epoch 210/1000: Training Accuracy = 79.07%\n",
      "Epoch 211/1000: Training Accuracy = 79.07%\n",
      "Epoch 212/1000: Training Accuracy = 79.07%\n",
      "Epoch 213/1000: Training Accuracy = 79.07%\n",
      "Epoch 214/1000: Training Accuracy = 79.07%\n",
      "Epoch 215/1000: Training Accuracy = 79.07%\n",
      "Epoch 216/1000: Training Accuracy = 79.07%\n",
      "Epoch 217/1000: Training Accuracy = 79.07%\n",
      "Epoch 218/1000: Training Accuracy = 79.21%\n",
      "Epoch 219/1000: Training Accuracy = 79.21%\n",
      "Epoch 220/1000: Training Accuracy = 79.21%\n",
      "Epoch 221/1000: Training Accuracy = 79.21%\n",
      "Epoch 222/1000: Training Accuracy = 79.21%\n",
      "Epoch 223/1000: Training Accuracy = 79.21%\n",
      "Epoch 224/1000: Training Accuracy = 79.21%\n",
      "Epoch 225/1000: Training Accuracy = 79.35%\n",
      "Epoch 226/1000: Training Accuracy = 79.35%\n",
      "Epoch 227/1000: Training Accuracy = 79.35%\n",
      "Epoch 228/1000: Training Accuracy = 79.35%\n",
      "Epoch 229/1000: Training Accuracy = 79.35%\n",
      "Epoch 230/1000: Training Accuracy = 79.35%\n",
      "Epoch 231/1000: Training Accuracy = 79.35%\n",
      "Epoch 232/1000: Training Accuracy = 79.35%\n",
      "Epoch 233/1000: Training Accuracy = 79.35%\n",
      "Epoch 234/1000: Training Accuracy = 79.35%\n",
      "Epoch 235/1000: Training Accuracy = 79.35%\n",
      "Epoch 236/1000: Training Accuracy = 79.35%\n",
      "Epoch 237/1000: Training Accuracy = 79.35%\n",
      "Epoch 238/1000: Training Accuracy = 79.35%\n",
      "Epoch 239/1000: Training Accuracy = 79.35%\n",
      "Epoch 240/1000: Training Accuracy = 79.35%\n",
      "Epoch 241/1000: Training Accuracy = 79.35%\n",
      "Epoch 242/1000: Training Accuracy = 79.35%\n",
      "Epoch 243/1000: Training Accuracy = 79.21%\n",
      "Epoch 244/1000: Training Accuracy = 79.21%\n",
      "Epoch 245/1000: Training Accuracy = 79.21%\n",
      "Epoch 246/1000: Training Accuracy = 79.21%\n",
      "Epoch 247/1000: Training Accuracy = 79.21%\n",
      "Epoch 248/1000: Training Accuracy = 79.21%\n",
      "Epoch 249/1000: Training Accuracy = 79.21%\n",
      "Epoch 250/1000: Training Accuracy = 79.21%\n",
      "Epoch 251/1000: Training Accuracy = 79.21%\n",
      "Epoch 252/1000: Training Accuracy = 79.21%\n",
      "Epoch 253/1000: Training Accuracy = 79.21%\n",
      "Epoch 254/1000: Training Accuracy = 79.21%\n",
      "Epoch 255/1000: Training Accuracy = 79.21%\n",
      "Epoch 256/1000: Training Accuracy = 79.21%\n",
      "Epoch 257/1000: Training Accuracy = 79.21%\n",
      "Epoch 258/1000: Training Accuracy = 79.21%\n",
      "Epoch 259/1000: Training Accuracy = 79.21%\n",
      "Epoch 260/1000: Training Accuracy = 79.21%\n",
      "Epoch 261/1000: Training Accuracy = 79.21%\n",
      "Epoch 262/1000: Training Accuracy = 79.21%\n",
      "Epoch 263/1000: Training Accuracy = 79.21%\n",
      "Epoch 264/1000: Training Accuracy = 79.21%\n",
      "Epoch 265/1000: Training Accuracy = 79.21%\n",
      "Epoch 266/1000: Training Accuracy = 79.07%\n",
      "Epoch 267/1000: Training Accuracy = 79.07%\n",
      "Epoch 268/1000: Training Accuracy = 79.07%\n",
      "Epoch 269/1000: Training Accuracy = 79.07%\n",
      "Epoch 270/1000: Training Accuracy = 79.07%\n",
      "Epoch 271/1000: Training Accuracy = 79.07%\n",
      "Epoch 272/1000: Training Accuracy = 79.07%\n",
      "Epoch 273/1000: Training Accuracy = 79.07%\n",
      "Epoch 274/1000: Training Accuracy = 79.07%\n",
      "Epoch 275/1000: Training Accuracy = 79.07%\n",
      "Epoch 276/1000: Training Accuracy = 79.07%\n",
      "Epoch 277/1000: Training Accuracy = 79.07%\n",
      "Epoch 278/1000: Training Accuracy = 79.07%\n",
      "Epoch 279/1000: Training Accuracy = 79.07%\n",
      "Epoch 280/1000: Training Accuracy = 79.07%\n",
      "Epoch 281/1000: Training Accuracy = 79.07%\n",
      "Epoch 282/1000: Training Accuracy = 79.07%\n",
      "Epoch 283/1000: Training Accuracy = 79.07%\n",
      "Epoch 284/1000: Training Accuracy = 79.07%\n",
      "Epoch 285/1000: Training Accuracy = 79.07%\n",
      "Epoch 286/1000: Training Accuracy = 79.07%\n",
      "Epoch 287/1000: Training Accuracy = 79.07%\n",
      "Epoch 288/1000: Training Accuracy = 79.07%\n",
      "Epoch 289/1000: Training Accuracy = 79.07%\n",
      "Epoch 290/1000: Training Accuracy = 79.07%\n",
      "Epoch 291/1000: Training Accuracy = 79.07%\n",
      "Epoch 292/1000: Training Accuracy = 79.07%\n",
      "Epoch 293/1000: Training Accuracy = 79.07%\n",
      "Epoch 294/1000: Training Accuracy = 79.07%\n",
      "Epoch 295/1000: Training Accuracy = 79.21%\n",
      "Epoch 296/1000: Training Accuracy = 79.21%\n",
      "Epoch 297/1000: Training Accuracy = 79.21%\n",
      "Epoch 298/1000: Training Accuracy = 79.07%\n",
      "Epoch 299/1000: Training Accuracy = 79.07%\n",
      "Epoch 300/1000: Training Accuracy = 79.07%\n",
      "Epoch 301/1000: Training Accuracy = 79.07%\n",
      "Epoch 302/1000: Training Accuracy = 78.93%\n",
      "Epoch 303/1000: Training Accuracy = 78.93%\n",
      "Epoch 304/1000: Training Accuracy = 78.93%\n",
      "Epoch 305/1000: Training Accuracy = 78.93%\n",
      "Epoch 306/1000: Training Accuracy = 79.07%\n",
      "Epoch 307/1000: Training Accuracy = 79.07%\n",
      "Epoch 308/1000: Training Accuracy = 79.07%\n",
      "Epoch 309/1000: Training Accuracy = 79.07%\n",
      "Epoch 310/1000: Training Accuracy = 79.07%\n",
      "Epoch 311/1000: Training Accuracy = 79.07%\n",
      "Epoch 312/1000: Training Accuracy = 79.07%\n",
      "Epoch 313/1000: Training Accuracy = 79.07%\n",
      "Epoch 314/1000: Training Accuracy = 79.07%\n",
      "Epoch 315/1000: Training Accuracy = 79.07%\n",
      "Epoch 316/1000: Training Accuracy = 79.21%\n",
      "Epoch 317/1000: Training Accuracy = 79.21%\n",
      "Epoch 318/1000: Training Accuracy = 79.21%\n",
      "Epoch 319/1000: Training Accuracy = 79.21%\n",
      "Epoch 320/1000: Training Accuracy = 79.21%\n",
      "Epoch 321/1000: Training Accuracy = 79.21%\n",
      "Epoch 322/1000: Training Accuracy = 79.21%\n",
      "Epoch 323/1000: Training Accuracy = 79.21%\n",
      "Epoch 324/1000: Training Accuracy = 79.21%\n",
      "Epoch 325/1000: Training Accuracy = 79.35%\n",
      "Epoch 326/1000: Training Accuracy = 79.35%\n",
      "Epoch 327/1000: Training Accuracy = 79.35%\n",
      "Epoch 328/1000: Training Accuracy = 79.35%\n",
      "Epoch 329/1000: Training Accuracy = 79.35%\n",
      "Epoch 330/1000: Training Accuracy = 79.35%\n",
      "Epoch 331/1000: Training Accuracy = 79.49%\n",
      "Epoch 332/1000: Training Accuracy = 79.49%\n",
      "Epoch 333/1000: Training Accuracy = 79.49%\n",
      "Epoch 334/1000: Training Accuracy = 79.49%\n",
      "Epoch 335/1000: Training Accuracy = 79.49%\n",
      "Epoch 336/1000: Training Accuracy = 79.49%\n",
      "Epoch 337/1000: Training Accuracy = 79.49%\n",
      "Epoch 338/1000: Training Accuracy = 79.49%\n",
      "Epoch 339/1000: Training Accuracy = 79.49%\n",
      "Epoch 340/1000: Training Accuracy = 79.49%\n",
      "Epoch 341/1000: Training Accuracy = 79.49%\n",
      "Epoch 342/1000: Training Accuracy = 79.49%\n",
      "Epoch 343/1000: Training Accuracy = 79.49%\n",
      "Epoch 344/1000: Training Accuracy = 79.49%\n",
      "Epoch 345/1000: Training Accuracy = 79.49%\n",
      "Epoch 346/1000: Training Accuracy = 79.49%\n",
      "Epoch 347/1000: Training Accuracy = 79.49%\n",
      "Epoch 348/1000: Training Accuracy = 79.49%\n",
      "Epoch 349/1000: Training Accuracy = 79.49%\n",
      "Epoch 350/1000: Training Accuracy = 79.49%\n",
      "Epoch 351/1000: Training Accuracy = 79.49%\n",
      "Epoch 352/1000: Training Accuracy = 79.49%\n",
      "Epoch 353/1000: Training Accuracy = 79.49%\n",
      "Epoch 354/1000: Training Accuracy = 79.49%\n",
      "Epoch 355/1000: Training Accuracy = 79.49%\n",
      "Epoch 356/1000: Training Accuracy = 79.49%\n",
      "Epoch 357/1000: Training Accuracy = 79.49%\n",
      "Epoch 358/1000: Training Accuracy = 79.49%\n",
      "Epoch 359/1000: Training Accuracy = 79.63%\n",
      "Epoch 360/1000: Training Accuracy = 79.63%\n",
      "Epoch 361/1000: Training Accuracy = 79.63%\n",
      "Epoch 362/1000: Training Accuracy = 79.63%\n",
      "Epoch 363/1000: Training Accuracy = 79.49%\n",
      "Epoch 364/1000: Training Accuracy = 79.49%\n",
      "Epoch 365/1000: Training Accuracy = 79.49%\n",
      "Epoch 366/1000: Training Accuracy = 79.49%\n",
      "Epoch 367/1000: Training Accuracy = 79.49%\n",
      "Epoch 368/1000: Training Accuracy = 79.49%\n",
      "Epoch 369/1000: Training Accuracy = 79.49%\n",
      "Epoch 370/1000: Training Accuracy = 79.63%\n",
      "Epoch 371/1000: Training Accuracy = 79.63%\n",
      "Epoch 372/1000: Training Accuracy = 79.63%\n",
      "Epoch 373/1000: Training Accuracy = 79.63%\n",
      "Epoch 374/1000: Training Accuracy = 79.63%\n",
      "Epoch 375/1000: Training Accuracy = 79.63%\n",
      "Epoch 376/1000: Training Accuracy = 79.63%\n",
      "Epoch 377/1000: Training Accuracy = 79.78%\n",
      "Epoch 378/1000: Training Accuracy = 79.78%\n",
      "Epoch 379/1000: Training Accuracy = 79.78%\n",
      "Epoch 380/1000: Training Accuracy = 79.78%\n",
      "Epoch 381/1000: Training Accuracy = 79.78%\n",
      "Epoch 382/1000: Training Accuracy = 79.78%\n",
      "Epoch 383/1000: Training Accuracy = 79.78%\n",
      "Epoch 384/1000: Training Accuracy = 79.78%\n",
      "Epoch 385/1000: Training Accuracy = 79.78%\n",
      "Epoch 386/1000: Training Accuracy = 79.63%\n",
      "Epoch 387/1000: Training Accuracy = 79.63%\n",
      "Epoch 388/1000: Training Accuracy = 79.63%\n",
      "Epoch 389/1000: Training Accuracy = 79.63%\n",
      "Epoch 390/1000: Training Accuracy = 79.63%\n",
      "Epoch 391/1000: Training Accuracy = 79.63%\n",
      "Epoch 392/1000: Training Accuracy = 79.63%\n",
      "Epoch 393/1000: Training Accuracy = 79.63%\n",
      "Epoch 394/1000: Training Accuracy = 79.63%\n",
      "Epoch 395/1000: Training Accuracy = 79.63%\n",
      "Epoch 396/1000: Training Accuracy = 79.63%\n",
      "Epoch 397/1000: Training Accuracy = 79.63%\n",
      "Epoch 398/1000: Training Accuracy = 79.78%\n",
      "Epoch 399/1000: Training Accuracy = 79.78%\n",
      "Epoch 400/1000: Training Accuracy = 79.78%\n",
      "Epoch 401/1000: Training Accuracy = 79.78%\n",
      "Epoch 402/1000: Training Accuracy = 79.78%\n",
      "Epoch 403/1000: Training Accuracy = 79.92%\n",
      "Epoch 404/1000: Training Accuracy = 79.92%\n",
      "Epoch 405/1000: Training Accuracy = 79.92%\n",
      "Epoch 406/1000: Training Accuracy = 79.92%\n",
      "Epoch 407/1000: Training Accuracy = 79.92%\n",
      "Epoch 408/1000: Training Accuracy = 79.92%\n",
      "Epoch 409/1000: Training Accuracy = 80.06%\n",
      "Epoch 410/1000: Training Accuracy = 80.06%\n",
      "Epoch 411/1000: Training Accuracy = 80.06%\n",
      "Epoch 412/1000: Training Accuracy = 80.06%\n",
      "Epoch 413/1000: Training Accuracy = 80.06%\n",
      "Epoch 414/1000: Training Accuracy = 80.06%\n",
      "Epoch 415/1000: Training Accuracy = 80.06%\n",
      "Epoch 416/1000: Training Accuracy = 80.06%\n",
      "Epoch 417/1000: Training Accuracy = 79.92%\n",
      "Epoch 418/1000: Training Accuracy = 79.92%\n",
      "Epoch 419/1000: Training Accuracy = 79.92%\n",
      "Epoch 420/1000: Training Accuracy = 79.92%\n",
      "Epoch 421/1000: Training Accuracy = 79.92%\n",
      "Epoch 422/1000: Training Accuracy = 79.92%\n",
      "Epoch 423/1000: Training Accuracy = 79.92%\n",
      "Epoch 424/1000: Training Accuracy = 79.92%\n",
      "Epoch 425/1000: Training Accuracy = 79.92%\n",
      "Epoch 426/1000: Training Accuracy = 79.92%\n",
      "Epoch 427/1000: Training Accuracy = 79.92%\n",
      "Epoch 428/1000: Training Accuracy = 79.92%\n",
      "Epoch 429/1000: Training Accuracy = 79.78%\n",
      "Epoch 430/1000: Training Accuracy = 79.78%\n",
      "Epoch 431/1000: Training Accuracy = 79.78%\n",
      "Epoch 432/1000: Training Accuracy = 79.78%\n",
      "Epoch 433/1000: Training Accuracy = 79.78%\n",
      "Epoch 434/1000: Training Accuracy = 79.78%\n",
      "Epoch 435/1000: Training Accuracy = 79.78%\n",
      "Epoch 436/1000: Training Accuracy = 79.78%\n",
      "Epoch 437/1000: Training Accuracy = 79.78%\n",
      "Epoch 438/1000: Training Accuracy = 79.78%\n",
      "Epoch 439/1000: Training Accuracy = 79.78%\n",
      "Epoch 440/1000: Training Accuracy = 79.78%\n",
      "Epoch 441/1000: Training Accuracy = 79.78%\n",
      "Epoch 442/1000: Training Accuracy = 79.78%\n",
      "Epoch 443/1000: Training Accuracy = 79.78%\n",
      "Epoch 444/1000: Training Accuracy = 79.78%\n",
      "Epoch 445/1000: Training Accuracy = 79.78%\n",
      "Epoch 446/1000: Training Accuracy = 79.78%\n",
      "Epoch 447/1000: Training Accuracy = 79.78%\n",
      "Epoch 448/1000: Training Accuracy = 79.78%\n",
      "Epoch 449/1000: Training Accuracy = 79.78%\n",
      "Epoch 450/1000: Training Accuracy = 79.78%\n",
      "Epoch 451/1000: Training Accuracy = 79.78%\n",
      "Epoch 452/1000: Training Accuracy = 79.78%\n",
      "Epoch 453/1000: Training Accuracy = 79.78%\n",
      "Epoch 454/1000: Training Accuracy = 79.78%\n",
      "Epoch 455/1000: Training Accuracy = 79.78%\n",
      "Epoch 456/1000: Training Accuracy = 79.78%\n",
      "Epoch 457/1000: Training Accuracy = 79.78%\n",
      "Epoch 458/1000: Training Accuracy = 79.78%\n",
      "Epoch 459/1000: Training Accuracy = 79.78%\n",
      "Epoch 460/1000: Training Accuracy = 79.78%\n",
      "Epoch 461/1000: Training Accuracy = 79.78%\n",
      "Epoch 462/1000: Training Accuracy = 79.78%\n",
      "Epoch 463/1000: Training Accuracy = 79.78%\n",
      "Epoch 464/1000: Training Accuracy = 79.78%\n",
      "Epoch 465/1000: Training Accuracy = 79.78%\n",
      "Epoch 466/1000: Training Accuracy = 79.78%\n",
      "Epoch 467/1000: Training Accuracy = 79.78%\n",
      "Epoch 468/1000: Training Accuracy = 79.78%\n",
      "Epoch 469/1000: Training Accuracy = 79.78%\n",
      "Epoch 470/1000: Training Accuracy = 79.78%\n",
      "Epoch 471/1000: Training Accuracy = 79.78%\n",
      "Epoch 472/1000: Training Accuracy = 79.78%\n",
      "Epoch 473/1000: Training Accuracy = 79.78%\n",
      "Epoch 474/1000: Training Accuracy = 79.78%\n",
      "Epoch 475/1000: Training Accuracy = 79.78%\n",
      "Epoch 476/1000: Training Accuracy = 79.78%\n",
      "Epoch 477/1000: Training Accuracy = 79.78%\n",
      "Epoch 478/1000: Training Accuracy = 79.78%\n",
      "Epoch 479/1000: Training Accuracy = 79.78%\n",
      "Epoch 480/1000: Training Accuracy = 79.78%\n",
      "Epoch 481/1000: Training Accuracy = 79.78%\n",
      "Epoch 482/1000: Training Accuracy = 79.78%\n",
      "Epoch 483/1000: Training Accuracy = 79.78%\n",
      "Epoch 484/1000: Training Accuracy = 79.78%\n",
      "Epoch 485/1000: Training Accuracy = 79.78%\n",
      "Epoch 486/1000: Training Accuracy = 79.78%\n",
      "Epoch 487/1000: Training Accuracy = 79.78%\n",
      "Epoch 488/1000: Training Accuracy = 79.78%\n",
      "Epoch 489/1000: Training Accuracy = 79.78%\n",
      "Epoch 490/1000: Training Accuracy = 79.78%\n",
      "Epoch 491/1000: Training Accuracy = 79.78%\n",
      "Epoch 492/1000: Training Accuracy = 79.78%\n",
      "Epoch 493/1000: Training Accuracy = 79.78%\n",
      "Epoch 494/1000: Training Accuracy = 79.78%\n",
      "Epoch 495/1000: Training Accuracy = 79.78%\n",
      "Epoch 496/1000: Training Accuracy = 79.78%\n",
      "Epoch 497/1000: Training Accuracy = 79.78%\n",
      "Epoch 498/1000: Training Accuracy = 79.78%\n",
      "Epoch 499/1000: Training Accuracy = 79.78%\n",
      "Epoch 500/1000: Training Accuracy = 79.78%\n",
      "Epoch 501/1000: Training Accuracy = 79.78%\n",
      "Epoch 502/1000: Training Accuracy = 79.78%\n",
      "Epoch 503/1000: Training Accuracy = 79.78%\n",
      "Epoch 504/1000: Training Accuracy = 79.78%\n",
      "Epoch 505/1000: Training Accuracy = 79.78%\n",
      "Epoch 506/1000: Training Accuracy = 79.78%\n",
      "Epoch 507/1000: Training Accuracy = 79.78%\n",
      "Epoch 508/1000: Training Accuracy = 79.78%\n",
      "Epoch 509/1000: Training Accuracy = 79.78%\n",
      "Epoch 510/1000: Training Accuracy = 79.78%\n",
      "Epoch 511/1000: Training Accuracy = 79.78%\n",
      "Epoch 512/1000: Training Accuracy = 79.78%\n",
      "Epoch 513/1000: Training Accuracy = 79.78%\n",
      "Epoch 514/1000: Training Accuracy = 79.78%\n",
      "Epoch 515/1000: Training Accuracy = 79.78%\n",
      "Epoch 516/1000: Training Accuracy = 79.78%\n",
      "Epoch 517/1000: Training Accuracy = 79.78%\n",
      "Epoch 518/1000: Training Accuracy = 79.78%\n",
      "Epoch 519/1000: Training Accuracy = 79.78%\n",
      "Epoch 520/1000: Training Accuracy = 79.78%\n",
      "Epoch 521/1000: Training Accuracy = 79.78%\n",
      "Epoch 522/1000: Training Accuracy = 79.78%\n",
      "Epoch 523/1000: Training Accuracy = 79.78%\n",
      "Epoch 524/1000: Training Accuracy = 79.78%\n",
      "Epoch 525/1000: Training Accuracy = 79.78%\n",
      "Epoch 526/1000: Training Accuracy = 79.78%\n",
      "Epoch 527/1000: Training Accuracy = 79.78%\n",
      "Epoch 528/1000: Training Accuracy = 79.78%\n",
      "Epoch 529/1000: Training Accuracy = 79.78%\n",
      "Epoch 530/1000: Training Accuracy = 79.78%\n",
      "Epoch 531/1000: Training Accuracy = 79.78%\n",
      "Epoch 532/1000: Training Accuracy = 79.78%\n",
      "Epoch 533/1000: Training Accuracy = 79.78%\n",
      "Epoch 534/1000: Training Accuracy = 79.78%\n",
      "Epoch 535/1000: Training Accuracy = 79.78%\n",
      "Epoch 536/1000: Training Accuracy = 79.78%\n",
      "Epoch 537/1000: Training Accuracy = 79.78%\n",
      "Epoch 538/1000: Training Accuracy = 79.78%\n",
      "Epoch 539/1000: Training Accuracy = 79.78%\n",
      "Epoch 540/1000: Training Accuracy = 79.78%\n",
      "Epoch 541/1000: Training Accuracy = 79.78%\n",
      "Epoch 542/1000: Training Accuracy = 79.78%\n",
      "Epoch 543/1000: Training Accuracy = 79.78%\n",
      "Epoch 544/1000: Training Accuracy = 79.78%\n",
      "Epoch 545/1000: Training Accuracy = 79.78%\n",
      "Epoch 546/1000: Training Accuracy = 79.78%\n",
      "Epoch 547/1000: Training Accuracy = 79.78%\n",
      "Epoch 548/1000: Training Accuracy = 79.78%\n",
      "Epoch 549/1000: Training Accuracy = 79.78%\n",
      "Epoch 550/1000: Training Accuracy = 79.78%\n",
      "Epoch 551/1000: Training Accuracy = 79.78%\n",
      "Epoch 552/1000: Training Accuracy = 79.78%\n",
      "Epoch 553/1000: Training Accuracy = 79.78%\n",
      "Epoch 554/1000: Training Accuracy = 79.78%\n",
      "Epoch 555/1000: Training Accuracy = 79.78%\n",
      "Epoch 556/1000: Training Accuracy = 79.78%\n",
      "Epoch 557/1000: Training Accuracy = 79.78%\n",
      "Epoch 558/1000: Training Accuracy = 79.78%\n",
      "Epoch 559/1000: Training Accuracy = 79.78%\n",
      "Epoch 560/1000: Training Accuracy = 79.78%\n",
      "Epoch 561/1000: Training Accuracy = 79.78%\n",
      "Epoch 562/1000: Training Accuracy = 79.78%\n",
      "Epoch 563/1000: Training Accuracy = 79.78%\n",
      "Epoch 564/1000: Training Accuracy = 79.78%\n",
      "Epoch 565/1000: Training Accuracy = 79.78%\n",
      "Epoch 566/1000: Training Accuracy = 79.78%\n",
      "Epoch 567/1000: Training Accuracy = 79.78%\n",
      "Epoch 568/1000: Training Accuracy = 79.78%\n",
      "Epoch 569/1000: Training Accuracy = 79.78%\n",
      "Epoch 570/1000: Training Accuracy = 79.78%\n",
      "Epoch 571/1000: Training Accuracy = 79.78%\n",
      "Epoch 572/1000: Training Accuracy = 79.78%\n",
      "Epoch 573/1000: Training Accuracy = 79.78%\n",
      "Epoch 574/1000: Training Accuracy = 79.78%\n",
      "Epoch 575/1000: Training Accuracy = 79.78%\n",
      "Epoch 576/1000: Training Accuracy = 79.78%\n",
      "Epoch 577/1000: Training Accuracy = 79.78%\n",
      "Epoch 578/1000: Training Accuracy = 79.78%\n",
      "Epoch 579/1000: Training Accuracy = 79.78%\n",
      "Epoch 580/1000: Training Accuracy = 79.78%\n",
      "Epoch 581/1000: Training Accuracy = 79.78%\n",
      "Epoch 582/1000: Training Accuracy = 79.78%\n",
      "Epoch 583/1000: Training Accuracy = 79.78%\n",
      "Epoch 584/1000: Training Accuracy = 79.78%\n",
      "Epoch 585/1000: Training Accuracy = 79.78%\n",
      "Epoch 586/1000: Training Accuracy = 79.78%\n",
      "Epoch 587/1000: Training Accuracy = 79.78%\n",
      "Epoch 588/1000: Training Accuracy = 79.78%\n",
      "Epoch 589/1000: Training Accuracy = 79.78%\n",
      "Epoch 590/1000: Training Accuracy = 79.78%\n",
      "Epoch 591/1000: Training Accuracy = 79.78%\n",
      "Epoch 592/1000: Training Accuracy = 79.78%\n",
      "Epoch 593/1000: Training Accuracy = 79.78%\n",
      "Epoch 594/1000: Training Accuracy = 79.78%\n",
      "Epoch 595/1000: Training Accuracy = 79.78%\n",
      "Epoch 596/1000: Training Accuracy = 79.78%\n",
      "Epoch 597/1000: Training Accuracy = 79.78%\n",
      "Epoch 598/1000: Training Accuracy = 79.78%\n",
      "Epoch 599/1000: Training Accuracy = 79.78%\n",
      "Epoch 600/1000: Training Accuracy = 79.78%\n",
      "Epoch 601/1000: Training Accuracy = 79.78%\n",
      "Epoch 602/1000: Training Accuracy = 79.78%\n",
      "Epoch 603/1000: Training Accuracy = 79.78%\n",
      "Epoch 604/1000: Training Accuracy = 79.78%\n",
      "Epoch 605/1000: Training Accuracy = 79.78%\n",
      "Epoch 606/1000: Training Accuracy = 79.78%\n",
      "Epoch 607/1000: Training Accuracy = 79.78%\n",
      "Epoch 608/1000: Training Accuracy = 79.78%\n",
      "Epoch 609/1000: Training Accuracy = 79.78%\n",
      "Epoch 610/1000: Training Accuracy = 79.78%\n",
      "Epoch 611/1000: Training Accuracy = 79.78%\n",
      "Epoch 612/1000: Training Accuracy = 79.78%\n",
      "Epoch 613/1000: Training Accuracy = 79.78%\n",
      "Epoch 614/1000: Training Accuracy = 79.78%\n",
      "Epoch 615/1000: Training Accuracy = 79.78%\n",
      "Epoch 616/1000: Training Accuracy = 79.78%\n",
      "Epoch 617/1000: Training Accuracy = 79.78%\n",
      "Epoch 618/1000: Training Accuracy = 79.78%\n",
      "Epoch 619/1000: Training Accuracy = 79.78%\n",
      "Epoch 620/1000: Training Accuracy = 79.78%\n",
      "Epoch 621/1000: Training Accuracy = 79.78%\n",
      "Epoch 622/1000: Training Accuracy = 79.78%\n",
      "Epoch 623/1000: Training Accuracy = 79.78%\n",
      "Epoch 624/1000: Training Accuracy = 79.92%\n",
      "Epoch 625/1000: Training Accuracy = 79.92%\n",
      "Epoch 626/1000: Training Accuracy = 79.92%\n",
      "Epoch 627/1000: Training Accuracy = 79.92%\n",
      "Epoch 628/1000: Training Accuracy = 79.92%\n",
      "Epoch 629/1000: Training Accuracy = 79.92%\n",
      "Epoch 630/1000: Training Accuracy = 79.92%\n",
      "Epoch 631/1000: Training Accuracy = 79.92%\n",
      "Epoch 632/1000: Training Accuracy = 79.92%\n",
      "Epoch 633/1000: Training Accuracy = 79.92%\n",
      "Epoch 634/1000: Training Accuracy = 79.92%\n",
      "Epoch 635/1000: Training Accuracy = 79.92%\n",
      "Epoch 636/1000: Training Accuracy = 79.92%\n",
      "Epoch 637/1000: Training Accuracy = 79.92%\n",
      "Epoch 638/1000: Training Accuracy = 79.92%\n",
      "Epoch 639/1000: Training Accuracy = 79.92%\n",
      "Epoch 640/1000: Training Accuracy = 79.92%\n",
      "Epoch 641/1000: Training Accuracy = 79.92%\n",
      "Epoch 642/1000: Training Accuracy = 79.92%\n",
      "Epoch 643/1000: Training Accuracy = 79.92%\n",
      "Epoch 644/1000: Training Accuracy = 79.92%\n",
      "Epoch 645/1000: Training Accuracy = 79.92%\n",
      "Epoch 646/1000: Training Accuracy = 79.92%\n",
      "Epoch 647/1000: Training Accuracy = 79.92%\n",
      "Epoch 648/1000: Training Accuracy = 79.92%\n",
      "Epoch 649/1000: Training Accuracy = 79.92%\n",
      "Epoch 650/1000: Training Accuracy = 79.92%\n",
      "Epoch 651/1000: Training Accuracy = 79.92%\n",
      "Epoch 652/1000: Training Accuracy = 80.06%\n",
      "Epoch 653/1000: Training Accuracy = 80.06%\n",
      "Epoch 654/1000: Training Accuracy = 80.06%\n",
      "Epoch 655/1000: Training Accuracy = 80.06%\n",
      "Epoch 656/1000: Training Accuracy = 80.06%\n",
      "Epoch 657/1000: Training Accuracy = 80.06%\n",
      "Epoch 658/1000: Training Accuracy = 80.06%\n",
      "Epoch 659/1000: Training Accuracy = 80.06%\n",
      "Epoch 660/1000: Training Accuracy = 80.06%\n",
      "Epoch 661/1000: Training Accuracy = 80.06%\n",
      "Epoch 662/1000: Training Accuracy = 80.06%\n",
      "Epoch 663/1000: Training Accuracy = 80.06%\n",
      "Epoch 664/1000: Training Accuracy = 80.06%\n",
      "Epoch 665/1000: Training Accuracy = 80.06%\n",
      "Epoch 666/1000: Training Accuracy = 80.06%\n",
      "Epoch 667/1000: Training Accuracy = 80.06%\n",
      "Epoch 668/1000: Training Accuracy = 80.06%\n",
      "Epoch 669/1000: Training Accuracy = 80.06%\n",
      "Epoch 670/1000: Training Accuracy = 80.06%\n",
      "Epoch 671/1000: Training Accuracy = 80.06%\n",
      "Epoch 672/1000: Training Accuracy = 80.06%\n",
      "Epoch 673/1000: Training Accuracy = 80.06%\n",
      "Epoch 674/1000: Training Accuracy = 80.06%\n",
      "Epoch 675/1000: Training Accuracy = 80.06%\n",
      "Epoch 676/1000: Training Accuracy = 80.06%\n",
      "Epoch 677/1000: Training Accuracy = 80.06%\n",
      "Epoch 678/1000: Training Accuracy = 80.06%\n",
      "Epoch 679/1000: Training Accuracy = 80.06%\n",
      "Epoch 680/1000: Training Accuracy = 80.06%\n",
      "Epoch 681/1000: Training Accuracy = 80.06%\n",
      "Epoch 682/1000: Training Accuracy = 80.06%\n",
      "Epoch 683/1000: Training Accuracy = 80.06%\n",
      "Epoch 684/1000: Training Accuracy = 80.06%\n",
      "Epoch 685/1000: Training Accuracy = 80.06%\n",
      "Epoch 686/1000: Training Accuracy = 80.06%\n",
      "Epoch 687/1000: Training Accuracy = 80.06%\n",
      "Epoch 688/1000: Training Accuracy = 80.06%\n",
      "Epoch 689/1000: Training Accuracy = 80.06%\n",
      "Epoch 690/1000: Training Accuracy = 80.06%\n",
      "Epoch 691/1000: Training Accuracy = 80.20%\n",
      "Epoch 692/1000: Training Accuracy = 80.20%\n",
      "Epoch 693/1000: Training Accuracy = 80.20%\n",
      "Epoch 694/1000: Training Accuracy = 80.20%\n",
      "Epoch 695/1000: Training Accuracy = 80.20%\n",
      "Epoch 696/1000: Training Accuracy = 80.20%\n",
      "Epoch 697/1000: Training Accuracy = 80.20%\n",
      "Epoch 698/1000: Training Accuracy = 80.20%\n",
      "Epoch 699/1000: Training Accuracy = 80.20%\n",
      "Epoch 700/1000: Training Accuracy = 80.20%\n",
      "Epoch 701/1000: Training Accuracy = 80.20%\n",
      "Epoch 702/1000: Training Accuracy = 80.20%\n",
      "Epoch 703/1000: Training Accuracy = 80.20%\n",
      "Epoch 704/1000: Training Accuracy = 80.20%\n",
      "Epoch 705/1000: Training Accuracy = 80.20%\n",
      "Epoch 706/1000: Training Accuracy = 80.20%\n",
      "Epoch 707/1000: Training Accuracy = 80.20%\n",
      "Epoch 708/1000: Training Accuracy = 80.20%\n",
      "Epoch 709/1000: Training Accuracy = 80.20%\n",
      "Epoch 710/1000: Training Accuracy = 80.20%\n",
      "Epoch 711/1000: Training Accuracy = 80.20%\n",
      "Epoch 712/1000: Training Accuracy = 80.20%\n",
      "Epoch 713/1000: Training Accuracy = 80.20%\n",
      "Epoch 714/1000: Training Accuracy = 80.20%\n",
      "Epoch 715/1000: Training Accuracy = 80.20%\n",
      "Epoch 716/1000: Training Accuracy = 80.20%\n",
      "Epoch 717/1000: Training Accuracy = 80.20%\n",
      "Epoch 718/1000: Training Accuracy = 80.20%\n",
      "Epoch 719/1000: Training Accuracy = 80.20%\n",
      "Epoch 720/1000: Training Accuracy = 80.20%\n",
      "Epoch 721/1000: Training Accuracy = 80.20%\n",
      "Epoch 722/1000: Training Accuracy = 80.20%\n",
      "Epoch 723/1000: Training Accuracy = 80.20%\n",
      "Epoch 724/1000: Training Accuracy = 80.20%\n",
      "Epoch 725/1000: Training Accuracy = 80.20%\n",
      "Epoch 726/1000: Training Accuracy = 80.20%\n",
      "Epoch 727/1000: Training Accuracy = 80.20%\n",
      "Epoch 728/1000: Training Accuracy = 80.20%\n",
      "Epoch 729/1000: Training Accuracy = 80.20%\n",
      "Epoch 730/1000: Training Accuracy = 80.20%\n",
      "Epoch 731/1000: Training Accuracy = 80.06%\n",
      "Epoch 732/1000: Training Accuracy = 80.06%\n",
      "Epoch 733/1000: Training Accuracy = 80.06%\n",
      "Epoch 734/1000: Training Accuracy = 80.06%\n",
      "Epoch 735/1000: Training Accuracy = 80.06%\n",
      "Epoch 736/1000: Training Accuracy = 80.06%\n",
      "Epoch 737/1000: Training Accuracy = 80.06%\n",
      "Epoch 738/1000: Training Accuracy = 80.06%\n",
      "Epoch 739/1000: Training Accuracy = 80.06%\n",
      "Epoch 740/1000: Training Accuracy = 80.06%\n",
      "Epoch 741/1000: Training Accuracy = 80.06%\n",
      "Epoch 742/1000: Training Accuracy = 80.06%\n",
      "Epoch 743/1000: Training Accuracy = 80.06%\n",
      "Epoch 744/1000: Training Accuracy = 80.06%\n",
      "Epoch 745/1000: Training Accuracy = 80.06%\n",
      "Epoch 746/1000: Training Accuracy = 80.06%\n",
      "Epoch 747/1000: Training Accuracy = 80.06%\n",
      "Epoch 748/1000: Training Accuracy = 80.06%\n",
      "Epoch 749/1000: Training Accuracy = 80.06%\n",
      "Epoch 750/1000: Training Accuracy = 80.06%\n",
      "Epoch 751/1000: Training Accuracy = 80.06%\n",
      "Epoch 752/1000: Training Accuracy = 80.06%\n",
      "Epoch 753/1000: Training Accuracy = 80.06%\n",
      "Epoch 754/1000: Training Accuracy = 80.06%\n",
      "Epoch 755/1000: Training Accuracy = 80.06%\n",
      "Epoch 756/1000: Training Accuracy = 80.06%\n",
      "Epoch 757/1000: Training Accuracy = 80.06%\n",
      "Epoch 758/1000: Training Accuracy = 80.06%\n",
      "Epoch 759/1000: Training Accuracy = 80.06%\n",
      "Epoch 760/1000: Training Accuracy = 80.06%\n",
      "Epoch 761/1000: Training Accuracy = 80.06%\n",
      "Epoch 762/1000: Training Accuracy = 80.06%\n",
      "Epoch 763/1000: Training Accuracy = 80.06%\n",
      "Epoch 764/1000: Training Accuracy = 80.06%\n",
      "Epoch 765/1000: Training Accuracy = 80.06%\n",
      "Epoch 766/1000: Training Accuracy = 80.06%\n",
      "Epoch 767/1000: Training Accuracy = 80.06%\n",
      "Epoch 768/1000: Training Accuracy = 80.06%\n",
      "Epoch 769/1000: Training Accuracy = 80.06%\n",
      "Epoch 770/1000: Training Accuracy = 80.06%\n",
      "Epoch 771/1000: Training Accuracy = 80.06%\n",
      "Epoch 772/1000: Training Accuracy = 80.06%\n",
      "Epoch 773/1000: Training Accuracy = 80.06%\n",
      "Epoch 774/1000: Training Accuracy = 80.06%\n",
      "Epoch 775/1000: Training Accuracy = 80.06%\n",
      "Epoch 776/1000: Training Accuracy = 80.06%\n",
      "Epoch 777/1000: Training Accuracy = 80.06%\n",
      "Epoch 778/1000: Training Accuracy = 80.06%\n",
      "Epoch 779/1000: Training Accuracy = 80.06%\n",
      "Epoch 780/1000: Training Accuracy = 80.06%\n",
      "Epoch 781/1000: Training Accuracy = 80.06%\n",
      "Epoch 782/1000: Training Accuracy = 80.06%\n",
      "Epoch 783/1000: Training Accuracy = 80.06%\n",
      "Epoch 784/1000: Training Accuracy = 80.06%\n",
      "Epoch 785/1000: Training Accuracy = 80.06%\n",
      "Epoch 786/1000: Training Accuracy = 80.06%\n",
      "Epoch 787/1000: Training Accuracy = 80.06%\n",
      "Epoch 788/1000: Training Accuracy = 80.06%\n",
      "Epoch 789/1000: Training Accuracy = 80.06%\n",
      "Epoch 790/1000: Training Accuracy = 80.06%\n",
      "Epoch 791/1000: Training Accuracy = 80.06%\n",
      "Epoch 792/1000: Training Accuracy = 80.06%\n",
      "Epoch 793/1000: Training Accuracy = 80.06%\n",
      "Epoch 794/1000: Training Accuracy = 80.06%\n",
      "Epoch 795/1000: Training Accuracy = 80.06%\n",
      "Epoch 796/1000: Training Accuracy = 80.06%\n",
      "Epoch 797/1000: Training Accuracy = 80.06%\n",
      "Epoch 798/1000: Training Accuracy = 80.20%\n",
      "Epoch 799/1000: Training Accuracy = 80.20%\n",
      "Epoch 800/1000: Training Accuracy = 80.20%\n",
      "Epoch 801/1000: Training Accuracy = 80.20%\n",
      "Epoch 802/1000: Training Accuracy = 80.20%\n",
      "Epoch 803/1000: Training Accuracy = 80.20%\n",
      "Epoch 804/1000: Training Accuracy = 80.20%\n",
      "Epoch 805/1000: Training Accuracy = 80.20%\n",
      "Epoch 806/1000: Training Accuracy = 80.20%\n",
      "Epoch 807/1000: Training Accuracy = 80.20%\n",
      "Epoch 808/1000: Training Accuracy = 80.20%\n",
      "Epoch 809/1000: Training Accuracy = 80.20%\n",
      "Epoch 810/1000: Training Accuracy = 80.20%\n",
      "Epoch 811/1000: Training Accuracy = 80.20%\n",
      "Epoch 812/1000: Training Accuracy = 80.20%\n",
      "Epoch 813/1000: Training Accuracy = 80.20%\n",
      "Epoch 814/1000: Training Accuracy = 80.20%\n",
      "Epoch 815/1000: Training Accuracy = 80.20%\n",
      "Epoch 816/1000: Training Accuracy = 80.20%\n",
      "Epoch 817/1000: Training Accuracy = 80.20%\n",
      "Epoch 818/1000: Training Accuracy = 80.20%\n",
      "Epoch 819/1000: Training Accuracy = 80.20%\n",
      "Epoch 820/1000: Training Accuracy = 80.20%\n",
      "Epoch 821/1000: Training Accuracy = 80.20%\n",
      "Epoch 822/1000: Training Accuracy = 80.20%\n",
      "Epoch 823/1000: Training Accuracy = 80.20%\n",
      "Epoch 824/1000: Training Accuracy = 80.20%\n",
      "Epoch 825/1000: Training Accuracy = 80.20%\n",
      "Epoch 826/1000: Training Accuracy = 80.20%\n",
      "Epoch 827/1000: Training Accuracy = 80.20%\n",
      "Epoch 828/1000: Training Accuracy = 80.20%\n",
      "Epoch 829/1000: Training Accuracy = 80.20%\n",
      "Epoch 830/1000: Training Accuracy = 80.20%\n",
      "Epoch 831/1000: Training Accuracy = 80.20%\n",
      "Epoch 832/1000: Training Accuracy = 80.20%\n",
      "Epoch 833/1000: Training Accuracy = 80.20%\n",
      "Epoch 834/1000: Training Accuracy = 80.34%\n",
      "Epoch 835/1000: Training Accuracy = 80.34%\n",
      "Epoch 836/1000: Training Accuracy = 80.34%\n",
      "Epoch 837/1000: Training Accuracy = 80.34%\n",
      "Epoch 838/1000: Training Accuracy = 80.34%\n",
      "Epoch 839/1000: Training Accuracy = 80.34%\n",
      "Epoch 840/1000: Training Accuracy = 80.34%\n",
      "Epoch 841/1000: Training Accuracy = 80.34%\n",
      "Epoch 842/1000: Training Accuracy = 80.34%\n",
      "Epoch 843/1000: Training Accuracy = 80.34%\n",
      "Epoch 844/1000: Training Accuracy = 80.34%\n",
      "Epoch 845/1000: Training Accuracy = 80.34%\n",
      "Epoch 846/1000: Training Accuracy = 80.34%\n",
      "Epoch 847/1000: Training Accuracy = 80.34%\n",
      "Epoch 848/1000: Training Accuracy = 80.34%\n",
      "Epoch 849/1000: Training Accuracy = 80.34%\n",
      "Epoch 850/1000: Training Accuracy = 80.34%\n",
      "Epoch 851/1000: Training Accuracy = 80.34%\n",
      "Epoch 852/1000: Training Accuracy = 80.34%\n",
      "Epoch 853/1000: Training Accuracy = 80.34%\n",
      "Epoch 854/1000: Training Accuracy = 80.34%\n",
      "Epoch 855/1000: Training Accuracy = 80.34%\n",
      "Epoch 856/1000: Training Accuracy = 80.34%\n",
      "Epoch 857/1000: Training Accuracy = 80.34%\n",
      "Epoch 858/1000: Training Accuracy = 80.34%\n",
      "Epoch 859/1000: Training Accuracy = 80.34%\n",
      "Epoch 860/1000: Training Accuracy = 80.34%\n",
      "Epoch 861/1000: Training Accuracy = 80.34%\n",
      "Epoch 862/1000: Training Accuracy = 80.34%\n",
      "Epoch 863/1000: Training Accuracy = 80.34%\n",
      "Epoch 864/1000: Training Accuracy = 80.34%\n",
      "Epoch 865/1000: Training Accuracy = 80.34%\n",
      "Epoch 866/1000: Training Accuracy = 80.34%\n",
      "Epoch 867/1000: Training Accuracy = 80.34%\n",
      "Epoch 868/1000: Training Accuracy = 80.34%\n",
      "Epoch 869/1000: Training Accuracy = 80.34%\n",
      "Epoch 870/1000: Training Accuracy = 80.34%\n",
      "Epoch 871/1000: Training Accuracy = 80.34%\n",
      "Epoch 872/1000: Training Accuracy = 80.34%\n",
      "Epoch 873/1000: Training Accuracy = 80.34%\n",
      "Epoch 874/1000: Training Accuracy = 80.34%\n",
      "Epoch 875/1000: Training Accuracy = 80.34%\n",
      "Epoch 876/1000: Training Accuracy = 80.34%\n",
      "Epoch 877/1000: Training Accuracy = 80.34%\n",
      "Epoch 878/1000: Training Accuracy = 80.34%\n",
      "Epoch 879/1000: Training Accuracy = 80.34%\n",
      "Epoch 880/1000: Training Accuracy = 80.34%\n",
      "Epoch 881/1000: Training Accuracy = 80.34%\n",
      "Epoch 882/1000: Training Accuracy = 80.34%\n",
      "Epoch 883/1000: Training Accuracy = 80.34%\n",
      "Epoch 884/1000: Training Accuracy = 80.34%\n",
      "Epoch 885/1000: Training Accuracy = 80.34%\n",
      "Epoch 886/1000: Training Accuracy = 80.34%\n",
      "Epoch 887/1000: Training Accuracy = 80.34%\n",
      "Epoch 888/1000: Training Accuracy = 80.34%\n",
      "Epoch 889/1000: Training Accuracy = 80.34%\n",
      "Epoch 890/1000: Training Accuracy = 80.34%\n",
      "Epoch 891/1000: Training Accuracy = 80.34%\n",
      "Epoch 892/1000: Training Accuracy = 80.34%\n",
      "Epoch 893/1000: Training Accuracy = 80.34%\n",
      "Epoch 894/1000: Training Accuracy = 80.34%\n",
      "Epoch 895/1000: Training Accuracy = 80.34%\n",
      "Epoch 896/1000: Training Accuracy = 80.34%\n",
      "Epoch 897/1000: Training Accuracy = 80.34%\n",
      "Epoch 898/1000: Training Accuracy = 80.34%\n",
      "Epoch 899/1000: Training Accuracy = 80.34%\n",
      "Epoch 900/1000: Training Accuracy = 80.34%\n",
      "Epoch 901/1000: Training Accuracy = 80.34%\n",
      "Epoch 902/1000: Training Accuracy = 80.34%\n",
      "Epoch 903/1000: Training Accuracy = 80.34%\n",
      "Epoch 904/1000: Training Accuracy = 80.34%\n",
      "Epoch 905/1000: Training Accuracy = 80.34%\n",
      "Epoch 906/1000: Training Accuracy = 80.34%\n",
      "Epoch 907/1000: Training Accuracy = 80.34%\n",
      "Epoch 908/1000: Training Accuracy = 80.34%\n",
      "Epoch 909/1000: Training Accuracy = 80.34%\n",
      "Epoch 910/1000: Training Accuracy = 80.34%\n",
      "Epoch 911/1000: Training Accuracy = 80.34%\n",
      "Epoch 912/1000: Training Accuracy = 80.34%\n",
      "Epoch 913/1000: Training Accuracy = 80.34%\n",
      "Epoch 914/1000: Training Accuracy = 80.34%\n",
      "Epoch 915/1000: Training Accuracy = 80.34%\n",
      "Epoch 916/1000: Training Accuracy = 80.34%\n",
      "Epoch 917/1000: Training Accuracy = 80.34%\n",
      "Epoch 918/1000: Training Accuracy = 80.34%\n",
      "Epoch 919/1000: Training Accuracy = 80.34%\n",
      "Epoch 920/1000: Training Accuracy = 80.34%\n",
      "Epoch 921/1000: Training Accuracy = 80.34%\n",
      "Epoch 922/1000: Training Accuracy = 80.34%\n",
      "Epoch 923/1000: Training Accuracy = 80.34%\n",
      "Epoch 924/1000: Training Accuracy = 80.34%\n",
      "Epoch 925/1000: Training Accuracy = 80.34%\n",
      "Epoch 926/1000: Training Accuracy = 80.34%\n",
      "Epoch 927/1000: Training Accuracy = 80.34%\n",
      "Epoch 928/1000: Training Accuracy = 80.34%\n",
      "Epoch 929/1000: Training Accuracy = 80.34%\n",
      "Epoch 930/1000: Training Accuracy = 80.34%\n",
      "Epoch 931/1000: Training Accuracy = 80.34%\n",
      "Epoch 932/1000: Training Accuracy = 80.34%\n",
      "Epoch 933/1000: Training Accuracy = 80.34%\n",
      "Epoch 934/1000: Training Accuracy = 80.34%\n",
      "Epoch 935/1000: Training Accuracy = 80.34%\n",
      "Epoch 936/1000: Training Accuracy = 80.34%\n",
      "Epoch 937/1000: Training Accuracy = 80.34%\n",
      "Epoch 938/1000: Training Accuracy = 80.34%\n",
      "Epoch 939/1000: Training Accuracy = 80.34%\n",
      "Epoch 940/1000: Training Accuracy = 80.34%\n",
      "Epoch 941/1000: Training Accuracy = 80.34%\n",
      "Epoch 942/1000: Training Accuracy = 80.34%\n",
      "Epoch 943/1000: Training Accuracy = 80.34%\n",
      "Epoch 944/1000: Training Accuracy = 80.34%\n",
      "Epoch 945/1000: Training Accuracy = 80.34%\n",
      "Epoch 946/1000: Training Accuracy = 80.34%\n",
      "Epoch 947/1000: Training Accuracy = 80.34%\n",
      "Epoch 948/1000: Training Accuracy = 80.34%\n",
      "Epoch 949/1000: Training Accuracy = 80.34%\n",
      "Epoch 950/1000: Training Accuracy = 80.34%\n",
      "Epoch 951/1000: Training Accuracy = 80.34%\n",
      "Epoch 952/1000: Training Accuracy = 80.34%\n",
      "Epoch 953/1000: Training Accuracy = 80.34%\n",
      "Epoch 954/1000: Training Accuracy = 80.34%\n",
      "Epoch 955/1000: Training Accuracy = 80.34%\n",
      "Epoch 956/1000: Training Accuracy = 80.34%\n",
      "Epoch 957/1000: Training Accuracy = 80.34%\n",
      "Epoch 958/1000: Training Accuracy = 80.34%\n",
      "Epoch 959/1000: Training Accuracy = 80.34%\n",
      "Epoch 960/1000: Training Accuracy = 80.34%\n",
      "Epoch 961/1000: Training Accuracy = 80.34%\n",
      "Epoch 962/1000: Training Accuracy = 80.34%\n",
      "Epoch 963/1000: Training Accuracy = 80.34%\n",
      "Epoch 964/1000: Training Accuracy = 80.34%\n",
      "Epoch 965/1000: Training Accuracy = 80.34%\n",
      "Epoch 966/1000: Training Accuracy = 80.34%\n",
      "Epoch 967/1000: Training Accuracy = 80.34%\n",
      "Epoch 968/1000: Training Accuracy = 80.34%\n",
      "Epoch 969/1000: Training Accuracy = 80.34%\n",
      "Epoch 970/1000: Training Accuracy = 80.34%\n",
      "Epoch 971/1000: Training Accuracy = 80.34%\n",
      "Epoch 972/1000: Training Accuracy = 80.34%\n",
      "Epoch 973/1000: Training Accuracy = 80.34%\n",
      "Epoch 974/1000: Training Accuracy = 80.34%\n",
      "Epoch 975/1000: Training Accuracy = 80.34%\n",
      "Epoch 976/1000: Training Accuracy = 80.34%\n",
      "Epoch 977/1000: Training Accuracy = 80.34%\n",
      "Epoch 978/1000: Training Accuracy = 80.34%\n",
      "Epoch 979/1000: Training Accuracy = 80.34%\n",
      "Epoch 980/1000: Training Accuracy = 80.34%\n",
      "Epoch 981/1000: Training Accuracy = 80.34%\n",
      "Epoch 982/1000: Training Accuracy = 80.34%\n",
      "Epoch 983/1000: Training Accuracy = 80.34%\n",
      "Epoch 984/1000: Training Accuracy = 80.34%\n",
      "Epoch 985/1000: Training Accuracy = 80.34%\n",
      "Epoch 986/1000: Training Accuracy = 80.34%\n",
      "Epoch 987/1000: Training Accuracy = 80.34%\n",
      "Epoch 988/1000: Training Accuracy = 80.34%\n",
      "Epoch 989/1000: Training Accuracy = 80.34%\n",
      "Epoch 990/1000: Training Accuracy = 80.34%\n",
      "Epoch 991/1000: Training Accuracy = 80.34%\n",
      "Epoch 992/1000: Training Accuracy = 80.34%\n",
      "Epoch 993/1000: Training Accuracy = 80.34%\n",
      "Epoch 994/1000: Training Accuracy = 80.34%\n",
      "Epoch 995/1000: Training Accuracy = 80.34%\n",
      "Epoch 996/1000: Training Accuracy = 80.34%\n",
      "Epoch 997/1000: Training Accuracy = 80.34%\n",
      "Epoch 998/1000: Training Accuracy = 80.34%\n",
      "Epoch 999/1000: Training Accuracy = 80.34%\n",
      "Epoch 1000/1000: Training Accuracy = 80.34%\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train_normalize.shape[1]\n",
    "p = SingleLayerPerceptronSigmoid(input_size, learning_rate=lr, epochs=epochs)\n",
    "p.train(x_train_normalize, y_train_normalize)\n",
    "predict = p.predict(x_test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAG5CAYAAADrgswuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOn0lEQVR4nO3de1zO9/8/8Md1UVcpndBpVM7lmLMwQiSnKKNpkxi25djG1jbnTZg5jjU25zIz08THaU455JSFkYSwTQekWlE6vH5/+Pb+uQ5ZV666wuO+2/u23q/36/16P6+rSz17Hd5vmRBCgIiIiOgZcn0HQERERJUPEwQiIiJSwwSBiIiI1DBBICIiIjVMEIiIiEgNEwQiIiJSwwSBiIiI1DBBICIiIjVMEIiIiEgNEwTSu8TERPTu3Rvm5uaQyWSIjIzUafu3bt2CTCbD+vXrddruy8zd3R3u7u76DuOFjRw5Ek5OTmU691V5D4jKCxMEAgDcuHED48aNQ7169WBkZAQzMzN07twZy5Ytw+PHj8v12gEBAbh06RK++uorbNq0CW3bti3X61WkkSNHQiaTwczMTOP7mJiYCJlMBplMhkWLFmnd/t27dzFr1izExcXpINqyK34N7733nsbjn3/+uVTn/v37FRzdi5k3bx46duyIWrVqwcjICA0bNsTkyZNx7949fYdGVK6q6jsA0r/du3fjrbfegkKhwIgRI9CsWTM8efIEx48fx9SpU3H58mWsXr26XK79+PFjxMTE4PPPP8f48ePL5RqOjo54/PgxDAwMyqX9/1K1alU8evQIUVFRGDp0qNKx8PBwGBkZITc3t0xt3717F7Nnz4aTkxNcXV1Lfd7+/fvLdL3nMTIywvbt27Fq1SoYGhoqHduyZcsLvU59io2NhaurK/z8/FC9enXEx8djzZo12L17N+Li4mBiYqLvEInKBROE11xSUhL8/Pzg6OiIQ4cOwc7OTjoWFBSE69evY/fu3eV2/eK/wiwsLMrtGjKZDEZGRuXW/n9RKBTo3LkztmzZopYgREREoF+/fti+fXuFxPLo0SNUq1ZN7Re4LvTp0wc7d+7Enj174O3tLZWfPHkSSUlJ8PX1rbDXqUuaYnZzc8OQIUMQFRUFPz8/PURFVP44xPCaW7hwIbKzs/Hjjz8qJQfFGjRogEmTJkn7BQUFmDt3LurXrw+FQgEnJyd89tlnyMvLUzrPyckJ/fv3x/Hjx9G+fXsYGRmhXr162Lhxo1Rn1qxZcHR0BABMnToVMplMGk8uaWx51qxZkMlkSmUHDhxAly5dYGFhAVNTUzRu3BifffaZdLykOQiHDh3Cm2++CRMTE1hYWMDb2xvx8fEar3f9+nWMHDkSFhYWMDc3R2BgIB49elTyG6ti+PDh2LNnDzIyMqSys2fPIjExEcOHD1ern56ejo8//hjNmzeHqakpzMzM4OXlhQsXLkh1jhw5gnbt2gEAAgMDpS784tfp7u6OZs2aITY2Fl27dkW1atWk90V1/D0gIABGRkZqr9/T0xOWlpa4e/fuf77GN954A127dkVERIRSeXh4OJo3b45mzZppPG/btm1o06YNjI2NUbNmTbzzzjv4559/1OpFRkaiWbNmMDIyQrNmzbBjxw6N7RUVFWHp0qVo2rQpjIyMYGNjg3HjxuHhw4f/+RpKq/iz+ez3k+hVwwThNRcVFYV69eqhU6dOpar/3nvvYcaMGWjdujWWLFmCbt26ITQ0VONfUdevX8eQIUPQq1cvfPPNN7C0tMTIkSNx+fJlAICPjw+WLFkCAHj77bexadMmLF26VKv4L1++jP79+yMvLw9z5szBN998g4EDB+LEiRPPPe/333+Hp6cn0tLSMGvWLAQHB+PkyZPo3Lkzbt26pVZ/6NCh+PfffxEaGoqhQ4di/fr1mD17dqnj9PHxgUwmw6+//iqVRUREwNnZGa1bt1arf/PmTURGRqJ///5YvHgxpk6dikuXLqFbt27SL2sXFxfMmTMHADB27Fhs2rQJmzZtQteuXaV2Hjx4AC8vL7i6umLp0qXo3r27xviWLVuGWrVqISAgAIWFhQCA77//Hvv378eKFStgb29fqtc5fPhwREVFITs7G8DThHLbtm0akyAAWL9+PYYOHYoqVaogNDQUY8aMwa+//oouXboo/fLdv38/fH19IZPJEBoaikGDBiEwMBDnzp1Ta3PcuHGYOnWqNIcmMDAQ4eHh8PT0RH5+fqlehyohBO7fv4+UlBQcO3YMEydORJUqVTjJkV5tgl5bmZmZAoDw9vYuVf24uDgBQLz33ntK5R9//LEAIA4dOiSVOTo6CgAiOjpaKktLSxMKhUJ89NFHUllSUpIAIL7++mulNgMCAoSjo6NaDDNnzhTPfmyXLFkiAIh79+6VGHfxNdatWyeVubq6Cmtra/HgwQOp7MKFC0Iul4sRI0aoXW/UqFFKbQ4ePFjUqFGjxGs++zpMTEyEEEIMGTJE9OzZUwghRGFhobC1tRWzZ8/W+B7k5uaKwsJCtdehUCjEnDlzpLKzZ8+qvbZi3bp1EwBEWFiYxmPdunVTKtu3b58AIL788ktx8+ZNYWpqKgYNGvSfr1EIIQCIoKAgkZ6eLgwNDcWmTZuEEELs3r1byGQycevWLem9LP5ePXnyRFhbW4tmzZqJx48fS23t2rVLABAzZsyQylxdXYWdnZ3IyMiQyvbv3y8AKH1Ojh07JgCI8PBwpfj27t2rVq7pPShJcnKyACBttWvXFlu3bi3VuUQvK/YgvMaysrIAANWrVy9V/f/9738AgODgYKXyjz76CADU5io0adIEb775prRfq1YtNG7cGDdv3ixzzKqK5y789ttvKCoqKtU5ycnJiIuLw8iRI2FlZSWVt2jRAr169ZJe57Pef/99pf0333wTDx48kN7D0hg+fDiOHDmClJQUHDp0CCkpKSX+Za1QKCCXP/3nWVhYiAcPHkjDJ+fPny/1NRUKBQIDA0tVt3fv3hg3bhzmzJkDHx8fGBkZ4fvvvy/1tQDA0tISffr0wZYtWwA87SXp1KmTNJT0rHPnziEtLQ0ffvih0hyRfv36wdnZWfo8FX+/AgICYG5uLtXr1asXmjRpotTmtm3bYG5ujl69euH+/fvS1qZNG5iamuLw4cNavZ5iVlZWOHDgAKKiojBnzhzUrFlT6iUhelUxQXiNmZmZAQD+/fffUtW/ffs25HI5GjRooFRua2sLCwsL3L59W6ncwcFBrQ1LS0udjgUPGzYMnTt3xnvvvQcbGxv4+fnh559/fm6yUBxn48aN1Y65uLjg/v37yMnJUSpXfS2WlpYAoNVr6du3L6pXr46tW7ciPDwc7dq1U3svixUVFWHJkiVo2LAhFAoFatasiVq1auHixYvIzMws9TXfeOMNrSYkLlq0CFZWVoiLi8Py5cthbW1d6nOLDR8+HAcOHMCdO3cQGRlZYhL0vO+Ds7OzdLz4/w0bNlSrp3puYmIiMjMzYW1tjVq1ailt2dnZSEtL0/r1AIChoSE8PDzQv39/TJ8+HStXrsTo0aOxa9euMrVH9DLgKobXmJmZGezt7fHnn39qdZ7qJMGSVKlSRWO5EKLM1ygeHy9mbGyM6OhoHD58GLt378bevXuxdetW9OjRA/v37y8xBm29yGspplAo4OPjgw0bNuDmzZuYNWtWiXXnzZuH6dOnY9SoUZg7dy6srKwgl8sxefLkUveUAE/fH2388ccf0i/RS5cu4e2339bqfAAYOHAgFAoFAgICkJeXp7ZyozwVFRXB2toa4eHhGo/XqlVLJ9fp1KkT7OzsEB4ejv79++ukTaLKhgnCa65///5YvXo1YmJi4Obm9ty6jo6OKCoqQmJiIlxcXKTy1NRUZGRkaOxGLitLS0uNM8RVeykAQC6Xo2fPnujZsycWL16MefPm4fPPP8fhw4fh4eGh8XUAQEJCgtqxq1evombNmuW2tn348OFYu3Yt5HL5c5fH/fLLL+jevTt+/PFHpfKMjAzUrFlT2i9tslYaOTk5CAwMRJMmTdCpUycsXLgQgwcPllZKlJaxsTEGDRqEzZs3w8vLSyneZz37fejRo4fSsYSEBOl48f8TExPV2lD9HtavXx+///47OnfurHVypK3c3FytenOIXjYcYnjNTZs2DSYmJnjvvfeQmpqqdvzGjRtYtmwZgKdd5ADUVhosXrwYwNOxY12pX78+MjMzcfHiRaksOTlZbWlbenq62rnFNwxSXXpZzM7ODq6urtiwYYNSEvLnn39i//790ussD927d8fcuXPx7bffwtbWtsR6VapUUeud2LZtm9ryv+JERhfL7T755BPcuXMHGzZswOLFi+Hk5CT1Amjr448/xsyZMzF9+vQS67Rt2xbW1tYICwtTusaePXsQHx8vfZ6e/X49+wv5wIEDuHLlilKbQ4cORWFhIebOnat2vYKCAq3fp5ycHI3LWbdv346HDx++Unf9JFLFHoTXXP369REREYFhw4bBxcVF6U6KJ0+exLZt2zBy5EgAQMuWLREQEIDVq1cjIyMD3bp1w5kzZ7BhwwYMGjSoxCV0ZeHn54dPPvkEgwcPxsSJE/Ho0SN89913aNSokdIkvTlz5iA6Ohr9+vWDo6Mj0tLSsGrVKtSuXRtdunQpsf2vv/4aXl5ecHNzw+jRo/H48WOsWLEC5ubmz+36f1FyuRxffPHFf9br378/5syZg8DAQHTq1AmXLl1CeHg46tWrp1Svfv36sLCwQFhYGKpXrw4TExN06NABdevW1SquQ4cOYdWqVZg5c6a07HLdunVwd3fH9OnTsXDhQq3aa9myJVq2bPncOgYGBliwYAECAwPRrVs3vP3220hNTcWyZcvg5OSEKVOmSHVDQ0PRr18/dOnSBaNGjUJ6ejpWrFiBpk2bKk0W7NatG8aNG4fQ0FDExcWhd+/eMDAwQGJiIrZt24Zly5ZhyJAhpX4diYmJ8PDwwLBhw+Ds7Ay5XI5z585h8+bNcHJyUrpHCNErR8+rKKiSuHbtmhgzZoxwcnIShoaGonr16qJz585ixYoVIjc3V6qXn58vZs+eLerWrSsMDAxEnTp1REhIiFIdIZ4uc+zXr5/adVSXlpW0zFGIp8vYmjVrJgwNDUXjxo3F5s2b1ZY5Hjx4UHh7ewt7e3thaGgo7O3txdtvvy2uXbumdg3VpYC///676Ny5szA2NhZmZmZiwIAB4sqVK0p1VJfmFVu3bp0AIJKSkkp8T4VQXuZYkpKWOX700UfCzs5OGBsbi86dO4uYmBiNS/N+++030aRJE1G1alWl19mtWzfRtGlTjdd8tp2srCzh6OgoWrduLfLz85XqTZkyRcjlchETE/Pc14D/W+b4PCW9l1u3bhWtWrUSCoVCWFlZCX9/f/H333+rnb99+3bh4uIiFAqFaNKkifj1119LXA67evVq0aZNG2FsbCyqV68umjdvLqZNmybu3r2r8T0oyb1798TYsWOFs7OzMDExEYaGhqJhw4Zi8uTJz11aS/QqkAmhxSwrIiIiei1wDgIRERGpYYJAREREapggEBERkRomCERERKSGCQIRERGpYYJAREREapggEBERkRomCERERKSGCQIRERGpYYJAREREapggEBERkRomCERERKSGCQIRERGpqarvAIq1cOym7xCIKp2DW7/SdwhElVKtjl3KtX1d/k66ePuoztqqSJUmQSAiIqosZDKZvkPQOw4xEBERkRomCERERKSGQwxEREQqZDL+/cwEgYiISIUcnIPAFImIiIjUMEEgIiIiNRxiICIiUsFljuxBICIiIg2YIBAREamQy+Q627QRHR2NAQMGwN7eHjKZDJGRkUrHs7OzMX78eNSuXRvGxsZo0qQJwsLClOrk5uYiKCgINWrUgKmpKXx9fZGamqr9e6D1GURERK84mUyms00bOTk5aNmyJVauXKnxeHBwMPbu3YvNmzcjPj4ekydPxvjx47Fz506pzpQpUxAVFYVt27bh6NGjuHv3Lnx8fLR+DzgHgYiIqJLw8vKCl5dXicdPnjyJgIAAuLu7AwDGjh2L77//HmfOnMHAgQORmZmJH3/8EREREejRowcAYN26dXBxccGpU6fQsWPHUsfCHgQiIqJylJeXh6ysLKUtLy+vTG116tQJO3fuxD///AMhBA4fPoxr166hd+/eAIDY2Fjk5+fDw8NDOsfZ2RkODg6IiYnR6lpMEIiIiFTIdPhfaGgozM3NlbbQ0NAyxbVixQo0adIEtWvXhqGhIfr06YOVK1eia9euAICUlBQYGhrCwsJC6TwbGxukpKRodS0OMRAREZWjkJAQBAcHK5UpFIoytbVixQqcOnUKO3fuhKOjI6KjoxEUFAR7e3ulXgNdYIJARESkQtvVB8+jUCjKnBA86/Hjx/jss8+wY8cO9OvXDwDQokULxMXFYdGiRfDw8ICtrS2ePHmCjIwMpV6E1NRU2NraanU9DjEQERG9BPLz85Gfnw+5XPlXd5UqVVBUVAQAaNOmDQwMDHDw4EHpeEJCAu7cuQM3NzetrsceBCIiIhX6upNidnY2rl+/Lu0nJSUhLi4OVlZWcHBwQLdu3TB16lQYGxvD0dERR48excaNG7F48WIAgLm5OUaPHo3g4GBYWVnBzMwMEyZMgJubm1YrGAAmCERERJXGuXPn0L17d2m/eO5CQEAA1q9fj59++gkhISHw9/dHeno6HB0d8dVXX+H999+XzlmyZAnkcjl8fX2Rl5cHT09PrFq1SutYZEII8eIv6cW1cOym7xCIKp2DW7/SdwhElVKtjl3Ktf0ujfvrrK3jCbt01lZF4hwEIiIiUsMEgYiIiNRwDgIREZEKGf9+ZoJARESkSl+rGCoTpkhERESkhj0IREREKuTsQWAPAhEREaljgkBERERqOMRARESkQgYOMTBBICIiUqHLpzm+rPgOEBERkRomCERERKSGQwxEREQqeKMkJghERERqeB8EDjEQERGRBkwQiIiISA2HGIiIiFTwPgjsQSAiIiIN2INARESkgjdKYoJARESkhsscOcRAREREGjBBICIiIjUcYiAiIlLBGyUxQSAiIlLDZY4cYiAiIiINmCAQERGRGg4xEBERqeAyR/YgEBERkQal6kFYvnx5qRucOHFimYMhIiKqDLiKoZQJwpIlS5T27927h0ePHsHCwgIAkJGRgWrVqsHa2poJAhER0SugVEMMSUlJ0vbVV1/B1dUV8fHxSE9PR3p6OuLj49G6dWvMnTu3vOMlIiJ6ZUVHR2PAgAGwt7eHTCZDZGSkWp34+HgMHDgQ5ubmMDExQbt27XDnzh3peG5uLoKCglCjRg2YmprC19cXqampWsei9RyE6dOnY8WKFWjcuLFU1rhxYyxZsgRffPGF1gEQERFVNjId/qeNnJwctGzZEitXrtR4/MaNG+jSpQucnZ1x5MgRXLx4EdOnT4eRkZFUZ8qUKYiKisK2bdtw9OhR3L17Fz4+Plq/B1qvYkhOTkZBQYFaeWFhYZkyFCIiospGX09z9PLygpeXV4nHP//8c/Tt2xcLFy6UyurXry99nZmZiR9//BERERHo0aMHAGDdunVwcXHBqVOn0LFjx1LHovU70LNnT4wbNw7nz5+XymJjY/HBBx/Aw8ND2+aIiIioFIqKirB79240atQInp6esLa2RocOHZSGIWJjY5Gfn6/0+9jZ2RkODg6IiYnR6npaJwhr166Fra0t2rZtC4VCAYVCgfbt28PGxgY//PCDts0RERFVOjKZTGdbXl4esrKylLa8vDytY0pLS0N2djbmz5+PPn36YP/+/Rg8eDB8fHxw9OhRAEBKSgoMDQ2lRQTFbGxskJKSotX1tB5iqFWrFv73v//h2rVruHr1KoCn2UmjRo20bYqIiOiVFxoaitmzZyuVzZw5E7NmzdKqnaKiIgCAt7c3pkyZAgBwdXXFyZMnERYWhm7duukk3mJlvpOik5MThBCoX78+qlblDRmJiOjVocv7IISEhCA4OFipTKFQaN1OzZo1UbVqVTRp0kSp3MXFBcePHwcA2Nra4smTJ8jIyFDqRUhNTYWtra1W19N6iOHRo0cYPXo0qlWrhqZNm0pLKyZMmID58+dr2xwREdErTaFQwMzMTGkrS4JgaGiIdu3aISEhQan82rVrcHR0BAC0adMGBgYGOHjwoHQ8ISEBd+7cgZubm1bX0zpBCAkJwYULF3DkyBGlZRUeHh7YunWrts0RERFVOvpa5pidnY24uDjExcUBeHofori4OOmP8alTp2Lr1q1Ys2YNrl+/jm+//RZRUVH48MMPAQDm5uYYPXo0goODcfjwYcTGxiIwMBBubm5arWAAyjDEEBkZia1bt6Jjx45KD7No2rQpbty4oW1zRERE9H/OnTuH7t27S/vFQxMBAQFYv349Bg8ejLCwMISGhmLixIlo3Lgxtm/fji5dukjnLFmyBHK5HL6+vsjLy4OnpydWrVqldSxaJwj37t2DtbW1WnlOTg6ffkVERPQC3N3dIYR4bp1Ro0Zh1KhRJR43MjLCypUrS7zZUmlpPcTQtm1b7N69W9ovTgp++OEHrcc3iIiIKiO5TKaz7WWldQ/CvHnz4OXlhStXrqCgoADLli3DlStXcPLkSWkdJhER0cuMPeJl6EHo0qUL4uLiUFBQgObNm2P//v2wtrZGTEwM2rRpUx4xEhERUQUr0w0M6tevjzVr1ug6FiIiokrhZR4a0BWtexA8PDywfv16ZGVllUc8REREVAlonSA0bdoUISEhsLW1xVtvvYXffvsN+fn55REbERER6YnWCcKyZcvwzz//IDIyEiYmJhgxYgRsbGwwduxYTlIkIqJXgr5ulFSZlOmB13K5HL1798b69euRmpqK77//HmfOnJGePU1ERPQy4zLHF3hYE/D0sZI//fQTNm/ejIsXL6J9+/a6iouIiIj0SOsehKysLKxbtw69evVCnTp18N1332HgwIFITEzEqVOnyiNGIiIiqmBa9yDY2NjA0tISw4YNQ2hoKNq2bVsecREREekNb5RUhgRh586d6NmzJ+TyMk1fICIiqvRe5rkDuqJ1gtCrV6/yiIOIiIgqkVIlCK1bt8bBgwdhaWmJVq1aPbfr5fz58zoLjoiIiPSjVAmCt7c3FAqF9DXHZoiI6FX2Mt+/QFdKlSDMnDlT+nrWrFnlFQsRERFVElrPNHzvvfdw5MiRcgiFiIiocuCNksqQINy7dw99+vRBnTp1MHXqVFy4cKE84iIiItIbmUyms+1lpXWC8NtvvyE5ORnTp0/H2bNn0bp1azRt2hTz5s3DrVu3yiFEIiIiqmhlupmBpaUlxo4diyNHjuD27dsYOXIkNm3ahAYNGug6PiIiItKDF3oWQ35+Ps6dO4fTp0/j1q1bsLGx0VVcREREevMyzx3QlTL1IBw+fBhjxoyBjY0NRo4cCTMzM+zatQt///23ruMjIiKqcJyDUIYehDfeeAPp6eno06cPVq9ejQEDBkj3SCAiIqJXg9YJwqxZs/DWW2/BwsKiHMIhIiKiykCrBCE/Px8ffPAB3NzcmCC8RNq0b4GR496GS/NGsLapiUljPsfh/cel48bVjDH507Ho0bsLzC3N8c9fyYhYtx3bwncCAOxr22Lvia0a2/7og5k48L8jFfEyiMpd3NUEROzZh4Rbt/AgIxPzJgaha5vW0vEuAaM1nvfhsLcwvG+figqTKgDvpKhlgmBgYAAHBwcUFhaWVzxUDoyrGSMh/jp2/Pw/LF39pdrxqdOD0L5TK4RM/gp3/06B25vt8PmXk3Ev9T6O/H4SKXfT0L3tYKVzhrw9ACPH+eH4kdMV9TKIyt3jvCdoUKc2+r3ZBZ+vWKl2/Ldli5X2T128hPlr16Nb2zYVFSJRhdF6iOHzzz/HZ599hk2bNsHKyqo8YiIdO37k9HN/kbu2aYqd2/fh3Kk4AMD2LVF4y38Amrm64MjvJ1FUVIQH99KVzunR503s230Yjx89Ls/QiSqUW8vmcGvZvMTjNSzMlfaP//EHWrs0xhvWtco7NKpgcnYgaL+K4dtvv0V0dDTs7e3RuHFjtG7dWmmjl09c7GW4e3SGtU1NAEA7t1ZwrFsHMdFnNdZ3adYILk0bYsfW3RUZJlGlkp6ZiZMXLqFf1zf1HQpRudC6B2HQoEHlEAbpU+jMZZgZ+jF+P7Md+fkFEEVFmP3pIsSeuaixvo9fP9xIvIULsZcrOFKiymPP8ZOoZqRAtzYcXqBXk9YJwrNPdiyrvLw85OXlKZUViSLIZWW6LQO9oOEjfdCiVRNMGBWCu/+koE2Hlvhs7mSkpd7H6ROxSnUVCkN4DeyJ1Ss26ilaosph97Hj6O3WEQpDA32HQuXgZb5/ga7o5TdyaGgozM3NlbZ7mXf0EcprT6EwxMSpY/D1lytx9OBJJF69iZ827MC+XYcwcuwwtfq9+rrD2NgIUdv36SFaosrhQsI13ElOQf9uXfUdCpUTPs2xDAmCXC5HlSpVStxKIyQkBJmZmUpbLXMHrYOnF1fVoCoMDA0gioRSeWFhEWRy9Y/H4GF9ceT3E3iYnllRIRJVOruij6GxkyMaOtTRdyj0iomOjsaAAQNgb28PmUyGyMjIEuu+//77kMlkWLp0qVJ5eno6/P39YWZmBgsLC4wePRrZ2dlax6L1EMOOHTuU9vPz8/HHH39gw4YNmD17dqnaUCgUandf5PBC+TGuZgwHpzek/Tfq2KFxkwbIzMhCyt00nI35A8GfvY/c3Dwk/5OCNh1cMcDXE4vmKi/zquP4Btp0aImgkZ9U9EsgqhCPcnPxT2qatJ987z4Sb99BdVMT2NaoAQDIefwYh8+cw/i31XvY6NWhryGGnJwctGzZEqNGjYKPj0+J9Xbs2IFTp07B3t5e7Zi/vz+Sk5Nx4MAB5OfnIzAwEGPHjkVERIRWsWidIHh7e6uVDRkyBE2bNsXWrVsxerTmG4mQ/jRt0Rhrty6T9qfNGA8A+G3bHkz/eD6mTZiDSdPGInTZFzC3MEPy3ylY8fUP+Hnzb0rtDB7aF6nJ93CyhNUNRC+7q0m3MHH+19L+ii1PbxDm1aUTPh/z9Gfb76fOQADw6NheHyHSK87LywteXl7PrfPPP/9gwoQJ2LdvH/r166d0LD4+Hnv37sXZs2fRtm1bAMCKFSvQt29fLFq0SGNCUZIXeprjszp27IixY8fqqjnSoXOn4tDCsVuJxx/cS8eMqfP/s53lX6/B8q/X6DI0okqltYszjm/48bl1vLt3g3f3kv890atBrsM7KWqamK+pJ700ioqK8O6772Lq1Klo2rSp2vGYmBhYWFhIyQEAeHh4QC6X4/Tp0xg8eLDaOSXRSb/+48ePsXz5crzxxhv/XZmIiOg1omlifmhoaJnaWrBgAapWrYqJEydqPJ6SkgJra2ulsqpVq8LKygopKSlaXUvrHgRLS0ulsRkhBP79919Uq1YNmzdv1rY5IiKiSkeXcxBCQkIQHBysVFaW3oPY2FgsW7YM58+fr5A5ElonCKqzJeVyOWrVqoUOHTrA0tJSV3ERERG9Eso6nKDq2LFjSEtLg4PD/1/1V1hYiI8++ghLly7FrVu3YGtri7S0NKXzCgoKkJ6eDltbW62up3WCEBAQoO0pRERE9ILeffddeHh4KJV5enri3XffRWBgIADAzc0NGRkZiI2NRZv/u8vnoUOHUFRUhA4dOmh1vVInCPfv30dOTg4cHR2lssuXL2PRokXIycnBoEGDMHz4cK0uTkREVBnp6wZH2dnZuH79urSflJSEuLg4WFlZwcHBATX+b7ltMQMDA9ja2qJx48YAABcXF/Tp0wdjxoxBWFgY8vPzMX78ePj5+Wm1ggHQYpLihAkTsHz5cmk/LS0Nb775Js6ePYu8vDyMHDkSmzZt0uriRERElZFMprtNG+fOnUOrVq3QqlUrAEBwcDBatWqFGTNmlLqN8PBwODs7o2fPnujbty+6dOmC1atXaxcItOhBOHXqFNavXy/tb9y4EVZWVoiLi0PVqlWxaNEirFy5Eu+++67WQRARERHg7u4OIcR/V/w/t27dUiuzsrLS+qZImpS6ByElJQVOTk7S/qFDh+Dj44OqVZ/mGAMHDkRiYuILB0RERET6V+oEwczMDBkZGdL+mTNnlCY8yGQytRtBEBERvYz4sCYtEoSOHTti+fLlKCoqwi+//IJ///0XPXr0kI5fu3YNderwwSVERESvglLPQZg7dy569uyJzZs3o6CgAJ999pnSfQ9++ukndOvG248SEdHLT6bDWy2/rEqdILRo0QLx8fE4ceIEbG1t1dZT+vn5oUmTJjoPkIiIqKLp62mOlYlWN0qqWbOmxqc5AlB7ohQRERG9vHTysCYiIiJ6tejscc9ERESvipd59YGuMEEgIiJSwfyAQwxERESkgdYJQpUqVdQeJQkADx48QJUqVXQSFBEREemX1kMMJd0jOi8vD4aGhi8cEBERkb5xDoIWCULxkxxlMhl++OEHmJqaSscKCwsRHR0NZ2dn3UdIREREFa7UCcKSJUsAPO1BCAsLUxpOMDQ0hJOTE8LCwnQfIRERUQXjnRS1SBCSkpIAAN27d8evv/6qdJtlIiKiVwmHGMowB+Hw4cPS18XzEXhLSiIioldLmZY5bty4Ec2bN4exsTGMjY3RokULbNq0SdexERERkZ5o3YOwePFiTJ8+HePHj0fnzp0BAMePH8f777+P+/fvY8qUKToPkoiIqCKxY7wMCcKKFSvw3XffYcSIEVLZwIED0bRpU8yaNYsJAhERvfQ4dF6GIYbk5GR06tRJrbxTp05ITk7WSVBERESkX1onCA0aNMDPP/+sVr5161Y0bNhQJ0ERERGRfmk9xDB79mwMGzYM0dHR0hyEEydO4ODBgxoTByIiopcNlzmWoQfB19cXp0+fRs2aNREZGYnIyEjUrFkTZ86cweDBg8sjRiIiIqpgZXrcc5s2bbB582Zdx0JERFQpsAOBj3smIiIiDUrdgyCXy/9z2YdMJkNBQcELB0VERET6VeoEYceOHSUei4mJwfLly1FUVKSToIiIiPSJkxS1SBC8vb3VyhISEvDpp58iKioK/v7+mDNnjk6DIyIi0gc+zbGMcxDu3r2LMWPGoHnz5igoKEBcXBw2bNgAR0dHXcdHREREeqBVgpCZmYlPPvkEDRo0wOXLl3Hw4EFERUWhWbNm5RUfERFRhZPJZDrbXlalHmJYuHAhFixYAFtbW2zZskXjkAMRERG9Gkrdg/Dpp58iNzcXDRo0wIYNG+Dj46NxIyIietnJZbrbtBEdHY0BAwbA3t4eMpkMkZGR0rH8/Hx88sknaN68OUxMTGBvb48RI0bg7t27Sm2kp6fD398fZmZmsLCwwOjRo5Gdna31e1DqHoQRI0a81F0lRERElV1OTg5atmyJUaNGqf3R/ejRI5w/fx7Tp09Hy5Yt8fDhQ0yaNAkDBw7EuXPnpHr+/v5ITk7GgQMHkJ+fj8DAQIwdOxYRERFaxVLqBGH9+vVaNUxERPSy0tcfxF5eXvDy8tJ4zNzcHAcOHFAq+/bbb9G+fXvcuXMHDg4OiI+Px969e3H27Fm0bdsWALBixQr07dsXixYtgr29falj4Z0UiYiIylFeXh6ysrKUtry8PJ20nZmZCZlMBgsLCwBP70tkYWEhJQcA4OHhAblcjtOnT2vVNhMEIiKichQaGgpzc3OlLTQ09IXbzc3NxSeffIK3334bZmZmAICUlBRYW1sr1atatSqsrKyQkpKiVftlelgTERHRq0yXQwwhISEIDg5WKlMoFC/UZn5+PoYOHQohBL777rsXaqskTBCIiIhUaLv64HkUCsULJwTPKk4Obt++jUOHDkm9BwBga2uLtLQ0pfoFBQVIT0+Hra2tVtfhEAMREdFLojg5SExMxO+//44aNWooHXdzc0NGRgZiY2OlskOHDqGoqAgdOnTQ6lrsQSAiIqoksrOzcf36dWk/KSkJcXFxsLKygp2dHYYMGYLz589j165dKCwslOYVWFlZwdDQEC4uLujTpw/GjBmDsLAw5OfnY/z48fDz89NqBQPABIGIiEiNvpY5njt3Dt27d5f2i+cuBAQEYNasWdi5cycAwNXVVem8w4cPw93dHQAQHh6O8ePHo2fPnpDL5fD19cXy5cu1joUJAhERkQp93RfQ3d0dQogSjz/vWDErKyutb4qkCecgEBERkRr2IBAREamQ89EC7EEgIiIidUwQiIiISA2HGIiIiFTIwCEGJghEREQqOAWBQwxERESkARMEIiIiUsMhBiIiIhVc5sgeBCIiItKAPQhEREQq9PUshsqEPQhERESkhj0IREREKtiBwB4EIiIi0oA9CERERCo4B4EJAhERkRo58wMOMRAREZE6JghERESkhkMMREREKjgHgT0IREREpAF7EIiIiFSwA4E9CERERKQBEwQiIiJSwyEGIiIiFXzcMxMEIiIiNVzFwASBiIhIDfMDzkEgIiIiDZggEBERkRoOMRAREangHAT2IBAREZEGTBCIiIhUyGS627QRHR2NAQMGwN7eHjKZDJGRkUrHhRCYMWMG7OzsYGxsDA8PDyQmJirVSU9Ph7+/P8zMzGBhYYHRo0cjOztb6/eACQIREVElkZOTg5YtW2LlypUajy9cuBDLly9HWFgYTp8+DRMTE3h6eiI3N1eq4+/vj8uXL+PAgQPYtWsXoqOjMXbsWK1j4RwEIiKiSsLLywteXl4ajwkhsHTpUnzxxRfw9vYGAGzcuBE2NjaIjIyEn58f4uPjsXfvXpw9exZt27YFAKxYsQJ9+/bFokWLYG9vX+pY2INARESkQi6T6WzLy8tDVlaW0paXl6d1TElJSUhJSYGHh4dUZm5ujg4dOiAmJgYAEBMTAwsLCyk5AAAPDw/I5XKcPn1au/dA6wiJiIhecbqcgxAaGgpzc3OlLTQ0VOuYUlJSAAA2NjZK5TY2NtKxlJQUWFtbKx2vWrUqrKyspDqlxSEGIiKichQSEoLg4GClMoVCoadoSo8JAhERUTlSKBQ6SQhsbW0BAKmpqbCzs5PKU1NT4erqKtVJS0tTOq+goADp6enS+aXFIQYiIiIVMplMZ5uu1K1bF7a2tjh48KBUlpWVhdOnT8PNzQ0A4ObmhoyMDMTGxkp1Dh06hKKiInTo0EGr61WaHoQjUd/oOwSiSmfT3L36DoGoUpq0rUu5tq+vGylmZ2fj+vXr0n5SUhLi4uJgZWUFBwcHTJ48GV9++SUaNmyIunXrYvr06bC3t8egQYMAAC4uLujTpw/GjBmDsLAw5OfnY/z48fDz89NqBQNQiRIEIiKi1925c+fQvXt3ab947kJAQADWr1+PadOmIScnB2PHjkVGRga6dOmCvXv3wsjISDonPDwc48ePR8+ePSGXy+Hr64vly5drHQsTBCIiIhX6ehaDu7s7hBAlHpfJZJgzZw7mzJlTYh0rKytERES8cCycg0BERERqmCAQERGRGg4xEBERqeDTnpkgEBERqZEzQ+AQAxEREaljgkBERERqOMRARESkgiMM7EEgIiIiDdiDQEREpEJfN0qqTNiDQERERGrYg0BERKSCHQjsQSAiIiIN2INARESkgnMQmCAQERGpYX7AIQYiIiLSgAkCERERqeEQAxERkQrOQWAPAhEREWnAHgQiIiIV7EBgDwIRERFpwASBiIiI1HCIgYiISAUnKTJBICIiUsP8gAkCERGRGjkzBM5BICIiInVMEIiIiEgNhxiIiIhUcISBPQhERESkAXsQiIiIVHCZI3sQiIiISAMmCERERKSGCQIREZEKmUx3mzYKCwsxffp01K1bF8bGxqhfvz7mzp0LIYRURwiBGTNmwM7ODsbGxvDw8EBiYqKO3wEmCERERGpkcpnONm0sWLAA3333Hb799lvEx8djwYIFWLhwIVasWCHVWbhwIZYvX46wsDCcPn0aJiYm8PT0RG5urk7fA05SJCIiqiROnjwJb29v9OvXDwDg5OSELVu24MyZMwCe9h4sXboUX3zxBby9vQEAGzduhI2NDSIjI+Hn56ezWNiDQEREVI7y8vKQlZWltOXl5Wms26lTJxw8eBDXrl0DAFy4cAHHjx+Hl5cXACApKQkpKSnw8PCQzjE3N0eHDh0QExOj07iZIBAREanQ5RyE0NBQmJubK22hoaEar/vpp5/Cz88Pzs7OMDAwQKtWrTB58mT4+/sDAFJSUgAANjY2SufZ2NhIx3SFQwxEREQqdHkfhJCQEAQHByuVKRQKjXV//vlnhIeHIyIiAk2bNkVcXBwmT54Me3t7BAQE6Cym0mCCQEREVI4UCkWJCYGqqVOnSr0IANC8eXPcvn0boaGhCAgIgK2tLQAgNTUVdnZ20nmpqalwdXXVadwcYiAiIlKhr2WOjx49glyu/Ku5SpUqKCoqAgDUrVsXtra2OHjwoHQ8KysLp0+fhpub2wu/7mexB4GIiKiSGDBgAL766is4ODigadOm+OOPP7B48WKMGjUKwNOhj8mTJ+PLL79Ew4YNUbduXUyfPh329vYYNGiQTmNhgkBERFRJrFixAtOnT8eHH36ItLQ02NvbY9y4cZgxY4ZUZ9q0acjJycHYsWORkZGBLl26YO/evTAyMtJpLDLx7O2Z9Cj94jl9h0BU6Wyau1ffIRBVSpO2fVGu7UfPXKOztrrOHqOztioSexCIiIhU8GGOnKRIREREGjBBICIiIjUcYiAiIlLFMQb2IBAREZE69iAQERGp0OWtll9W7EEgIiIiNexBICIiUsEOBPYgEBERkQbsQSAiIlIhk7MLgQkCERGRCg4xcIiBiIiINGCCQERERGo4xEBERKSC90FgDwIRERFpwB4EIiIiFexAYA8CERERacAEgYiIiNRwiIGIiEgFJykyQSAiIlLD/IBDDERERKRBqXsQfHx8St3or7/+WqZgiIiIqHIodYJgbm4ufS2EwI4dO2Bubo62bdsCAGJjY5GRkaFVIkFERFQZcQ6CFgnCunXrpK8/+eQTDB06FGFhYahSpQoAoLCwEB9++CHMzMx0HyUREVFF4gB82d6CtWvX4uOPP5aSAwCoUqUKgoODsXbtWp0FR0RERPpRpgShoKAAV69eVSu/evUqioqKXjgoIiIifZLJZDrbXlZlWuYYGBiI0aNH48aNG2jfvj0A4PTp05g/fz4CAwN1GiARERFVvDIlCIsWLYKtrS2++eYbJCcnAwDs7OwwdepUfPTRRzoNkIiIiCpemRIEuVyOadOmYdq0acjKygIATk4kIqJXxks8MqAzZZ6nWVBQgN9//x1btmyRxlju3r2L7OxsnQVHRESkD5yDUMYE4fbt22jevDm8vb0RFBSEe/fuAQAWLFiAjz/+WKcBEhERvU7++ecfvPPOO6hRowaMjY3RvHlznDt3TjouhMCMGTNgZ2cHY2NjeHh4IDExUedxlClBmDRpEtq2bYuHDx/C2NhYKh88eDAOHjyos+CIiIheJw8fPkTnzp1hYGCAPXv24MqVK/jmm29gaWkp1Vm4cCGWL1+OsLAwnD59GiYmJvD09ERubq5OYynTHIRjx47h5MmTMDQ0VCp3cnLCP//8o5PAiIiI9EVfIwMLFixAnTp1lG5OWLduXelrIQSWLl2KL774At7e3gCAjRs3wsbGBpGRkfDz89NZLGXqQSgqKkJhYaFa+d9//43q1au/cFBERER6JZPpbMvLy0NWVpbSlpeXp/GyO3fuRNu2bfHWW2/B2toarVq1wpo1a6TjSUlJSElJgYeHh1Rmbm6ODh06ICYmRqdvQZkShN69e2Pp0qXSvkwmQ3Z2NmbOnIm+ffvqKjYiIqKXXmhoKMzNzZW20NBQjXVv3ryJ7777Dg0bNsS+ffvwwQcfYOLEidiwYQMAICUlBQBgY2OjdJ6NjY10TFfKNMTwzTffwNPTE02aNEFubi6GDx+OxMRE1KxZE1u2bNFpgERERBVNJtfdGENISAiCg4OVyhQKhca6RUVFaNu2LebNmwcAaNWqFf7880+EhYUhICBAZzGVRpkShNq1a+PChQv46aefcPHiRWRnZ2P06NHw9/dXmrRIRET0ulMoFCUmBKrs7OzQpEkTpTIXFxds374dAGBrawsASE1NhZ2dnVQnNTUVrq6uugn4/5QpQcjNzYWRkRHeeecdnQZDRET0OuvcuTMSEhKUyq5duwZHR0cATycs2tra4uDBg1JCkJWVhdOnT+ODDz7QaSxlmoNgbW2NgIAAHDhwgA9nIiKiV44O5yhqZcqUKTh16hTmzZuH69evIyIiAqtXr0ZQUND/xSXD5MmT8eWXX2Lnzp24dOkSRowYAXt7ewwaNEin70GZEoQNGzbg0aNH8Pb2xhtvvIHJkycr3cSBiIjoZaavOym2a9cOO3bswJYtW9CsWTPMnTsXS5cuhb+/v1Rn2rRpmDBhAsaOHYt27dohOzsbe/fuhZGRkW7fAyGEKOvJ//77L3755Rds2bIFhw4dQr169fDOO+9gxowZWreVfpEJBpGqTXP36jsEokpp0rYvyrX9S6sidNZW8w+H66ytilTmZzEAQPXq1REYGIj9+/fj4sWLMDExwezZs3UVGxEREelJmSYpFsvNzcXOnTsRERGBvXv3wsbGBlOnTtVVbFSBch4/xuqffkH0mbNIz8xCo7pOmBL4Lpo0qK/v0IjKjb2LA9oM7AjrenYwtaqOqIU/4+bZa9Lx+u0bo3nvNrCuZwvj6tUQPnUN7t9KVWqjmoUJurzrAYcWdWFoZIiHdx/g7K8ncP301Yp+OaRDL/EzlnSmTD0I+/btQ0BAAGxsbPDBBx/AxsYG+/fvx+3btzF//nxdx0gVIPS7NTh78RJmTPgAm7+Zjw4tm2PinFCkPUjXd2hE5cZAYYD7t9Nw5EfNQzkGRoa4e/UvnNh8qMQ2eo/3hqW9FaIW/IzNH63G9dMJ8Ar2QS0nmxLPIXoZlKkHYfDgwejfvz82btyIvn37wsDAQNdxUQXKzXuCI6fPYsG0YLRq4gIAeG+oL46fO48d+3/HuLeH6jlCovJxO+4GbsfdKPH41ehLAIDqtcxLrGPXuDYOr9mD1Ot3AQBnfz2OVv3bw7qeHe6p9DbQS4RdCGVLEFJTU/nMhVdIYVEhCouKYGionOgpDA1x4eq1Es4iIgBITvgbjTo1QdL5ROTl5KKRWxNUNaiKv6/c1ndoRC+k1AlCVlYWzMzMADx9mlRWVlaJdYvr0cvBxNgYzRo1xLpfIuH0xhuwMjfHgRMn8ee1RNT+v7t2EZFm/1u8HX2n+OD9dR+jsKAQBU/ysevrX5CZ8lDfodEL0OWtll9WpU4QLC0tkZycDGtra1hYWGhc2ymEgEwm0/ikx2fl5eWpPckq78kTKFQeH00VZ+aED/DVqtUYOG48qsjlaFTXCb26dMLVm0n6Do2oUnPzc4fCxAi/zt6Mx/8+Qv12jdE32AfbZmzAgzv39B0eUZmVOkE4dOgQrKyspK+1vfnDs0JDQ9WWQ057fww++WBsmdukF1Pb1gbfzZmOx7m5yHn8GDUtLfHF4uV4w9pa36ERVVrmNpZw9WqHTVPCkP73fQDA/dtpsHdxQEvPtji0Zo+eI6Sy4hQELRKEbt26SV+7u7u/0EU1Pdkq59qfL9Qm6YaxkRGMjYyQlZ2D0xcuIeidt/UdElGlVVXx9Eeo6v3mRFERwC7qlxszhLJNUmzYsCH8/f3h7++Phg0ban2+pidbFXB4Qa9OxV2EEAKO9nb4OyUV326KgOMbdujfvau+QyMqNwZGBjC3tZL2za0tUNPJBnnZj/Hv/SwoTI1QvaY5TC1NAQCW9jUAAI8ysvEoIwcP/3mAjOR09BzbD8c2/Y7cfx+jXrtGcGhRDzvn/6SX10SkK2VKED788ENERERg7ty5aN26Nd555x0MGzZMegwlvXyyHz1CWMRWpD1Ih5mpKdw7tMP7bw9F1aovdC8tokrNup49hsx+V9rvOrI3AODKkQs4sDIK9do2Qu+ggdLxvlN8AACnfo7G6W3RKCoswm/ztqCzfw8M/GQoDIwMkZHyEPtX7sStP0pePkn0MnihZzFcu3YN4eHh2LJlC5KSktC9e3e88847GDFihNZt8VkMROr4LAYizcr7WQzxP27VWVsuo4fprK2K9ELPYmjUqBFmz56Na9eu4dixY7h37x4CAwN1FRsRERHpyQv3H585cwYRERHYunUrsrKy8NZbb+kiLiIiIr3hfRDKmCCoDi306NEDCxYsgI+PD0xNTXUdIxEREVWwMiUIzs7OaNeuHYKCguDn5wcbGz6UhIiI6FWidYJQWFiI77//HkOGDIGlpWV5xERERKRXL3IzwFeF1pMUq1SpggkTJiAjI6McwiEiIqoEZDrcXlJlWsXQrFkz3Lx5U9exEBERUSVRpgThyy+/xMcff4xdu3YhOTkZWVlZShsRERG93Mo0SbFv374AgIEDByqN05T2aY5ERESVGecglDFBOHz4sK7jICIiqjSYIJQxQXj2yY5ERET06ilTghAdHf3c41278gmARET0EnuhBxG8GsqUILi7u6uVPdsdwzkIREREL7cy5UgPHz5U2tLS0rB37160a9cO+/fv13WMREREVMHK1INgbm6uVtarVy8YGhoiODgYsbGxLxwYERGRvnCSog6e5vgsGxsbJCQk6LJJIiKiCscEoYwJwsWLF5X2hRBITk7G/Pnz4erqqou4iIiISI/KlCC4urpCJpNBCKFU3rFjR6xdu1YngREREZH+lClBSEpKUtqXy+WoVasWjIyMdBIUERGRXnGEQbtVDDExMdi1axccHR2l7ejRo+jatSscHBwwduxY5OXllVesREREFUIml+lsK6v58+dDJpNh8uTJUllubi6CgoJQo0YNmJqawtfXF6mpqTp4xeq0ShDmzJmDy5cvS/uXLl3C6NGj4eHhgU8//RRRUVEIDQ3VeZBERESvk7Nnz+L7779HixYtlMqnTJmCqKgobNu2DUePHsXdu3fh4+NTLjFolSDExcWhZ8+e0v5PP/2EDh06YM2aNQgODsby5cvx888/6zxIIiKi10V2djb8/f2xZs0aWFpaSuWZmZn48ccfsXjxYvTo0QNt2rTBunXrcPLkSZw6dUrncWiVIDx8+BA2NjbS/tGjR+Hl5SXtt2vXDn/99ZfuoiMiItIHmUxnW15eHrKyspS25w3HBwUFoV+/fvDw8FAqj42NRX5+vlK5s7MzHBwcEBMTo/O3QKsEwcbGRpqg+OTJE5w/fx4dO3aUjv/7778wMDDQbYREREQvsdDQUJibmyttJQ3H//TTTzh//rzG4ykpKTA0NISFhYVSuY2NDVJSUnQet1arGPr27YtPP/0UCxYsQGRkJKpVq4Y333xTOn7x4kXUr19f50ESERFVJF3eJykkJATBwcFKZQqFQq3eX3/9hUmTJuHAgQOVYlWgVgnC3Llz4ePjg27dusHU1BQbNmyAoaGhdHzt2rXo3bu3zoMkIiKqSLq8k6JCodCYEKiKjY1FWloaWrduLZUVFhYiOjoa3377Lfbt24cnT54gIyNDqRchNTUVtra2Oou3mFYJQs2aNREdHY3MzEyYmpqiSpUqSse3bdsGU1NTnQZIRET0OujZsycuXbqkVBYYGAhnZ2d88sknqFOnDgwMDHDw4EH4+voCABISEnDnzh24ubnpPB6dPawJAKysrF4oGCIiotdV9erV0axZM6UyExMT1KhRQyofPXo0goODYWVlBTMzM0yYMAFubm5K8wF1RacPayIiInolvMANjsrTkiVLIJfL4evri7y8PHh6emLVqlXlci0mCERERJXUkSNHlPaNjIywcuVKrFy5styvzQSBiIhIBR/3rOV9EIiIiOj1wB4EIiIiVexAYA8CERERqWMPAhERkQrOQWCCQEREpEZWSZc5ViQOMRAREZEaJghERESkhkMMREREqjgHgT0IREREpI49CERERCq4ioE9CERERKQBEwQiIiJSwyEGIiIiVRxhYIJARESkijdK4hADERERacAEgYiIiNRwiIGIiEgVlzkyQSAiIlLF+yBwiIGIiIg0YA8CERGRKq5iYA8CERERqWOCQERERGo4xEBERKSCkxSZIBAREaljfsAhBiIiIlLHBIGIiIjUcIiBiIhIBecgMEEgIiJSx/sgcIiBiIiI1DFBICIiqiRCQ0PRrl07VK9eHdbW1hg0aBASEhKU6uTm5iIoKAg1atSAqakpfH19kZqaqvNYmCAQERGpkMlkOtu0cfToUQQFBeHUqVM4cOAA8vPz0bt3b+Tk5Eh1pkyZgqioKGzbtg1Hjx7F3bt34ePjo+u3gHMQiIiIKou9e/cq7a9fvx7W1taIjY1F165dkZmZiR9//BERERHo0aMHAGDdunVwcXHBqVOn0LFjR53Fwh4EIiIiVTKZzra8vDxkZWUpbXl5eaUKIzMzEwBgZWUFAIiNjUV+fj48PDykOs7OznBwcEBMTIxO3wImCERERCp0OcQQGhoKc3NzpS00NPQ/YygqKsLkyZPRuXNnNGvWDACQkpICQ0NDWFhYKNW1sbFBSkqKTt8DDjEQERGVo5CQEAQHByuVKRSK/zwvKCgIf/75J44fP15eoT0XEwQiIqJypFAoSpUQPGv8+PHYtWsXoqOjUbt2banc1tYWT548QUZGhlIvQmpqKmxtbXUVMgAOMRAREamTy3S3aUEIgfHjx2PHjh04dOgQ6tatq3S8TZs2MDAwwMGDB6WyhIQE3LlzB25ubjp56cXYg0BERFRJBAUFISIiAr/99huqV68uzSswNzeHsbExzM3NMXr0aAQHB8PKygpmZmaYMGEC3NzcdLqCAWCCQEREpEZfz2L47rvvAADu7u5K5evWrcPIkSMBAEuWLIFcLoevry/y8vLg6emJVatW6TwWJghERESVhBDiP+sYGRlh5cqVWLlyZbnGwgSBiIhIFZ/myEmKREREpI49CERERCpkfNwzexCIiIhIHRMEIiIiUsMhBiIiIlWcpMgEgYiISJW+7oNQmXCIgYiIiNSwB4GIiEgVexDYg0BERETqmCAQERGRGg4xEBERqeCNkpggEBERqeMcBA4xEBERkTomCERERKSGQwxERESqOMQAmRBC6DsIqjzy8vIQGhqKkJAQKBQKfYdDVCnw3wW9jpggkJKsrCyYm5sjMzMTZmZm+g6HqFLgvwt6HXEOAhEREalhgkBERERqmCAQERGRGiYIpEShUGDmzJmciEX0DP67oNcRJykSERGRGvYgEBERkRomCERERKSGCQIRERGpYYJAOjdr1iy4urqW+3WcnJywdOnScr8O0bOOHDkCmUyGjIyMcr3OyJEjMWjQoHK9BtHzMEGoACNHjoRMJsP8+fOVyiMjIyHT8n7fpf2leOHCBQwcOBDW1tYwMjKCk5MThg0bhrS0NK2uVxYff/wxDh48WO7XodfbvXv38MEHH8DBwQEKhQK2trbw9PTEiRMnyvW6nTp1QnJyMszNzcv1OkT6xgShghgZGWHBggV4+PBhuV/r3r176NmzJ6ysrLBv3z7Ex8dj3bp1sLe3R05OTpnbffLkSanqmZqaokaNGmW+DlFp+Pr64o8//sCGDRtw7do17Ny5E+7u7njw4EGZ2hNCoKCg4D/rGRoawtbWVuvknuhlwwShgnh4eMDW1hahoaHPrbd9+3Y0bdoUCoUCTk5O+Oabb6Rj7u7uuH37NqZMmQKZTFbiD6gTJ04gMzMTP/zwA1q1aoW6deuie/fuWLJkCerWrQsAWL9+PSwsLJTOU+3RKB4q+OGHH1C3bl0YGRlh9erVsLe3R1FRkdK53t7eGDVqlNJ5ALB//34YGRmpdcdOmjQJPXr0kPaPHz+ON998E8bGxqhTpw4mTpyolMykpaVhwIABMDY2Rt26dREeHv7c95FebRkZGTh27BgWLFiA7t27w9HREe3bt0dISAgGDhyIW7duQSaTIS4uTukcmUyGI0eOAPj/QwV79uxBmzZtoFAosHbtWshkMly9elXpekuWLEH9+vWVzsvIyEBWVhaMjY2xZ88epfo7duxA9erV8ejRIwDAX3/9haFDh8LCwgJWVlbw9vbGrVu3pPqFhYUIDg6GhYUFatSogWnTpoEr0EnfmCBUkCpVqmDevHlYsWIF/v77b411YmNjMXToUPj5+eHSpUuYNWsWpk+fjvXr1wMAfv31V9SuXRtz5sxBcnIykpOTNbZja2uLgoIC7Nix44V/yFy/fh3bt2/Hr7/+iri4OLz11lt48OABDh8+LNVJT0/H3r174e/vr3Z+z549YWFhge3bt0tlhYWF2Lp1q1T/xo0b6NOnD3x9fXHx4kVs3boVx48fx/jx46VzRo4cib/++guHDx/GL7/8glWrVlXIcAlVTqampjA1NUVkZCTy8vJeqK1PP/0U8+fPR3x8PIYMGYK2bduqJaDh4eEYPny42rlmZmbo378/IiIi1OoPGjQI1apVQ35+Pjw9PVG9enUcO3YMJ06cgKmpKfr06SP1yn3zzTdYv3491q5di+PHjyM9PR07dux4oddF9MIElbuAgADh7e0thBCiY8eOYtSoUUIIIXbs2CGe/RYMHz5c9OrVS+ncqVOniiZNmkj7jo6OYsmSJf95zc8++0xUrVpVWFlZiT59+oiFCxeKlJQU6fi6deuEubm50jmq8cycOVMYGBiItLQ0pXre3t7SaxBCiO+//17Y29uLwsJC6byWLVtKxydNmiR69Ogh7e/bt08oFArx8OFDIYQQo0ePFmPHjlW6xrFjx4RcLhePHz8WCQkJAoA4c+aMdDw+Pl4AKNV7Qa+mX375RVhaWgojIyPRqVMnERISIi5cuCCEECIpKUkAEH/88YdU/+HDhwKAOHz4sBBCiMOHDwsAIjIyUqndJUuWiPr160v7xZ+/+Ph4pfOKP787duwQpqamIicnRwghRGZmpjAyMhJ79uwRQgixadMm0bhxY1FUVCS1mZeXJ4yNjcW+ffuEEELY2dmJhQsXSsfz8/NF7dq1pZ8bRPrAHoQKtmDBAmzYsAHx8fFqx+Lj49G5c2elss6dOyMxMRGFhYVaXeerr75CSkoKwsLC0LRpU4SFhcHZ2RmXLl3Sqh1HR0fUqlVLqczf3x/bt2+X/nILDw+Hn58f5HLNHyd/f38cOXIEd+/eler369dPGuK4cOEC1q9fL/1VaGpqCk9PTxQVFSEpKQnx8fGoWrUq2rRpI7Xp7OysNkRCrxdfX1/cvXsXO3fuRJ8+fXDkyBG0bt1a6nErrbZt2yrt+/n54datWzh16hSAp5/X1q1bw9nZWeP5ffv2hYGBAXbu3Ang6TChmZkZPDw8ADz9fF+/fh3Vq1eXPt9WVlbIzc3FjRs3kJmZieTkZHTo0EFqs2rVqmpxEVU0JggVrGvXrvD09ERISEi5X6tGjRp46623sGjRIsTHx8Pe3h6LFi0CAMjlcrXhh/z8fLU2TExM1MoGDBgAIQR2796Nv/76C8eOHdM4vFCsXbt2qF+/Pn766Sc8fvwYO3bsUKqfnZ2NcePGIS4uTtouXLiAxMREadyXSBMjIyP06tUL06dPx8mTJzFy5EjMnDlTSlaf/Yxr+nwD6p9xW1tb9OjRQxo2iIiIeO7n29DQEEOGDFGqP2zYMFStWhXA0893mzZtlD7fcXFxuHbtmsZhC6LKoqq+A3gdzZ8/H66urmjcuLFSuYuLi9oSrRMnTqBRo0aoUqUKgKc/jLTtTSg+r379+tLEv1q1auHff/9FTk6O9APy2Qldz2NkZAQfHx+Eh4fj+vXraNy4MVq3bv3cc/z9/REeHo7atWtDLpejX79+0rHWrVvjypUraNCggcZznZ2dUVBQgNjYWLRr1w4AkJCQUO7r0Onl06RJE0RGRkq9XsnJyWjVqhWA0n++gaef12nTpuHtt9/GzZs34efn95/1e/XqhcuXL+PQoUP48ssvpWOtW7fG1q1bYW1tDTMzM43n29nZ4fTp0+jatSsASJ/3//p3RVSu9DzE8Vp4dg5CsXfffVcYGRkpjfnHxsYKuVwu5syZIxISEsT69euFsbGxWLdunVSnV69eYuDAgeLvv/8W9+7d03i9qKgo4e/vL6KiokRCQoK4evWq+Prrr0WVKlXExo0bhRBCPHjwQJiYmIiJEyeK69evi/DwcGFvb682B+HZuQTPOnDggFAoFKJx48Zi7ty5Ssc0nZeYmCgAiBYtWojRo0crHbtw4YIwNjYWQUFB4o8//hDXrl0TkZGRIigoSKrTp08f0apVK3Hq1Clx7tw50aVLF2FsbMw5CK+p+/fvi+7du4tNmzaJCxcuiJs3b4qff/5Z2NjYSPNjOnbsKN58801x5coVceTIEdG+fXuNcxCK5xI8KysrSxgbG4uWLVuKnj17Kh3TdF5RUZGoU6eOaNmypdL8BSGEyMnJEQ0bNhTu7u4iOjpa3Lx5Uxw+fFhMmDBB/PXXX0IIIebPny+srKzEjh07RHx8vBgzZoyoXr065yCQXjFBqACaEoSkpCRhaGgoVHO0X375RTRp0kQYGBgIBwcH8fXXXysdj4mJES1atBAKhULt3GI3btwQY8aMEY0aNRLGxsbCwsJCtGvXTinREOLp5KoGDRoIY2Nj0b9/f7F69epSJwiFhYXCzs5OABA3btxQOlbSecU/oA8dOqR27MyZM6JXr17C1NRUmJiYiBYtWoivvvpKOp6cnCz69esnFAqFcHBwEBs3biz1hE169eTm5opPP/1UtG7dWpibm4tq1aqJxo0biy+++EI8evRICCHElStXhJubmzA2Nhaurq5i//79pU4QhBBi6NChAoBYu3atUnlJ502bNk0AEDNmzFBrKzk5WYwYMULUrFlTKBQKUa9ePTFmzBiRmZkphHg6KXHSpEnCzMxMWFhYiODgYDFixAgmCKRXfNwzERERqeEkRSIiIlLDBIGIiIjUMEEgIiIiNUwQiIiISA0TBCIiIlLDBIGIiIjUMEEgIiIiNUwQiIiISA0TBCIiIlLDBIGIiIjUMEEgIiIiNUwQiIiISM3/A1eZMM8L4azQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3_cf = confusion_matrix(y_test_normalize, predict)\n",
    "plot_cm(model3_cf, 'Model 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Survived</th>\n",
       "      <td>0.954082</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>204.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>127.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.921450</td>\n",
       "      <td>0.921450</td>\n",
       "      <td>0.921450</td>\n",
       "      <td>0.92145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.914078</td>\n",
       "      <td>0.922900</td>\n",
       "      <td>0.917882</td>\n",
       "      <td>331.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.923384</td>\n",
       "      <td>0.921450</td>\n",
       "      <td>0.921864</td>\n",
       "      <td>331.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "Not Survived   0.954082  0.916667  0.935000  204.00000\n",
       "Survived       0.874074  0.929134  0.900763  127.00000\n",
       "accuracy       0.921450  0.921450  0.921450    0.92145\n",
       "macro avg      0.914078  0.922900  0.917882  331.00000\n",
       "weighted avg   0.923384  0.921450  0.921864  331.00000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_report = classification_report(y_test_normalize, predict, output_dict=True, target_names=['Not Survived',\"Survived\"])\n",
    "pd.DataFrame(model3_report).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
